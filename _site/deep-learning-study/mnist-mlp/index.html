<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Gratus907's Study Note


  | Softmax Regression / MLPë¡œ MNIST í’€ì–´ë³´ê¸°

</title>
<meta name="description" content="Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/deep-learning-study/mnist-mlp/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KX3EZM1ESL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-KX3EZM1ESL');
</script>



<!-- Panelbear Analytics - We respect your privacy -->
<script async src="https://cdn.panelbear.com/analytics.js?site=KX0fnophvY8"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: 'KX0fnophvY8' });
</script>


<script async src = "//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script >

    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [ ['$$', '$$'], ['\\[', '\\]'], ['\\(', '\\)']],
        packages: {'[+]': ['physics']}
      },
      loader: {
        load: ["input/tex", "output/chtml", '[tex]/physics']
      },
    };
  </script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  <p style="display: none;">$$
      \newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
      \newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
      \newcommand{\N}{\mathbb{N}}
      \newcommand{\R}{\mathbb{R}}
      \newcommand{\Z}{\mathbb{Z}}
      \newcommand{\Q}{\mathbb{Q}}
      \newcommand{\C}{\mathbb{C}}
      \renewcommand{\L}{\mathcal{L}}
      \newcommand{\x}{\times}
      \newcommand{\contra}{\scalebox{1.5}{$\lightning$}}
      \newcommand{\inner}[2]{\left\langle #1 , #2 \right\rangle}
      \newcommand{\st}{\text{ such that }}
      \newcommand{\for}{\text{ for }}
      \newcommand{\Setcond}[2]{ \left\{\, #1 \mid #2 \, \right\}}
      \newcommand{\setcond}[2]{\Setcond{#1}{#2}}
      \newcommand{\seq}[1]{ \left\langle #1 \right\rangle}
      \newcommand{\Set}[1]{ \left\{ #1 \right\}}
      \newcommand{\set}[1]{ \set{#1} }
      \newcommand{\sgn}{\text{sign}}
      \newcommand{\halfline}{\vspace{0.5em}}
      \newcommand{\diag}{\text{diag}}
  
      \newcommand{\legn}[2]{\left(\frac{#1}{#2}\right)} 
      \newcommand{\ord}{\text{ord}}
      \newcommand{\di}{\mathrel{|}} 
      \newcommand{\gen}[1] 
      \newcommand{\irr}{\mathrm{irr }}
      \renewcommand{\deg}{\mathrm{deg }}
      \newcommand{\nsgeq}{\trianglelefteq}
      \newcommand{\nsg}{\triangleleft}
      
      \newcommand{\argmin}{\mathrm{argmin}}
      \newcommand{\argmax}{\mathrm{argmax}}
      \newcommand{\minimize}{\mathrm{minimize}}
      \newcommand{\maximize}{\mathrm{maximize}}
      \newcommand{\subto}{\mathrm{subject\ to}}
      \newcommand{\DKL}[2]{D_{\mathrm{KL}}\left(#1 \di\di #2\right)}
      \newcommand{\ReLU}{\mathrm{ReLU}}
      
      \newcommand{\E}{\mathbb{E}}
      \newcommand{\expect}[1]{\E\left[#1\right]}
      \newcommand{\expectwith}[2]{\E_{#1}\left[#2\right]}
      \renewcommand{\P}{\mathbb{P}}
      \newcommand{\uniform}[2]{\mathrm{Uniform}\left(#1 \dots #2\right)}
      \newcommand{\gdist}[2]{\mathcal{N}\left(#1, #2\right)}
      $$</p>
  
  </head>

  <body class=" sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       Gratus907's Study Note
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              Home
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Posts
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/about-me/">
                About me
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/study-note/">
                Notes
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                ë¶„ë¥˜
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/ds-alg-note/">Algo / DS</a>
              
              
              
                <a class="dropdown-item" href="/advanced-algorithms/">Advanced Algo / DS</a>
              
              
              
                <a class="dropdown-item" href="/cs-adventure/">CS-Adventure</a>
              
              
              
                <a class="dropdown-item" href="/cp-rounds/">Competitive Programming</a>
              
              
              
                <a class="dropdown-item" href="/deep-learning-study/">Deep Learning Study</a>
              
              
              </div>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->
    
    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Softmax Regression / MLPë¡œ MNIST í’€ì–´ë³´ê¸°</h1>
    <p class="post-meta">October 6, 2021 â€¢ 1371 words</p>
  </header>

  <article class="post-content">
    <a href="http://localhost:4000/deep-learning-study"> Back to : deep-learning-study</a><br>
    
    <div id="toc">
Contents
</div>
<ul id="markdown-toc">
  <li><a href="#problem--dataset" id="markdown-toc-problem--dataset">Problem / Dataset</a></li>
  <li><a href="#softmax-regression" id="markdown-toc-softmax-regression">Softmax Regression</a></li>
  <li><a href="#multi-layer-perceptron" id="markdown-toc-multi-layer-perceptron">Multi-Layer Perceptron</a></li>
</ul>
<hr>

<p><strong>ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ìˆ˜í•™ì  ê¸°ì´ˆ</strong> 5ê°•, 6ê°• (9ì›” 16ì¼, 23ì¼) ì— ê¸°ë°˜í•©ë‹ˆë‹¤. ì´ë²ˆ ë‚´ìš©ì€ ëŒ€ë¶€ë¶„ì´ ì½”ë“œì— ëŒ€í•œ ë‚´ìš©ì´ë¼ì„œ, $\LaTeX$ ë…¸íŠ¸ë¥¼ ë³€í™˜í•˜ì§€ ì•Šê³  ì—¬ê¸°ì— ë°”ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.</p>

<p>ì•„ì§ ì½ì§€ ì•Šì•˜ë‹¤ë©´, ìµœì†Œí•œ <a href="/deep-learning-study/softmax-regression">Softmax(ë§í¬)</a>ì™€ <a href="/deep-learning-study/multilayer-perceptron">MLP(ë§í¬)</a>ì— ëŒ€í•œ í¬ìŠ¤íŒ… ì„, ë˜ë„ë¡ <a href="/deep-learning-study/">ë§í¬</a> ì— ìˆëŠ” í¬ìŠ¤íŒ… ì¤‘ shallow-nnê³¼ SVM, LRì— ëŒ€í•œ ë‚´ìš©ì„ ì½ìœ¼ë©´ ì´ë¡ ì  ë°°ê²½ì´ ì¶©ë¶„í•  ê²ƒìœ¼ë¡œ ìƒê°í•©ë‹ˆë‹¤ (ì œê°€ ì´ ë‚´ìš©ì„ ê³µë¶€í•´ì„œ ì´í•´í•œëŒ€ë¡œ ì •ë¦¬í–ˆìœ¼ë‹ˆê¹Œìš”..?)</p>

<h2 id="problem--dataset">Problem / Dataset</h2>
<p>ì´ë²ˆì— í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œëŠ”, MNISTë¼ëŠ” ë§¤ìš° ìœ ëª…í•œ ë°ì´í„°ì…‹ì„ ì´ìš©í•©ë‹ˆë‹¤. MNISTëŠ” Hand-written ìˆ«ìë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ, ë„ë¦¬ ì•Œë ¤ì§„ CNN ëª¨ë¸ì„ ì²˜ìŒ ì œì‹œí•œ LeCunì˜ ì—°êµ¬ì— ì‚¬ìš©ë˜ì—ˆë˜ ë°ì´í„°ì…‹ì´ê¸°ë„ í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ë”¥ ëŸ¬ë‹ì„ ë§Œë“¤ê¸°ì—ëŠ” ë„ˆë¬´ ì‘ì€ ë°ì´í„°ì…‹ì´ì§€ë§Œ ê³µë¶€í•˜ëŠ” ëª©ì ìœ¼ë¡œ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

<p>ê° ì´ë¯¸ì§€ëŠ” 28 by 28 grayscale imageë¡œ, í¸ì˜ìƒ $\R^{28 \times 28}$ ìœ¼ë¡œ ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.</p>

<p>ê°€ì¥ ë¨¼ì € í•´ì•¼í•  ì¼ì€ pytorch moduleì„ importí•˜ê³ , ë°ì´í„°ë¥¼ ë°›ì•„ì˜¤ê³  ì •ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.<br>
Pytorchì—ì„œëŠ” <code class="language-plaintext highlighter-rouge">DataLoader</code>ë¼ëŠ” ëª¨ë“ˆì„ ì´ìš©í•˜ì—¬, í¸í•˜ê²Œ ë°ì´í„°ë¥¼ Batchë¡œ ë¨¹ì¸ë‹¤ê±°ë‚˜ í•˜ëŠ” ì‘ì—…ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./mnist_data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./mnist_data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">device =</code> ë¶€ë¶„ì€ ê°€ëŠ¥í•˜ë‹¤ë©´ cuda GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•˜ëŠ” ë¶€ë¶„ì¸ë°, ì‚¬ì‹¤ ì´ë²ˆ íƒœìŠ¤í¬ëŠ” ë„ˆë¬´ ì‘ê¸° ë•Œë¬¸ì— GPUë¥¼ ì“°ë©´ ì´ë“ì´ ì—†ê±°ë‚˜ ì˜¤íˆë ¤ ë” ëŠë ¤ì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</p>

<h2 id="softmax-regression">Softmax Regression</h2>
<p>ë¨¼ì €, ìš°ë¦¬ëŠ” Softmax regressionì„ ì‹œë„í•´ ë³´ê² ìŠµë‹ˆë‹¤. Pytorchì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.</p>
<ul>
  <li>Model ì •ì˜ : ì…ë ¥ $x$ë¥¼ ì–´ë–¤ ê³¼ì •ì„ ê±°ì³ ì¶œë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ì§€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì—ëŠ” í›ˆë ¨ê°€ëŠ¥í•œ parameterê°€ ìˆìŠµë‹ˆë‹¤.</li>
  <li>Loss function ì •ì˜ : ëª¨ë¸ì´ ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ í˜„ì¬ ì •í™•ë„ë¥¼ ì¸¡ì •í• ì§€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.</li>
  <li>í•™ìŠµ : Training dataë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.</li>
</ul>

<p>ì´ì œ, Modelì„ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤. Modelì€ ê¸°ë³¸ì ìœ¼ë¡œ softmax regressionì—ì„œ ê³µë¶€í–ˆë˜ ëª¨ë¸ë¡œ, $Ax + b$ ë¥¼ 10ê°œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.</p>

<p>ì—¬ê¸°ì„œ, <code class="language-plaintext highlighter-rouge">__init__</code> ì„ ì´ìš©í•˜ì—¬ ì´ ëª¨ë¸ì—ì„œ ì“¸ Layerë“¤ì„ ì •ì˜í•˜ê³ , ê·¸ Layerë“¤ì„ <code class="language-plaintext highlighter-rouge">forward</code> ë©”ì„œë“œë¥¼ í†µí•´ ì‚¬ìš©í•´ì„œ ë„˜ê²¨ì£¼ë©´ ë©ë‹ˆë‹¤.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SoftMax</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SoftMax</span><span class="p">()</span>
</code></pre></div></div>
<p>Softmax Regressionì€ ì´ë ‡ê²Œ ì •ì˜ëœ modelì— ë‹¤ìŒê³¼ ê°™ì€ ìµœì í™” ë¬¸ì œë¥¼ í‘¸ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. 
\(\underset{a \in \R^{k \times n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N}  \left(-(a_{Y_i}^T X_i + b_{Y_i} + \log\left(\sum_{j = 1}^{k} e^{a_j^TX_i + b}\right)\right)\)</p>

<p>pytorchì—ëŠ” $Ax + b$ì˜ ê²°ê³¼ë§Œ ë°›ì•„ë‚´ë©´ ì´ë¥¼ ê³„ì‚°í•´ì£¼ëŠ” í•¨ìˆ˜ê°€ ìˆìœ¼ë¯€ë¡œ, ëª¨ë¸ì€ $Ax + b$ë§Œ í•´ì£¼ë©´ ë©ë‹ˆë‹¤.<br>
ëŒ€ì‹  Loss functionì„ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ <code class="language-plaintext highlighter-rouge">lr</code> ì€ learning rate, $\alpha$ ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ìµœì í™” ìì²´ì—ëŠ” Stochastic Gradient Descentë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>    
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>   
</code></pre></div></div>

<p>ì´ì œ, ìš°ë¦¬ì—ê²Œ í•„ìš”í•œ ëª¨ë¸ì˜ í›ˆë ¨ ê³¼ì •ì€ ì´ë ‡ê²Œ ì§„í–‰ë©ë‹ˆë‹¤. Epochë¥¼ ë§ì´ ëŒë¦´ìˆ˜ë¡ ì •í™•í•´ì§€ê¸´ í•˜ì§€ë§Œ, íˆ¬ì…í•˜ëŠ” ì‹œê°„ ëŒ€ë¹„ ì–¼ë§Œí¼ì˜ íš¨ìœ¨ì´ ìˆëŠ”ì§€ëŠ” ìƒí™©ë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ ì ë‹¹íˆ íŒë‹¨í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.</p>

<p>ì›Œë‚™ ë‹¨ìˆœí•œ ëª¨ë¸ì´ë¼ í•™ìŠµí• ê²Œ ë§ì§€ ì•Šìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” epoch=2 (ì¦‰, ì „ì²´ ë°ì´í„°ë¥¼ ë‘ë°”í€´ ëŒë¦½ë‹ˆë‹¤) ë§Œ ëŒë¦¬ê² ìŠµë‹ˆë‹¤.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NUM_EPOCH</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_EPOCH</span><span class="p">)</span> <span class="p">:</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span> <span class="p">:</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<p>ì´ë¥¼ ëœ¯ì–´ë³´ë©´,</p>
<ul>
  <li>
<code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code> ë¡œ ê¸°ì¡´ MLP ëª¨ë¸ì— ë‚¨ì•„ìˆë˜ gradient ê°’ë“¤ì„ ë‹¤ ë‚ ë¦¬ê³ </li>
  <li>
<code class="language-plaintext highlighter-rouge">train_loss</code> ëŠ” í˜„ì¬ ì‹œì ì— ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ ì¶”ì¸¡ì„ í•´ë³´ê³  ê·¸ loss function ê°’ì„ í™•ì¸í•˜ê³ ,</li>
  <li>
<code class="language-plaintext highlighter-rouge">.backward()</code> ë¡œ í˜„ì¬ ì‹œì ì˜ gradientë¥¼ ê³„ì‚°í•˜ê³ </li>
  <li>
<code class="language-plaintext highlighter-rouge">optimizer.step()</code> ìœ¼ë¡œ ì‹¤ì œ optimization (ì—¬ê¸°ì„  SGD)ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.</li>
</ul>

<p>ê·¸ë ‡ë‹¤ë©´, ì´ ëª¨ë¸ì€ ì–¼ë§ˆë‚˜ ì •í™•í• ê¹Œìš”?</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">label</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="p">.</span><span class="n">eq</span><span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">)).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'''[Test set]</span><span class="se">\n</span><span class="s">Average loss: </span><span class="si">{</span><span class="n">test_loss</span> <span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, 
Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%)'''</span><span class="p">)</span>
</code></pre></div></div>
<p>ì´ ì½”ë“œëŠ” í…ŒìŠ¤íŠ¸ì…‹ì„ ëª¨ë‘ í•œë°”í€´ ëŒë¦¬ë©´ì„œ, test lossì˜ ê°’ê³¼ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.</p>

<p>ì´ˆê¸°í™” ìƒí™© ë“±ì— ë”°ë¼ ì¡°ê¸ˆ ë‹¬ë¼ì§ˆìˆ˜ëŠ” ìˆì„í…ë°, ì €ëŠ” 2ë²ˆì˜ epochë¡œ 92.11%ì˜ ì •í™•ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>

<h2 id="multi-layer-perceptron">Multi-Layer Perceptron</h2>
<p>PytorchëŠ” êµ‰ì¥íˆ ì“°ê¸° í¸í•œ ëª¨ë“ˆì¸ë°, ìœ„ ì½”ë“œì—ì„œ ì •ë§ <code class="language-plaintext highlighter-rouge">model</code>ë§Œ ë°”ê¾¸ë©´ ë°”ë¡œ MLPë¥¼ ì‚¬ìš©í•´ë³¼ìˆ˜ ìˆìŠµë‹ˆë‹¤. MLPë¥¼ ìˆ˜í–‰í•˜ë©´ì„œ ì ì  ê°œìˆ˜ê°€ ì¤„ì–´ë“¤ì–´ì•¼ í•˜ëŠ”ë°, ì—¬ê¸°ì„œëŠ” í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê·¸ëƒ¥ í¸ì˜ìƒ ì ì  ì¤„ì–´ë“œëŠ” ì´ìœ ê°’ì„ ëª‡ê°œ ì ì–´ë„£ê² ìŠµë‹ˆë‹¤.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,)</span> <span class="p">:</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nb">float</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>
<p>ì´ ëª¨ë¸ì€ activation functionìœ¼ë¡œ ReLUë¥¼ ì“°ëŠ” depth 4ì§œë¦¬ MLPì¸ë°, 784 -&gt; 256 -&gt; 128 -&gt; 64 -&gt; 10ìœ¼ë¡œ ë‹¨ê³„ì ìœ¼ë¡œ ê°œìˆ˜ë¥¼ ì¤„ì—¬ë‚˜ê°‘ë‹ˆë‹¤. ìˆœì„œëŒ€ë¡œ Linear-&gt;ReLU-&gt;â€¦-&gt;Linearë¡œ ëë‚©ë‹ˆë‹¤.</p>

<p>ìœ„ ì½”ë“œì—ì„œ <code class="language-plaintext highlighter-rouge">loss_function</code> ì •ì˜ë¶€í„°ëŠ” ê·¸ëŒ€ë¡œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤. ì €ëŠ” ë¡œì»¬ì—ì„œ ì •í™•ë„ê°€ 96% ì •ë„ ë‚˜ì˜¤ê³ , ì°¸ì„ì„±ì„ ê°–ê³  Epochë¥¼ 10ìœ¼ë¡œ ë°”ê¿¨ì„ ë•ŒëŠ” 98%ì˜ ì •í™•ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>

<p>Q. ì™œ 4ë‹¨ê³„ layerë¥¼ (3ë‹¨ê³„, 5ë‹¨ê³„ê°€ ì•„ë‹ˆë¼â€¦) ì“°ë‚˜ìš”?<br>
-&gt; ì¼ë°˜ì ìœ¼ë¡œ Layerê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ íŒŒë¼ë¯¸í„°ê°€ ë§ì•„ì ¸ì„œ training ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³  capacityê°€ ì»¤ì§‘ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, layerê°€ ì–•ìœ¼ë©´ non-linearityë¥¼ ì¶©ë¶„íˆ ì£¼ì§€ ëª»í•´ì„œ underfittingí•  ìš°ë ¤ê°€ ìˆìŠµë‹ˆë‹¤. 
ê·¸ë ‡ë‹¤ê³  í•´ì„œ ë¬¸ì œë¡œë¶€í„° ë°”ë¡œ ëª‡ Layerì§œë¦¬ MLPë¥¼ ì“¸ì§€ ê²°ì •í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. í•´ë³´ë‹ˆê¹Œ ì €ëŠ” 4 Layer ì •ë„ê°€ ê°€ì¥ ì ë‹¹í•´ ë³´ì˜€ìŠµë‹ˆë‹¤.</p>

  </article>

  
    <div id="disqus_thread"></div>
    <script>
        /**
         *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
        /*
        var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        */
        (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = 'https://gratus907-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by Disqus.</a>
</noscript>
  
  <a href="http://localhost:4000/deep-learning-study"> Back to : deep-learning-study</a><br>
  
</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    Â© Copyright 2021 Wonseok  Shin.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: December 17, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
