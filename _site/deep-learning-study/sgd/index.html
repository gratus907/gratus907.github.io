<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Gratus907's Study Note


  | [P] Stochastic Gradient Descent

</title>
<meta name="description" content="Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/deep-learning-study/sgd/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KX3EZM1ESL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-KX3EZM1ESL');
</script>



<!-- Panelbear Analytics - We respect your privacy -->
<script async src="https://cdn.panelbear.com/analytics.js?site=KX0fnophvY8"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: 'KX0fnophvY8' });
</script>


<script async src = "//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script >

    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [ ['$$', '$$'], ['\\[', '\\]'], ['\\(', '\\)']],
        packages: {'[+]': ['physics']}
      },
      loader: {
        load: ["input/tex", "output/chtml", '[tex]/physics']
      },
    };
  </script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  <p style="display: none;">$$
      \newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
      \newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
      \newcommand{\N}{\mathbb{N}}
      \newcommand{\R}{\mathbb{R}}
      \newcommand{\Z}{\mathbb{Z}}
      \newcommand{\Q}{\mathbb{Q}}
      \newcommand{\C}{\mathbb{C}}
      \renewcommand{\L}{\mathcal{L}}
      \newcommand{\x}{\times}
      \newcommand{\contra}{\scalebox{1.5}{$\lightning$}}
      \newcommand{\inner}[2]{\left\langle #1 , #2 \right\rangle}
      \newcommand{\st}{\text{ such that }}
      \newcommand{\for}{\text{ for }}
      \newcommand{\Setcond}[2]{ \left\{\, #1 \mid #2 \, \right\}}
      \newcommand{\setcond}[2]{\Setcond{#1}{#2}}
      \newcommand{\seq}[1]{ \left\langle #1 \right\rangle}
      \newcommand{\Set}[1]{ \left\{ #1 \right\}}
      \newcommand{\set}[1]{ \set{#1} }
      \newcommand{\sgn}{\text{sign}}
      \newcommand{\halfline}{\vspace{0.5em}}
      \newcommand{\diag}{\text{diag}}
  
      \newcommand{\legn}[2]{\left(\frac{#1}{#2}\right)} 
      \newcommand{\ord}{\text{ord}}
      \newcommand{\di}{\mathrel{|}} 
      \newcommand{\gen}[1] 
      \newcommand{\irr}{\mathrm{irr }}
      \renewcommand{\deg}{\mathrm{deg }}
      \newcommand{\nsgeq}{\trianglelefteq}
      \newcommand{\nsg}{\triangleleft}
      
      \newcommand{\argmin}{\mathrm{argmin}}
      \newcommand{\argmax}{\mathrm{argmax}}
      \newcommand{\minimize}{\mathrm{minimize}}
      \newcommand{\maximize}{\mathrm{maximize}}
      \newcommand{\subto}{\mathrm{subject\ to}}
      \newcommand{\DKL}[2]{D_{\mathrm{KL}}\left(#1 \di\di #2\right)}
      \newcommand{\ReLU}{\mathrm{ReLU}}
      
      \newcommand{\E}{\mathbb{E}}
      \newcommand{\expect}[1]{\E\left[#1\right]}
      \newcommand{\expectwith}[2]{\E_{#1}\left[#2\right]}
      \renewcommand{\P}{\mathbb{P}}
      \newcommand{\uniform}[2]{\mathrm{Uniform}\left(#1 \dots #2\right)}
      \newcommand{\gdist}[2]{\mathcal{N}\left(#1, #2\right)}
      $$</p>
  
  </head>

  <body class=" sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       Gratus907's Study Note
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              Home
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Posts
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/about-me/">
                About me
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/study-note/">
                Notes
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                ë¶„ë¥˜
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/ds-alg-note/">Algo / DS</a>
              
              
              
                <a class="dropdown-item" href="/advanced-algorithms/">Advanced Algo / DS</a>
              
              
              
                <a class="dropdown-item" href="/cs-adventure/">CS-Adventure</a>
              
              
              
                <a class="dropdown-item" href="/cp-rounds/">Competitive Programming</a>
              
              
              
                <a class="dropdown-item" href="/deep-learning-study/">Deep Learning Study</a>
              
              
              </div>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->
    
    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">[P] Stochastic Gradient Descent</h1>
    <p class="post-meta">September 24, 2021</p>
  </header>

  <article class="post-content">
    <a href="http://localhost:4000/deep-learning-study"> Back to : deep-learning-study</a><br>
    
    <div id="toc">
Contents
</div>
<ul id="markdown-toc">
  <li><a href="#stochastic-gradient-descent" id="markdown-toc-stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
  <li><a href="#batch-sgd--cyclic-sgd" id="markdown-toc-batch-sgd--cyclic-sgd">Batch SGD / Cyclic SGD</a></li>
  <li><a href="#sgd-convergence-theorem" id="markdown-toc-sgd-convergence-theorem">SGD Convergence Theorem</a></li>
</ul>
<hr>

<p><strong>ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ìˆ˜í•™ì  ê¸°ì´ˆ</strong> 2ê°• (9ì›” 7ì¼), 3ê°• (9ì›” 9ì¼) ì— ê¸°ë°˜í•©ë‹ˆë‹¤.</p>

<p>ì´ ë¬¸ì„œëŠ” $\LaTeX$ë¥¼ pandocìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‘ì„±í•˜ì˜€ê¸° ë•Œë¬¸ì—, ë ˆì´ì•„ì›ƒ ë“±ì´ ê¹”ë”í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–¸ì  ê°€ pdf ë²„ì „ì˜ ë…¸íŠ¸ë¥¼ ê³µê°œí•œë‹¤ë©´ ê·¸ìª½ì„ ì°¸ê³ í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<h2 id="stochastic-gradient-descent">Stochastic Gradient Descent</h2>

<p>MLì—ëŠ” ë§ì€ Finite sum optimizationì´ ìˆë‹¤. ìš°ë¦¬ëŠ”
$F(x) = \frac{1}{N} \sum_{i = 1}^{N} f_i(x)$ ë¥¼ ìµœì í™”í•˜ê³  ì‹¶ë‹¤.
ëŒ€í‘œì ìœ¼ë¡œ, Gradient Descentë¥¼ ì“¸ ìˆ˜ ìˆë‹¤. But, $N$ì´ ë§¤ìš° í¬ë©´ ì´
í•¨ìˆ˜ë¥¼ í•œë²ˆ ê³„ì‚°í•˜ëŠ” ì‹œê°„ì´ ë§¤ìš° ì˜¤ë˜ ê±¸ë¦°ë‹¤.</p>

<p>ìœ„ ì‹ì„, ì´ í•¨ìˆ˜ì˜ <strong>ê¸°ëŒ“ê°’</strong> ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤.
\(\underset{x \in \R^p}{\minimize}\ \E_I[f_I(x)], \ I \sim \uniform{1}{N}\)</p>

<p>ì´ëŸ° motivationì„ í†µí•´, Stochastic (Random) Gradient Descentë¥¼ ìƒê°í•œë‹¤.</p>

<p><strong>Algorithm (Stochastic Gradient Descent)</strong> <br>
ì„ì˜ì˜ ì‹œì‘ì  $x^0 \in \R^p$ ë¥¼ ì¡ê³ , ì ì ˆí•œ $\alpha_k &gt; 0$ ì— ëŒ€í•´
ë‹¤ìŒì„ ë°˜ë³µí•œë‹¤.
\(i(k) \sim \uniform{1}{N},\quad x^{k+1} = x^k - \alpha_k \nabla{f_{i(k)}(x^k)}\)</p>

<p><strong>ëŒ€ëµì˜ ì•„ì´ë””ì–´</strong> :<br>
GDì²˜ëŸ¼, Taylor expansioní•˜ê³  Stochasticì„ ê³ ë ¤í•˜ì—¬ Expectationì„ ì”Œìš´ë‹¤.</p>

<p>$x^k$ ê·¼ì²˜ì—ì„œ $F(x) = \frac{1}{N} \sum_{i = 1}^{N} f_i(x)$ë¥¼ í…Œì¼ëŸ¬
ì „ê°œí•˜ê³  $x^{k+1}$ ëŒ€ì…í•˜ë©´,
\(F(x^{k+1}) = F(x^k) - \alpha_k \nabla F(x^k)^T \nabla f_{i(k)}(x^k) + \order{\alpha_k^2}\)
ì´ì œ, ì–‘ìª½ì— $\E$ ë¥¼ ì”Œìš´ë‹¤.
\(\expect{F(x^{k+1})} = \expect{F(x^k)} - \alpha_k \expect{\nabla F(x^k)^T \nabla f_{i(k)}(x^k)} + \order{\alpha_k^2}\)
$\nabla F(x^k)^T$ ëŠ” ê¸°ëŒ“ê°’ì— ì˜í–¥ì´ ì—†ê³ , $\nabla f_{i(k)}(x^k)$ ì˜
ê¸°ëŒ“ê°’ì€ $\nabla F(x^k)$ ì´ë¯€ë¡œ,
\(\expect{F(x^{k+1})} = \expect{F(x^k)} - \alpha_k \norm{\nabla F(x^k)}^2 + \order{\alpha_k^2}\)
ì ë‹¹íˆ $\alpha_k$ë¥¼ ì¶©ë¶„íˆ ì‘ê²Œ ì¡ìœ¼ë©´, ê¸°ëŒ“ê°’ì´ ê°ì†Œí•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.</p>

<hr>

<ul>
  <li>
    <p>Stochastic Gradient Descentë„ ìˆ˜ë ´ì„±ì— ê´€í•œ ì •ë¦¬ë¥¼ ê¸°ìˆ í•  ìˆ˜
ìˆìœ¼ë‚˜, ì¦ëª…ì´ ë§¤ìš° Tediousí•˜ê³  ML ì„¸íŒ…ì—ì„œëŠ” ê·¸ë ‡ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šë‹¤.</p>
  </li>
  <li>ì§ì ‘ êµ¬í˜„í•´ì„œ í…ŒìŠ¤íŠ¸í•´ ë³´ë©´, ì´ˆë°˜ì— SGDê°€ GDë³´ë‹¤ ìˆ˜ë ´ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ,
Eventually GDì—ê²Œ ë”°ë¼ì¡íŒë‹¤.</li>
  <li>
    <p>ê·¸ëŸ¬ë‚˜, ìš°ë¦¬ëŠ” MLì„ ê³µë¶€í•˜ëŠ”ë° ìˆì–´ SGDë¥¼ Subroutineìœ¼ë¡œ ì“¸ ê²ƒì´ê³ , ì§§ì€ Training ì‹œê°„ì˜ í™˜ê²½ì—ì„œ SGDê°€ in practice GDë³´ë‹¤ ì˜ ìˆ˜ë ´í•œë‹¤.</p>
  </li>
  <li>Stochastic Gradient Descentì—ì„œ, $i(k)$ ìì²´ì˜ ì„±ì§ˆì€ ì „í˜€ í™œìš©í•˜ì§€ ì•Šì•˜ë‹¤.</li>
  <li>ì‹¤ì œë¡œ, SGDì˜ ìˆ˜ë ´ì„± ì¦ëª…ì—ì„œ ì¤‘ìš”í•œ ê²ƒì€, ë‹¤ìŒê³¼ ê°™ì€ Frameworkë©´ ì¶©ë¶„í•˜ê¸° ë•Œë¬¸.</li>
</ul>

<p><strong>Algorithm (Stochastic Gradient Descent)</strong> <br>
ì„ì˜ì˜ ì‹œì‘ì  $x^0 \in \R^p$ ë¥¼ ì¡ê³ , ì ì ˆí•œ $\alpha_k &gt; 0$ ì— ëŒ€í•´
ë‹¤ìŒì„ ë°˜ë³µí•œë‹¤.
\(i(k) \sim \uniform{1}{N},\quad x^{k+1} = x^k - \alpha_k g^k\) ì´ë•Œ,
$g^k$ ëŠ” Stochastic gradientë¡œ, $\nabla F(x^k)$ ì˜ Unbiased Estimator
ì´ë©´ - ì¦‰, ê¸°ëŒ“ê°’ì´ $\nabla F(x^k)$ ì´ë©´ ì¶©ë¶„í•˜ë‹¤.</p>

<h2 id="batch-sgd--cyclic-sgd">Batch SGD / Cyclic SGD</h2>
<ul>
  <li>ì˜ˆë¥¼ ë“¤ì–´, $g^k$ë¥¼ ê³ ë¥´ëŠ” ë°©ë²•ìœ¼ë¡œ Batch sampling with/without
Replacementë¥¼ ìƒê°í•  ìˆ˜ ìˆë‹¤.</li>
  <li>ì¦‰, $N$ê°œ ì¤‘ ì¼ë¶€ì¸ $B$ê°œë¥¼ ëœë¤í•˜ê²Œ ê³„ì†
ë½‘ì•„ì„œ, $\frac{1}{B}\sum_{b = 1}^{B} \nabla f_{i(k, b)}(x^k)$, ì¦‰
$B$ê°œì˜ batchì— ëŒ€í•œ gradientì˜ í‰ê· ì„ ì“°ëŠ” ê²ƒ.</li>
  <li>ì´ë•Œ, Batchë¥¼ ë½‘ì„ ë•Œ
ì¤‘ë³µì„ í—ˆìš©í•˜ëŠ”ì§€ ì—¬ë¶€ëŠ” ìƒê´€ ì—†ë‹¤ (ë‘˜ ë‹¤ Unbiased estimatorê°€ ë˜ê¸°
ë•Œë¬¸). ì¤‘ë³µì„ í—ˆìš©í•˜ê³  ì‹¶ìœ¼ë©´ randomí•œ $B$ê°œë¥¼ ë½‘ê³ , í—ˆìš©í•˜ê³  ì‹¶ì§€
ì•Šìœ¼ë©´ random permutationì˜ ì²« $B$ê°œë¥¼ ì“°ë©´ ëœë‹¤.</li>
</ul>

<p>íŠ¹íˆ, Batch ë°©ë²•ì˜ ê²½ìš°, GPUë¥¼ ì´ìš©í•œ Parallel ì—°ì‚°ì— ìœ ë¦¬í•˜ë‹¤ëŠ”
ì¶”ê°€ì ì¸ ì¥ì ì´ ìˆë‹¤. GPUì™€ ë³‘ë ¬ì²˜ë¦¬ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ê¸° ìœ„í•´, GPU
memoryì— ë“¤ì–´ê°€ëŠ” ìµœëŒ€ $B$ë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ìœ ë¦¬í•˜ë‹¤. Batch sizeëŠ”
noise ì •ë„ì— ë”°ë¼ ì„±ëŠ¥ì´ ë‹¬ë¼ì§€ëŠ”ë°, noiseê°€ í´ìˆ˜ë¡ large batchê°€
ìœ ë¦¬í•˜ë‹¤.</p>

<p>ê·¸ëŸ°ë°â€¦ì´ ì•Œê³ ë¦¬ì¦˜ì—ì„œ, ì›ë˜ ëœë¤í•˜ì§€ ì•Šì€ ê²ƒì„ ì–µì§€ë¡œ ëœë¤í•˜ê²Œ ë§Œë“¤ì–´ì„œ í’€ê³  ìˆëŠ” ê²ƒ ì•„ë‹Œê°€? Stochasticí•˜ê²Œ ë½‘ëŠ” ëŒ€ì‹ , ê·¸ëƒ¥ ìˆœì„œëŒ€ë¡œ ëŒë¦¬ë©´ì„œ ì“°ë©´ ì•ˆ ë˜ë‚˜?</p>

<p><strong>Algorithm : Cyclic SGD</strong><br>
ì„ì˜ì˜ ì‹œì‘ì  $x^0 \in \R^p$ ë¥¼ ì¡ê³ , ì ì ˆí•œ $\alpha &gt; 0$ ì— ëŒ€í•´ ë‹¤ìŒì„ ë°˜ë³µí•œë‹¤.
\(x^{k+1} = x^k - \alpha_k \nabla{f_{(k \text{ mod } N + 1)}(x^k)}\)</p>

<p>ì´ ë°©ë²•ì€ stochasticí•œ ë¶€ë¶„ì´ ì‚¬ì‹¤ ì—†ë‹¤. ì¥ë‹¨ì ì€...</p>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">(+)</code> í™•ì‹¤í•˜ê²Œ $N$ê°œì˜ ë°ì´í„°ë¥¼ $N$ë²ˆë§ˆë‹¤ í•œë²ˆì”© ì •í™•í•˜ê²Œ ì‚¬ìš©í•œë‹¤.</li>
  <li>
<code class="language-plaintext highlighter-rouge">(-)</code> SGDì˜ ìˆ˜ë ´ì„±ì— ëŒ€í•œ ì •ë¦¬ë¥¼ ì“¸ ìˆ˜ ì—†ë‹¤.</li>
  <li>
<code class="language-plaintext highlighter-rouge">(-)</code> ì¼ë°˜ SGDì— ë¹„í•´ Theoretically / Empirically, some caseì—ì„œëŠ” ì˜ ì‘ë™í•˜ì§€ ì•ŠìŒ.</li>
  <li>
<code class="language-plaintext highlighter-rouge">(-)</code> Deep Learningìœ¼ë¡œ ê°€ë©´, Neural networkê°€ ì´ ìˆœì„œ(cyclic order)ë¥¼ ê¸°ì–µí•˜ëŠ” ê²½í–¥ ë°œìƒ.</li>
</ul>

<p>íŠ¹íˆ ê¸°ì–µí•˜ëŠ” ê²½í–¥ì— ì˜í•œ overfittingì´ í° ì´ìŠˆì´ê¸° ë•Œë¬¸ì—, ì´ë¥¼
ë°©ì§€í•´ì•¼ í•œë‹¤. ì ë‹¹íˆ ì„ì–´ì£¼ë©´ ì–´ë–¨ê¹Œ?</p>

<p><strong>Algorithm : Shuffled Cyclic SGD</strong><br>
ì„ì˜ì˜ ì‹œì‘ì  $x^0 \in \R^p$ ë¥¼ ì¡ê³ , ì ì ˆí•œ $\alpha &gt; 0$ ì— ëŒ€í•´ ë‹¤ìŒì„
ë°˜ë³µí•œë‹¤.
\(x^{k+1} = x^k - \alpha \nabla{f_{\sigma^{(k/N)}(k \text{ mod } N + 1)}(x^k)}\)</p>

<p>ì¦‰, $N$ë²ˆì— í•œ ë²ˆì”©, ì¸ë±ìŠ¤ë“¤ì„ ëœë¤í•˜ê²Œ permutationí•´ë²„ë¦° ë‹¤ìŒ, ê·¸
ìˆœì„œë¡œ ë‹¤ìŒ $N$ë²ˆì˜ iterationì„ Cyclicí•˜ê²Œ ëŒë¦°ë‹¤. ì´ë ‡ê²Œ í•˜ë©´, ì •í™•í•˜ê²Œ
$N$ê°œì˜ ë°ì´í„°ë¥¼ í•œë²ˆì”© ì“´ë‹¤ëŠ” ì¥ì ì„ ì±™ê¸°ë©´ì„œë„, neural networkê°€
í•™ìŠµí•˜ëŠ” ì¼ì„ ë§‰ì„ ìˆ˜ ìˆë‹¤. ê¸°ì¡´ì—ëŠ” ê°•í•œ theoryê°€ ë³„ë¡œ ì—†ì—ˆì§€ë§Œ, recent
breakthroughë“¤ì´ ì´ë¥¼ ê°œì„ í•˜ê³  ìˆë‹¤.</p>

<p>ê·¸ëƒ¥ ì¼ë°˜ì ì¸ ì„¸íŒ…ì—ì„œëŠ”, <strong>Shuffled cyclic minibatch SGD without
replacement</strong> ë¥¼ ì“°ë©´ ë˜ê³ , <strong>GPUê°€ í—ˆë½í•˜ëŠ” ìµœëŒ€í•œ í° Batch size</strong>ë¥¼
ì¡ìœ¼ë©´ ëœë‹¤. Deep Learningì˜ ë§ì€ ê²½ìš°, ìˆ˜í•™ì ì¸ ë¶„ì„ì´ ì‹¤ì œ
performanceë¥¼ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ì§€ ëª»í•˜ëŠ” ê²½í–¥ì´ ìˆëŠ”ë°, empirically this
is best.</p>

<p>ì¼ë°˜ì ì¸ expectationìœ¼ë¡œ í‘œí˜„ëœ ìµœì í™” ë¬¸ì œ, ì˜ˆë¥¼ ë“¤ì–´ í™•ë¥ ë³€ìˆ˜
$\omega$ì— ëŒ€í•´ ì´ëŸ° ë¬¸ì œë“¤
\(\underset{x \in \R^p}{\minimize}\ \E_\omega[f_\omega(x)]\) ì˜ ê²½ìš°,
ë˜‘ê°™ì´ SGDë¡œ í’€ ìˆ˜ ìˆë‹¤. GDë¡œë„ í•  ìˆ˜ëŠ” ìˆì§€ë§Œ,
ì¼ë°˜ì ìœ¼ë¡œ â€˜gradientì˜ ê¸°ëŒ“ê°’â€™ ì„ êµ¬í•˜ê¸°ê°€ ì–´ë µê¸° ë•Œë¬¸ì—...</p>

<p>ì°¸ê³  : Optimization / MLì—ì„œ, ëŒ€ì¶© â€˜í•œë°”í€´â€™ ë¥¼ <strong>Epoch</strong> ë¼ê³  ë¶€ë¥¸ë‹¤. ëŒ€ì¶©
ë°ì´í„°ë“¤ì„ í•œë°”í€´ ëŒë©´ ëœë‹¤. Gradient descentë©´ í•œë²ˆ = 1 epoch, SGDë©´
$N$ë²ˆ, Batched SGDë©´ $N / B$ ë²ˆ ì •ë„.</p>

<h2 id="sgd-convergence-theorem">SGD Convergence Theorem</h2>

<p>ìƒì„¸í•˜ê²Œ ë‹¤ë£¨ì–´ì•¼ í•  ë‚´ìš©ì€ ì•„ë‹ˆì§€ë§Œ, ì•ì„œ ê³µë¶€í•œ Lipschitz Gradient Lemma ë“±ì„ ì´ìš©í•´ì„œ ë¹„ìŠ·í•œ ì¦ëª…ì„ ì“¸ ìˆ˜ ìˆë‹¤.</p>

<p>$F : \R^n \to \R$ ì´ ë¯¸ë¶„ê°€ëŠ¥í•˜ê³ , $\nabla F$ ê°€ $L$-Lipschitz ì—°ì†ì´ë©°,
$F$ê°€ $-\infty$ê°€ ì•„ë‹Œ ìµœì†Œê°’ì„ ê°€ì§€ë©°, $g^k$ê°€ ë‹¤ìŒ ì¡°ê±´
\(\E[g^k \di x^k] = \nabla F(x^k), \quad \quad \expect{\norm{g^k - \nabla F(x^k)}^2 \di x^k} \leq \sigma^2\)
ì„ ë§Œì¡±í•  ë•Œ, ì¦‰ $g^k$ ê°€ Gradientì— ëŒ€í•œ Unbiased estimatorì´ê³  ê·¸
ë¶„ì‚°ì´ $\sigma^2$ ì´í•˜ì¼ ë•Œ, ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤.
\(\frac{1}{M}\sum_{k = 0}^{M-1} \expect{\norm{\nabla F(x^k)}^2} \leq \frac{1}{\sqrt{M}}\left(2L(F(x^0) - F^*) + \sigma^2\right)\)</p>

<p>ì¦‰, Gradientì˜ í¬ê¸°ì˜ í‰ê· ì´ $M$ë²ˆì˜ iterationì— ì˜í•´
$\order{\frac{1}{\sqrt{M}}}$ë¡œ ê°ì†Œí•œë‹¤.</p>

<p><strong><em>Proof.</em></strong> ë¨¼ì €, Lipschitz Gradient Lemmaë¥¼
$x = x^k, \delta = -\alpha g^k$ì— ëŒ€í•´ ì“°ë©´,
\(F(x^{k+1}) \leq F(x^k) -\alpha \nabla F(x^k)^T g^k + \frac{\alpha^2L}{2}\norm{g^k}^2\)
$x^k$ ê°€ ì´ë¯¸ ì£¼ì–´ì¡Œì„ ë•Œì˜ Conditional expectationì„ ì“´ë‹¤.
\(\expect{F(x^{k+1}) \di x^k} \leq F(x^k) - \alpha \norm{\nabla F(x^k)}^2 + \frac{\alpha^2 L}{2}\left(\norm{\nabla F(x^k)}^2 + \sigma^2\right)\)
ì´ì œ ì´ë¥¼ ë‹¤ì‹œ Total expectationì„ ì·¨í•˜ë©´,
\(\expect{F(x^{k+1})} \leq \expect{F(x^k)} - \alpha\left(1 - \frac{\alpha L}{2}\right) \expect{\nabla F(x^k)} + \frac{\alpha^2 \sigma^2 L}{2}\)
ì´ë¥¼ $k = 0 \dots M-1$ì— ëŒ€í•´ ì–‘ë³€ì„ ë”í•˜ì—¬
\(\alpha\left(1 - \frac{\alpha L}{2}\right) \sum_{k = 1}^{M-1}\expect{\nabla F(x^k)} \leq (F(x^0) - F^*) + \expect{F(x^k) - F^*} + \frac{\alpha^2 \sigma^2 L}{2}\)
ë§ˆì§€ë§‰ìœ¼ë¡œ, $\alpha = \frac{1}{L \sqrt{K}}$ ë¥¼ ì·¨í•˜ì—¬ ì£¼ì–´ì§„ ì‹ì„
ì–»ëŠ”ë‹¤.Â â—»</p>

  </article>

  
    <div id="disqus_thread"></div>
    <script>
        /**
         *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
        /*
        var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        */
        (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = 'https://gratus907-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by Disqus.</a>
</noscript>
  
  <a href="http://localhost:4000/deep-learning-study"> Back to : deep-learning-study</a><br>
  
</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    Â© Copyright 2021 Wonseok  Shin.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: November 03, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
