<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-25T19:38:49+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
</subtitle><entry><title type="html">CNN Architecture - AlexNet (2012)</title><link href="http://localhost:4000/deep-learning-study/AlexNet/" rel="alternate" type="text/html" title="CNN Architecture - AlexNet (2012)" /><published>2021-11-25T00:00:00+09:00</published><updated>2021-11-25T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/AlexNet</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/AlexNet/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#architecture&quot; id=&quot;markdown-toc-architecture&quot;&gt;Architecture&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#2-gpu-training&quot; id=&quot;markdown-toc-2-gpu-training&quot;&gt;2-GPU Training&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#usage-of-relu&quot; id=&quot;markdown-toc-usage-of-relu&quot;&gt;Usage of ReLU&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#local-response-normalization&quot; id=&quot;markdown-toc-local-response-normalization&quot;&gt;Local Response Normalization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#overlapping-pooling&quot; id=&quot;markdown-toc-overlapping-pooling&quot;&gt;Overlapping Pooling&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#training&quot; id=&quot;markdown-toc-training&quot;&gt;Training&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#regularization-techniques&quot; id=&quot;markdown-toc-regularization-techniques&quot;&gt;Regularization Techniques&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#optimization&quot; id=&quot;markdown-toc-optimization&quot;&gt;Optimization&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#code&quot; id=&quot;markdown-toc-code&quot;&gt;Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;AlexNet은 2012년 Imagenet challenge를 큰 격차로 우승하면서, image classification task를 통해 Deep neural network &amp;amp; GPU-computing의 시대를 연 모델이라는 평가를 받는 그런 아키텍쳐입니다. 이번 포스팅에서는 그런 AlexNet의 원본 논문을 따라가면서, 메인 아이디어들에 대해 살펴봅니다.&lt;/p&gt;

&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;../../images/8190f2b2db0f7eb370af157be64544adbe4c13e88488ef86e8d2bf9a60d90be2.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기본적으로 AlexNet의 구조는 LeNet과 많이 다르지 않습니다. 보다 큰 이미지를 처리하기 위해 좀더 깊어진 구조라고 생각할 수 있는데요. Convolution layer 5개와 Fully connected layer 2개로 구성되어 있습니다. LeNet에서 본것처럼 Convolution layer들이 주변을 보면서 feature를 추출하고, 그 추출한 특징들을 마지막 linear layer에서 어떻게 합칠지를 고민해서 하나의 결과를 낸다고 생각할 수 있겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;2-gpu-training&quot;&gt;2-GPU Training&lt;/h3&gt;
&lt;p&gt;AlexNet은 몇가지 특이한 점이 있는데, 눈에 보이는 가장 큰 특징 중 하나는 위 그림에서 보듯 네트워크 전체를 두개로 나눠서 구현해놨다는 점입니다. 이는 당시 (2012) GPU 메모리가 3GB정도로 현재에 비해 부족했기 때문에 GPU 2개에 네트워크를 반씩 나눠서 돌리면서, 필요한 때만 서로간에 communicate하도록 한 것인데요. 지금에 와서는 GPU의 성능이 비약적으로 향상됨에 따라 굳이 이렇게 두개로 나누지 않아도 충분히 구현할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;usage-of-relu&quot;&gt;Usage of ReLU&lt;/h3&gt;
&lt;p&gt;LeNet에서도 그렇고, 이전까지의 많은 Neural network들은 activation function으로 $\tanh$ 나 sigmoid (어차피 거의 비슷하므로 sigmoid로 통칭하겠습니다) 같은 smooth한 함수를 사용했습니다. 그러나 AlexNet에서는 ReLU를 사용하면 훨씬 빠르게 training이 가능함을 주장하고 있으며, 이를 실험을 통해 확인하였습니다. 이부분에 대해서는 다양한 이야기와 생각해볼 이슈들이 있는데, ReLU는 계산 자체가 빠르게 가능한데다 양쪽에서 vanishing gradient 문제가 발생하는 sigmoid에 비해 이런 문제들이 덜하다는 장점을 직관적으로 생각해 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;AlexNet 논문에서는 이를 non-saturating이라고 부르고 있으며, 이후 많은 논문에서도 ReLU를 사용하여 이러한 이점을 얻고자 하고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;local-response-normalization&quot;&gt;Local Response Normalization&lt;/h3&gt;
&lt;p&gt;Sigmoid의 경우 각 뉴런의 입력이 0 주위로 모아져야 learning의 효율이 발휘되기 때문에 (끝쪽으로 갈수록 미분계수가 0에 가까워서 아무 일도 일어나지 않음), 많은 네트워크들이 input normalization을 통해 이를 맞춰주려고 했습니다. ReLU는 0 이하만 아니라면 입력값에 따라 미분계수가 줄어들거나 하지는 않으므로 이게 꼭 필요하지는 않지만, AlexNet 논문에서는 Local normalization이라는 방법을 적용할 때 효율이 좋았다고 합니다. 다만, 이 방법은 이후 Batch normalization 등 다양한 방법들이 제시되고 이러한 방법들의 효율이 더욱 우수함이 밝혀짐에 따라 이후의 연구에서 더이상 계승되지 않았기 때문에 자세히 다루지는 않겠습니다.&lt;/p&gt;

&lt;p&gt;간단하게만 말하자면, convolution layer 한번이 필터를 여러개 쓰는 상황에서 적용하는 normalization입니다. 예를 들어 보자면 총 96개의 필터 (커널) 을 쓰는 상황에서 뭐 17번 필터의 결과값이 있을텐데, 이 값을 13번, 14번, …, 21번까지의 필터의 결과값을 이용하여 normalize하는 것입니다 (좌우로 4개씩 쓰는건 그냥 임의로 정한 값입니다) 이 방법은 실제 뇌에서의 신경생리학에 있어서 측면 억제 (lateral inhibition) 로부터 motivation을 얻은 방법이라고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;overlapping-pooling&quot;&gt;Overlapping Pooling&lt;/h3&gt;
&lt;p&gt;AlexNet에서는 일부 pooling을 서로 살짝 겹치게 수행하는데, 이 방법을 통해 overfitting을 크게 줄일 수 있다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;
&lt;h3 id=&quot;regularization-techniques&quot;&gt;Regularization Techniques&lt;/h3&gt;
&lt;p&gt;Regularization에 사용되는 여러 방법들에 대해서는 따로 포스팅했습니다. &lt;a href=&quot;/deep-learning-study/regularization&quot;&gt;Regularization methods&lt;/a&gt;을 참고해주세요 :)&lt;/p&gt;

&lt;p&gt;AlexNet은 이전 LeNet에 비해 훨씬 더 큰 모델로, 파라미터의 개수가 훨씬 더 많기 때문에 overfitting의 우려가 큽니다. 이에 대응하기 위해, LeNet과 비교해 보면 훨씬 Regularization에 공을 들이는 것을 알 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;2012년 당시에는 최신 테크닉이었던 (그러나, 이후에는 Batch normalization등의 활용으로 인해 그 효용이 많이 줄어든) dropout을 적용합니다. 구체적으로 fully-connected layer 중 앞 두 칸에 $p = 0.5$입니다.&lt;/li&gt;
  &lt;li&gt;SGD에 Weight decay 0.0005를 적용합니다. 논문에서는 그 이유를 명확하게 밝히고 있지는 않으나, 단순히 regularization일 뿐 아니라 실제로 training에 반드시 필요하다고 주장하고 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;optimization&quot;&gt;Optimization&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SGD with Momentum 0.9, weight decay 0.0005.&lt;/li&gt;
  &lt;li&gt;Learning rate는 0.01로 시작해서, loss가 줄어들지 않는 것 같아 보일때마다 1/10으로 줄이는 방법을 사용했습니다.&lt;/li&gt;
  &lt;li&gt;“Adjusted Manually”…&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;/deep-learning-study/alexnet-cifar10&quot;&gt;AlexNet으로 CIFAR10 풀어보기&lt;/a&gt; 로 이어집니다&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">Pytorch-Cifar10</title><link href="http://localhost:4000/deep-learning-study/pytorch-cifar10/" rel="alternate" type="text/html" title="Pytorch-Cifar10" /><published>2021-11-25T00:00:00+09:00</published><updated>2021-11-25T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/pytorch-cifar10</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/pytorch-cifar10/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data&quot; id=&quot;markdown-toc-data&quot;&gt;Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#models&quot; id=&quot;markdown-toc-models&quot;&gt;Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;ImageNet Challenge를 따라가며, CNN의 가장 큰 태스크중 하나였던 &lt;strong&gt;이미지 분류&lt;/strong&gt;에 사용되는 모델들의 구현을 공부합니다.&lt;/p&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;
&lt;p&gt;CIFAR10은 32 x 32의 매우 작은 이미지 6만개로 구성된 데이터셋으로, 이미지 분류에서 MNIST보다는 어렵고 Imagenet보다는 쉬운, 적당한 연습용 데이터셋으로 생각할 수 있습니다. 각 이미지는 10개 중 하나의 클래스로 라벨링이 되어있습니다.&lt;/p&gt;

&lt;p&gt;여기서는 5만개를 training에, 1만개를 test에 사용할 것입니다.&lt;/p&gt;

&lt;p&gt;Data augmentation은 다음과 같이 수행합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;가로세로 4만큼의 패딩&lt;/li&gt;
  &lt;li&gt;Random crop (32 by 32). Padding된 다음 자르는거라 이미지 위치가 정가운데가 아니게 만드는 효과가 있습니다.&lt;/li&gt;
  &lt;li&gt;Random flip&lt;/li&gt;
  &lt;li&gt;Normalization (Imagenet weight)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;models&quot;&gt;Models&lt;/h2&gt;
&lt;p&gt;코드는 &lt;a href=&quot;https://github.com/gratus907/Pytorch-Cifar10&quot;&gt;Github repository&lt;/a&gt; 에 업로드됩니다.&lt;/p&gt;

&lt;style&gt;
table th:first-of-type {
    width: 15%;
}
table th:nth-of-type(2) {
    width: 50%;
}
table th:nth-of-type(3) {
    width: 15%;
}
table {
    width : 80%;
}
table td, table th {
    font-weight : 500;
}
&lt;/style&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Model Name&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Post Link&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;LeNet&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;71.95%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;AlexNet&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;/deep-learning-study/AlexNet/&quot;&gt;AlexNet : Explained&lt;/a&gt; &lt;br /&gt; &lt;a href=&quot;/deep-leanrning-study/AlexNet-Cifar10&quot;&gt;AlexNet on Cifar10&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">논문읽기 : All Pairs Almost Shortest Path</title><link href="http://localhost:4000/cs-adventure/APASP/" rel="alternate" type="text/html" title="논문읽기 : All Pairs Almost Shortest Path" /><published>2021-11-22T00:00:00+09:00</published><updated>2021-11-22T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/APASP</id><content type="html" xml:base="http://localhost:4000/cs-adventure/APASP/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-ideas&quot; id=&quot;markdown-toc-key-ideas&quot;&gt;Key ideas&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#at-a-glance&quot; id=&quot;markdown-toc-at-a-glance&quot;&gt;At a glance&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dominating-set&quot; id=&quot;markdown-toc-dominating-set&quot;&gt;Dominating Set&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#on32m12-log-n-complexity-2-error&quot; id=&quot;markdown-toc-on32m12-log-n-complexity-2-error&quot;&gt;$O(n^{3/2}m^{1/2} \log n)$ complexity, 2-error&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#on73-log2-n-complexity-2-error&quot; id=&quot;markdown-toc-on73-log2-n-complexity-2-error&quot;&gt;$O(n^{7/3} \log^2 n)$ complexity, 2-error&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#further--time-accuracy-tradeoff&quot; id=&quot;markdown-toc-further--time-accuracy-tradeoff&quot;&gt;Further : Time-Accuracy Tradeoff&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thoughts&quot; id=&quot;markdown-toc-thoughts&quot;&gt;Thoughts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이번에 공부해볼 논문은 &lt;strong&gt;All Pairs Almost Shortest Path&lt;/strong&gt; 입니다.&lt;/p&gt;

&lt;p&gt;D. Dor, S. Halperin and U. Zwick, “All pairs almost shortest paths,” Proceedings of 37th Conference on Foundations of Computer Science, 1996, pp. 452-461, doi: 10.1109/SFCS.1996.548504.&lt;/p&gt;

&lt;p&gt;1996년도 논문으로, 이후에도 많은 논문들이 이 논문에서 제시한 bound를 더 내리는 등 더 contribution이 있지만, 아이디어가 흥미롭고 이후 논문들의 기반이 되는 연구입니다.&lt;/p&gt;

&lt;p&gt;연도에 대해 언급하는 이후는 이후 25년간 알고리즘 분야의 발전으로 현재에는 다른 문제들의 복잡도가 약간씩 달라졌기 때문입니다.&lt;/p&gt;

&lt;p&gt;그래프 문제에서 흔히 그렇듯, $G = (V, E)$에 대해 $\abs{V} = n$, $\abs{E} = m$으로 쓰되, $O(V)$ 와 같이 notation을 abuse하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;All Pairs Shortest Path (이하 APSP) 란, 단순하게 어떤 그래프 $G = (V, E)$ 가 주어졌을 때, 각 vertex에서 다른 vertex로 가는 최단 경로의 길이를 모두 알아내는 문제입니다. 당연하게도, 실용적으로 많은 쓰임이 있습니다.&lt;/p&gt;

&lt;p&gt;우리는 우선 논문을 따라, Undirected의 경우만 고려합니다. 이때 경로의 길이는 지나가는 edge의 개수가 될 것입니다.&lt;/p&gt;

&lt;p&gt;다음 세 가지 알고리즘이 가장 먼저 고려할 만 합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Floyd-Warshal Algorithm : $O(V^3)$ 시간에 APSP를 해결하는 알고리즘입니다. 구현이 매우 쉽고, 간단한 Dynamic programming의 원리를 따르기 때문에 이해하기 쉽습니다.&lt;/li&gt;
  &lt;li&gt;Dijkstra (or any SSSP) : 다익스트라 알고리즘은 한 정점으로부터 다른 모든 정점까지의 거리를 찾는 Single Source Shortest Path (이하 SSSP) 문제를 $O(E + V \log V)$ 또는 $O(E \log V)$ 시간에 해결합니다. (Fibonacci heap의 사용 여부에 따라 다름) 자명하게, 모든 정점에서 출발하는 각 SSSP를 해결하면 되기 때문에 우리는 $O(VE + V^2 \log V)$ 정도 시간에는 APSP를 해결할 수 있습니다. 이 방법은 sparse graph에 대해서는 매우 빠르지만, dense graph에 대해서는 $E = O(V^2)$ 까지 가능하기 때문에 $O(V^3)$ 입니다.&lt;/li&gt;
  &lt;li&gt;Matrix Multiplication : Floyd-Warshall의 inner loop이 행렬곱셈이랑 비슷하게 생겼음을 활용합니다. 행렬곱셈과 거의 비슷한 알고리즘을 이용하면, Adjacency matrix $A$를 repeated squaring하여 이 문제를 $O(V^3 \log V)$ 에 풀 수 있습니다. 더 느려 보이는 이 방법을 언급하는 이유는, 행렬곱셈에 쓰는 빠른 알고리즘들 중 일부가&lt;sup id=&quot;fnref:matmul&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:matmul&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 이 ‘유사-행렬곱셈’에도 똑같이 적용가능하기 때문입니다. 스트라센을 쓰면 $O(V^{2.807} \log V)$ 이 되고 이는 위 두 방법보다 worst-case에 더 빠릅니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 논문에서는, “약간의 오차를 허용하면” 이보다 빠른 알고리즘이 존재함을 보입니다. 정확히는, 모든 정점쌍 $(v_i, v_j)$에 대해, $d(v_i, v_j) + 2$ 를 넘지 않는 값을 반환하는 알고리즘을 논의하고, 이를 확장하여 $k$만큼의 오차를 허용하되 그만큼 빨라지는 알고리즘을 논의합니다.&lt;/p&gt;

&lt;h2 id=&quot;key-ideas&quot;&gt;Key ideas&lt;/h2&gt;
&lt;h3 id=&quot;at-a-glance&quot;&gt;At a glance&lt;/h3&gt;
&lt;p&gt;이 알고리즘의 큰 아이디어는 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Dijkstra 알고리즘은 sparse graph에 대해 &lt;strong&gt;꽤&lt;/strong&gt; 빠릅니다.&lt;/li&gt;
  &lt;li&gt;그래프의 성질을 &lt;strong&gt;거의&lt;/strong&gt; 보존하면서 원래의 그래프보다 sparse한 auxillary graph 위에서 Dijkstra를 돌리고 싶습니다.&lt;/li&gt;
  &lt;li&gt;Unweighted graph에 대해서는 특히, dijkstra를 일반적인 BFS로 대체할 수 있습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;dominating-set&quot;&gt;Dominating Set&lt;/h3&gt;
&lt;p&gt;그래프 $(V, E)$에서, 어떤 정점의 부분집합 $S$가 다른 부분집합 $T$를 dominate 한다는 것은, $T$의 모든 vertex가 $S$의 vertex중 하나 이상과 edge로 연결되어 있는 것으로 정의합니다. 즉, 아래 그림에서 빨간색으로 색칠된 vertex는 그래프 전체를 dominate합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/82987572ed763cc4b5c4051dafdd2f09f351a476aeca2d83fdbf6ca5632322ea.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적인 그래프에 대해 minimal dominating set을 찾는 것은 매우 잘 알려진 NP-Hard 문제입니다. 그러나, 우리는 좀 특수한 경우만 논의합니다. 구체적으로, 어떤 parameter $s$에 대해, 다음을 해결합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dominate(G, s)&lt;/strong&gt; : $G$에서, degree가 $s$이상인 정점들을 모은 부분집합을 dominate하는 적당히 작은 dominating set을 찾는다.&lt;/p&gt;

&lt;p&gt;여기서 &lt;strong&gt;적당히 작은&lt;/strong&gt; 이란, $O\left(\frac{n \log n}{s}\right)$를 목표로 합니다. 이를 위해 다음의 그리디가 잘 알려져 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;각 vertex에 대해 neighbor set을 생각하면, dominating set을 찾는 것은 set cover를 찾는 것과 같은 문제입니다.&lt;/li&gt;
  &lt;li&gt;각 집합 $S_i$의 원소는 $\Set{1, \cdots, n}$ 범위 내에 있고, 전체 원소의 합은 $2m$개 입니다.&lt;/li&gt;
  &lt;li&gt;Greedy 알고리즘을 생각합니다. 각 스텝마다, ‘현재까지 cover되지 않은 가장 많은 element를 새로 cover하는’ 집합을 택합니다.&lt;/li&gt;
  &lt;li&gt;이 알고리즘은 잘 생각해보면 $m$에 대해 선형으로 구현가능합니다.
    &lt;ul&gt;
      &lt;li&gt;각 $x \in \Set{1, \cdots, n}$에 대해, $x$를 포함하는 모든 집합의 리스트 $L$ 를 관리하고, 동시에 현재 남은 covering power (현재 uncovered인 vertex 개수) 가 $i$인 집합의 리스트 $A[i]$를 관리합니다. 이때 각 원소의 remaining covering power를 $P[i]$라고 하겠습니다.&lt;/li&gt;
      &lt;li&gt;식으로 쓰면 복잡해지므로, pseudocode를 이용해서 표현해 보겠습니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cur = maximum of |S| among sets
while cur &amp;gt; 0:
    if A[cur] empty : cur -= 1, continue
    X = choose one with maximum P
    for t in X:
        if t is uncovered:
            mark t as covered
            for each Y containing t:
                remove Y from A[P[Y]]
                add Y to A[P[Y]-1]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시간 복잡도 증명 (위 알고리즘이 $O(\sum \abs{S})$) 임을 증명)
    &lt;ul&gt;
      &lt;li&gt;A를 관리하는 - 즉, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Y&lt;/code&gt;를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A[P[Y]]&lt;/code&gt;에서 꺼내서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A[P[Y]-1]&lt;/code&gt; 로 옮기는 decrease 연산이 $O(1)$에 시행가능하다면, 각 집합이 모두 그 크기만큼 decrease되어야 하므로 전체 복잡도는 각 집합의 원소의 개수의 합입니다. Bucket Queue 같은 자료구조를 이용하면 이게 가능함이 알려져 있습니다. (CLRS, 35-2-3).&lt;/li&gt;
      &lt;li&gt;그런데, 각 vertex의 neighbor 개수의 합은 결국 edge를 두번씩 센 것이므로 $2m$ 입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$\log$ approximation
    &lt;ul&gt;
      &lt;li&gt;먼저 이 알고리즘이 얼마나 좋은 approximation을 제공하는지 생각해 봅니다. Optimal solution이 $k$개의 부분집합을 사용한다고 가정합니다. 전체 cover할 원소가 $n = n_0$개이고, 집합을 하나씩 택한후 각 step에서 “남은 cover해야할 원소의 수” 를 $n_i$라 합시다.&lt;/li&gt;
      &lt;li&gt;비둘기집의 원리에 따라, 어떤 집합은 $n / k$개보다 많은 원소를 cover해야만 합니다. WLOG, 이를 $S_1$로 택하면 $n_1 \leq (n - n/k) = n\left(1-\frac{1}{k}\right)$ 입니다.&lt;/li&gt;
      &lt;li&gt;다시 비둘기집의 원리에 따라, $n_1/(k-1)$ 개보다 많은 원소를 cover하는 집합이 존재해야 하고, 
\(n_2 \leq n_1\left(1-\frac{1}{k}\right)\left(1-\frac{1}{k-1}\right)\leq n\left(1-\frac{1}{k}\right)^2\)&lt;/li&gt;
      &lt;li&gt;Greedy set cover의 결과가 $u$개의 집합을 쓴다면, $u$번을 반복하여, $n_u \leq n\left(1-\frac{1}{k}\right)^u &amp;lt; 1$
이를 다시 정리하여 다음을 얻습니다. 
\(\left(1-\frac{1}{k}\right)^{k \cdot u/k} &amp;lt; \frac{1}{n}\)
$(1-x)^{1/x} \leq 1/e$ 이므로, 이를 잘 정리하면 $u &amp;lt; k \log n$을 얻습니다.&lt;/li&gt;
      &lt;li&gt;즉, Greedy set cover의 결과는 optimal결과보다 $\log n$배 이상 나쁘지 않습니다!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;다만 위 알고리즘은 전체 graph의 dominating set을 제공합니다. 따라서, dummy vertex $s$개를 생성한 다음 degree가 $s$ 미만인 모든 vertex들에 대해 이들을 dummy vertex에 연결해 버리면 전체 edge는 최대 $ns$개 증가하고, 모든 vertex가 $s$이상의 degree를 가집니다. dummy vertex들은 어차피 high-degree vertex와는 연결되지 않으므로, dominating set에서 이를 마지막에 제거해도 됩니다. 이렇게 하면…&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dominate(G, s)&lt;/strong&gt; 의 결과값은 $O\left(\frac{n \log n}{s}\right)$개 이하의 dominating set을 찾아주고, 그 수행시간은 $O(m + ns)$ 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;on32m12-log-n-complexity-2-error&quot;&gt;$O(n^{3/2}m^{1/2} \log n)$ complexity, 2-error&lt;/h3&gt;
&lt;p&gt;이 알고리즘은 Aingworth et al. &lt;sup id=&quot;fnref:aingworth&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:aingworth&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 에서 제시된, $\tilde{O}(n^{5/2})$ 알고리즘을 약간 개선한 알고리즘입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$s = (m / n)^{1/2}$ 라 하고, degree가 $s$ 이상인 vertex 집합 $V_1$ 과 미만인 집합 $V_2$로 $V$를 나눕니다.&lt;/li&gt;
  &lt;li&gt;Low-degree vertex를 touch하는 edge의 집합을 $E_2$라 합시다. 이때, 이들의 개수는 $ns$개 이하입니다. (Low degree인 정점 최대 $V$개, 각각의 degree 최대 $s$)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dominate(G, s)&lt;/strong&gt; 를 돌립니다. 이 집합은 $O((n \log n) / s)$ 개 이하이므로, $O((n^{3/2} \log n) / m^{1/2})$ 개 이하의 정점으로 구성된 집합입니다. 또한, dominating set $D$를 찾는 과정에서, $V_1$개의 edge를 이용하여 $V_1$의 각 정점을 $D$의 정점에 매달 수 있습니다. 이 $V_1$개의 edge집합 (편의상, dominating edge라 하겠습니다) $E^*$을 찾습니다.&lt;/li&gt;
  &lt;li&gt;이제, $u \in D$에 대해, BFS를 이용해 최단경로를 그냥 찾습니다. BFS는 한번에 $O(m)$ 시간이 걸리므로 (connected graph이므로 $m \geq n$), 이부분의 수행시간은 $O(\abs{D}m) = O(m^{1/2}n^{3/2}\log n)$ 입니다.&lt;/li&gt;
  &lt;li&gt;$u \in V-D$ 에 대해, 다음과 같이 weighted graph를 만들어 다익스트라를 돌립니다.
    &lt;ul&gt;
      &lt;li&gt;각 $u$에 대해, $G_2(u)$를 만듭니다. 이때, $G_2(u)$의 정점은 $V$이고, edge는 $E^*$ 와 $E_2$에 있는 edge들을 모두 취한 다음, 각 $v \in D$에 대해 $(u, v)$ edge가 $\delta(u, v)$ weight을 갖도록 만듭니다.&lt;/li&gt;
      &lt;li&gt;$\delta(u, v)$는 앞선 BFS, 구체적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BFS(v)&lt;/code&gt;에서 구한 값이므로 &lt;strong&gt;정확한 최단거리값&lt;/strong&gt; 입니다.&lt;/li&gt;
      &lt;li&gt;이때, $\abs{E^*} = V_1 = O(n)$, $\abs{E_2} = O(ns) = O(n^{1/2}m^{1/2})$, $\abs{\Set{u} \times D} = \abs{D}  = O((n^{3/2} \log n) / m^{1/2})$ 입니다.&lt;/li&gt;
      &lt;li&gt;이 그래프 위에서, 다익스트라 알고리즘의 수행시간은 $O(n + n^{1/2}m^{1/2} + (n^{3/2} \log n) / m^{1/2})$ 개의 간선을 가진 그래프에서 돌리는 다익스트라입니다. 이 Edge set의 크기는 $O(m^{1/2}n^{1/2} \log n)$ 이하입니다. 다시, 다익스트라는 최대 $\abs{V-D} \leq n$ 번 시행되므로 모두 합하면 이쪽도 $O(m^{1/2}n^{3/2} \log n)$ 이 될 것입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;따라서 전체 알고리즘은 $O(m^{1/2}n^{3/2} \log n)$ 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제, 이 알고리즘이 최대 2 이하의 오차를 가짐을 보입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;정점쌍 $(u, v)$에 대해 $u \to v$의 최단경로가 적어도 하나 이상의 High-degree 정점을 지난다면:
    &lt;ul&gt;
      &lt;li&gt;마지막으로 지나는 high-점을 $w$라 합시다. 이제, $w \to v$의 최단경로는 모두 low-degree 정점만으로 구성되어 있고, 이는 다시 $G_2(u)$ 에 통째로 들어갑니다. 이는 $G_2(u)$를 만들때, low-degree 정점을 한번이라도 터치하는 모든 간선들을 때려넣었기 때문입니다.&lt;/li&gt;
      &lt;li&gt;$w’$ 를 $w$를 dominate하는 $D$의 정점이라고 하겠습니다. $(w, w’)$ 간선 또한 $G_2(u)$ 에 들어갑니다.&lt;/li&gt;
      &lt;li&gt;$w’ \in D$ 이므로, $(u, w’) \in G_2(u)$이고, 이 간선의 가중치 $\delta(u, w’)$는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BFS(w')&lt;/code&gt;에서 구한 값이므로 &lt;strong&gt;정확&lt;/strong&gt;합니다.&lt;/li&gt;
      &lt;li&gt;Dominating은 바로 연결되어 있다는 뜻이므로, $\delta(u, w’) \leq \delta(u, w) + 1$ 입니다.&lt;/li&gt;
      &lt;li&gt;다익스트라 알고리즘에 의해 구해지는 거리를 $\hat{\delta}$ 이라 하면, $\hat{\delta}(u, v)$ 는 다음을 만족합니다. \(\hat{\delta}(u, w') + \hat{\delta}(w', w) + \hat{\delta}(w, v)\)&lt;/li&gt;
      &lt;li&gt;그런데…$\hat{\delta}(u, w’)$ 은 BFS에서 구한 weight가 넘어오므로 정확하고, 이는 다시 $\delta(u, w) + 1$ 이하입니다.&lt;/li&gt;
      &lt;li&gt;$\hat{\delta}(w’, w)$는 어차피 1입니다.&lt;/li&gt;
      &lt;li&gt;$\hat{\delta}(w, v)$ 는 다시 실제 최단경로가 $G_2(u)$에 들어있으므로 정확합니다.&lt;/li&gt;
      &lt;li&gt;그러면, 다음 부등식이 성립합니다. 
\(\hat{\delta}(u, v) \leq \delta(u, w) + 1 + 1 + \delta(w, v) \leq \delta(u, v)\)&lt;/li&gt;
      &lt;li&gt;따라서, 이렇게 구한 최단경로는 최대 2만큼의 오차를 가집니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;정점쌍 $(u, v)$에 대해 $u \to v$의 최단경로가 High-degree 정점을 지나지 않는다면, 최단경로가 통째로 $E_2$에 들어있고, 다익스트라 알고리즘이 정확한 경로를 반환합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;on73-log2-n-complexity-2-error&quot;&gt;$O(n^{7/3} \log^2 n)$ complexity, 2-error&lt;/h3&gt;
&lt;p&gt;알고리즘 자체는 거의 똑같지만, 이번에는 세조각으로 나눕니다. degree가 $n^{1/3}$ 이상, $n^{2/3}$ 이상인 점을 각각 MID, HIGH라 하고, MID와 HIGH의 dominating set을 찾습니다. (이렇게 표현하기는 했지만, MID는 HIGH를 &lt;strong&gt;포함&lt;/strong&gt; 합니다. MID이상, HIGH이상이라고 생각해주세요!)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MID의 dominating set $D_M$ 은 $O(n^{2/3} \log n)$ 크기이고, 구하는데는 $O(m + n^{4/3})$ 시간이 걸립니다.&lt;/li&gt;
  &lt;li&gt;HIGH의 dominating set $D_H$ 는 $O(n^{1/3} \log n)$ 크기이고, 구하는데는 $O(m + n^{5/3})$ 시간이 걸립니다.&lt;/li&gt;
  &lt;li&gt;위에서와 같은 방법으로, MID에 포함되지 않는 정점 (즉 degree가 “작은” 정점) 을 하나라도 터치하는 edge의 집합을 $E_M$, HIGH에 포함되지 않는 정점 (degree가 “크지 않은” 정점) 을 하나라도 터치하는 edge의 집합을 $E_H$라 합니다. $E_M$의 크기는 $O(n^{4/3})$, $E_H$의 크기는 $O(n^{5/3})$ 입니다.&lt;/li&gt;
  &lt;li&gt;$D_H$ 에서 BFS를 돌립니다. 이는 $O(mn^{1/3}\log n)$ 시간이 걸립니다.&lt;/li&gt;
  &lt;li&gt;$D_M$ 에서 BFS를 돌리되, 이번에는 모든 간선을 쓰는 대신 $E_H$에 속하는 간선만 씁니다. 이는 $O(n^{2/3}n^{5/3}\log n) = O(n^{7/3} \log n)$ 시간이 걸립니다.&lt;/li&gt;
  &lt;li&gt;마지막으로, 나머지 점들에서는 Dijkstra를 돌립니다. 이때, 간선은 $E_M$에 속하는 간선들, dominate에 쓰인 간선들, $(D_H \times V)$ 에 속하는 간선들, $(D_M \times D_M)$ 에 속하는 간선들, $(\Set{u} \times D_M)$ 이렇게만 고릅니다.
    &lt;ul&gt;
      &lt;li&gt;$E_M$이 $O(n^{4/3})$, dominate에는 $n$개가 쓰이고,&lt;/li&gt;
      &lt;li&gt;$(D_H \times V)$ 가 또 $O(n^{4/3} \log n)$개, $D_M \times D_M$ 이 $O(n^{4/3} \log^2 n)$ 개, $(\Set{u} \times D_M)$이 $O(n^{2/3} \log n)$ 개입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;총 edge가 $O(n^{4/3} \log^2 n)$ 개이고, 돌리는 횟수가 $n$번 이하이므로 $O(n^{7/3} \log^2 n)$ 시간에 수행됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;같은 방법으로 2-error를 보입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;만약 최단경로가 HIGH의 정점을 하나라도 지난다면, 그중 마지막을 $w$라 하고 $D_H$에서 $w$를 dominate하는 $w’$를 고릅니다.
    &lt;ul&gt;
      &lt;li&gt;$\delta(u, w’)$ 는 $w’ \in D_H$ 이므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BFS(w')&lt;/code&gt;에 의한 정확한 거리를 압니다. 이는 $\delta(u, w) + 1$ 보다 작거나 같습니다.&lt;/li&gt;
      &lt;li&gt;$\delta(w’, v)$ 는 역시 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BFS(w')&lt;/code&gt;에 의해 정확한 거리를 알고, $\delta(w, v) + 1$ 보다 작거나 같습니다.&lt;/li&gt;
      &lt;li&gt;따라서, 이를 값은 $\delta(u, w) + 2 + \delta(w, v)$ 보다 작거나 같습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;만약 최단경로가 HIGH는 아예 안 지나지만, MID를 지난다면, 그중 마지막을 $w$라 하고 $D_M$에서 $w$를 dominate하는 $w’$를 고릅니다.
    &lt;ul&gt;
      &lt;li&gt;$\delta(u, w’)$ 에 대한 근사값은 $D_M$에서의 BFS(두번째 BFS) 도중에 비슷하게 찾을 수 있습니다. 그러나, 이번에는 $D_M$이 전체 그래프에 대고 BFS를 한 결과가 아니기 때문에 이게 정확하다는 보장이 없어서, $\delta_2(u, w’)$라고 쓰겠습니다. HIGH를 아예 안 지나는 경로가 최단임을 가정에서 보장했으므로 $\delta_2(u, w) = \delta(u, w)$ 이고, 결과적으로 $\delta_2(u, w’)$ 값은 $1 + \delta(w, u)$ 이하입니다.&lt;/li&gt;
      &lt;li&gt;$\delta(w’, w)$ 는 1이고&lt;/li&gt;
      &lt;li&gt;$\delta(w, v)$ 는 모두 low-touching 임이 보장되므로 다익스트라의 결과로 정확한 값을 구할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서, 이 알고리즘은 $O(n^{7/3} \log^2 n)$ 시간에 2-error approximation을 보장합니다.&lt;/p&gt;

&lt;h3 id=&quot;further--time-accuracy-tradeoff&quot;&gt;Further : Time-Accuracy Tradeoff&lt;/h3&gt;
&lt;p&gt;이를 이용하여, 2조각이나 3조각이 아닌 더 많은 조각으로 자르면 시간 복잡도가 더 낮아지는 대신 에러를 더 허용하게 됩니다. 구체적으로,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;첫번째 알고리즘을 확장, $s_i = (m / n)^{1-i/k}$을 이용하여 계산하는 알고리즘은 $\tilde{O}(n^{2-1/k}m^{1/k})$ 시간에 $2(k-1)$ 에러를 허용하고,&lt;/li&gt;
  &lt;li&gt;두번째 알고리즘을 확장, $s_i = n^{1-i/k}$를 이용하여 $D_{j} \times D_{j’}$ 같은 간선들을 추가해서 다익스트라를 쓰는 알고리즘은 $\tilde{O}(n^{2+1/k})$ 시간에 작동하는 대신 $2(\floor{k/3} + 1)$ 에러를 허용하게 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이를 합쳐서, $u$만큼의 에러 바운드를 고정하고 싶으면, 첫번째 경우의 $k = u/2 + 1$ 또는 두번째 경우에서 $k = 3u - 2$를 사용, 
\(\min(\tilde{O}(n^{2-\frac{2}{u+2}}m^{\frac{2}{u+2}}), \tilde{O}(n^{2+\frac{2}{3u-2}}))\)
이정도 시간복잡도에 최대 $u$만큼의 에러를 허용하는 APSP를 풀 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;지나치게 난해하지 않은 아이디어 (그래프의 edge를 HIGH-LOW로 나눈 다음, 이 위에서 경우에 따라 알고리즘을 바꿔끼움으로써 복잡도 개선하는 아이디어는 의외로 많이 보입니다) 를 이용하여 복잡도를 내리는 부분이 인상적이었습니다.&lt;/li&gt;
  &lt;li&gt;그래프가 dense하다면 최단경로가 생각보다 짧고, 그래프가 sparse하다면 $n$번의 다익스트라가 $O(nm)$으로 빠르기 때문에 이 알고리즘이 실용적으로 쓰이려면 $m$이 특정한 범위에 있고, 그래프가 꽤 커야 할 것 같습니다. 이론적인 복잡도 분석 측면에서 보다 큰 의미가 있는 듯 합니다.&lt;/li&gt;
  &lt;li&gt;이 논문의 Journal full version에는 weighted graph에서 최단경로의 3배 이하를 estimate하는 spanner에 대한 알고리즘이 추가로 논의되는것 같습니다. weighted graph는 이상한 케이스를 만들기가 쉽기 떄문에 이부분도 상당히 재밌을것 같습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:matmul&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;이론적으로 가장 빠른 알고리즘 (Coppersmith-Winograd), 실용적으로 빠른 알고리즘 (Strassen)이 이 min-plus-mm에도 적용가능함이 알려져 있습니다. &lt;a href=&quot;#fnref:matmul&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:aingworth&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;D. Aingworth, C. Chekuri, and R. Motwani. Fast estimation of diameter and shortest paths (without matrix multiplication). SODA 1996 &lt;a href=&quot;#fnref:aingworth&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="cs-adventure" /><summary type="html">Contents</summary></entry><entry><title type="html">Optimizers for Deep Learning</title><link href="http://localhost:4000/deep-learning-study/optimizer-for-deep-learning/" rel="alternate" type="text/html" title="Optimizers for Deep Learning" /><published>2021-11-20T00:00:00+09:00</published><updated>2021-11-20T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/optimizer-for-deep-learning</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/optimizer-for-deep-learning/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot; id=&quot;markdown-toc-stochastic-gradient-descent&quot;&gt;(Stochastic) Gradient Descent&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#momentum-sgd&quot; id=&quot;markdown-toc-momentum-sgd&quot;&gt;Momentum SGD&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nesterov-accelerated-gradient&quot; id=&quot;markdown-toc-nesterov-accelerated-gradient&quot;&gt;Nesterov Accelerated Gradient&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rmsprop&quot; id=&quot;markdown-toc-rmsprop&quot;&gt;RMSProp&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#adam&quot; id=&quot;markdown-toc-adam&quot;&gt;Adam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#other-algorithms&quot; id=&quot;markdown-toc-other-algorithms&quot;&gt;Other algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;많은 딥러닝 문헌에서 $x^i$를 $i$번째 데이터를 의미하는데 쓰고, $x_i$는 $x$벡터의 $i$번째를 의미하는데 씁니다. 이 관행을 따르겠습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;딥러닝의 문제는 수학적 관점에서 환원하면 결국 다음과 같이 요약할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;미지의 함수 $f$에 대해 알고자 하는데,&lt;/li&gt;
  &lt;li&gt;모든 지점이 아닌 어떤 지점 $x_i$ 들에서만 그 값 $f(x^i) = y^i$ 를 알고 있고,&lt;/li&gt;
  &lt;li&gt;그래서 어떤 페널티 $\ell$ 을 정의해서, $\sum_i \ell(f(x^i), g(x^i))$가 작은 $g$를 $f$의 근사-함수로 생각하고 싶습니다.&lt;/li&gt;
  &lt;li&gt;그런데 이 $g$를 모든 함수의 공간에서 최적화하는 것은 일반적으로 가능하지 않으므로,&lt;/li&gt;
  &lt;li&gt;어떤 parameter $\theta$ 에 의해 표현되는 함수공간의 부분집합 $g_\theta$만을 생각하며,&lt;/li&gt;
  &lt;li&gt;$\minimize \sum_i \ell(f(x^i), g_\theta(x^i))$ by moving $\theta$로 생각합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그런데 $f(x_i)$는 이미 알고 있으므로, 결국은 $\ell$ 이라는 함수는 $\theta$에만 의존하게 됩니다. 따라서, 우리는 $\ell(\theta)$를 최소화하는 $\theta$를 찾는 것을 목표로 합니다. 다시 이를 일반화해서, $\theta \in \R^n$ 으로 생각하면, $\ell : \R^n \to \R$ 함수의 최적화 문제가 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;일반적으로, $f$가 볼록(Convex) 함수인 경우에는 유일한 최적값이 존재하며, 추가로 강볼록 (Strictly Convex) 함수인 경우에는 최적값을 주는 최적 $\theta$도 유일함을 알고 있습니다.&lt;/li&gt;
  &lt;li&gt;볼록함수를 비롯한 여러 좋은 성질을 가진 함수들을 최적화하는것도 매우 흥미로운 이론들이 많이 있지만, 여기서는 깊이 다루지는 않겠습니다.&lt;/li&gt;
  &lt;li&gt;Deep Learning에서 사용되는 함수는 볼록성을 기대할 수 없기 때문에, 당연히 global minimum을 찾을 수는 없습니다. 우리는 Heuristic하게 그럴듯한 작은 값을 찾는 것을 목표합니다.&lt;/li&gt;
  &lt;li&gt;그렇기 때문에, 여기 나온 어떤 말도 엄밀하지 않습니다. 수리과학부에 한발 걸치고 있는 제게는 약간 의아한 부분이기도 한데, convex를 기대할 수 없으면서도 convex한 함수에 대해 증명한 다음 그러므로 잘 된다~ 라고 주장하거나, convex한 함수에서조차 수렴성이 증명이 안되는 알고리즘(ADAM) 을 마음껏 사용하는 등(…) 조금은 신기한 분야입니다. 하지만 실용적인 가치가 이쪽에서는 가장 우선시되기 때문에 어쩔수 없는듯 싶습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;주의&lt;/strong&gt; 이 글을 비롯하여, optimizer를 설명하는 많은 글에서 어떤 테스트 함수에 대한 아름다운 visualization을 이용하여 이해를 돕습니다. 매우 효과적이라고 생각했고 저도 실험해보면서 재밌었기 때문에 저도 직접 visualization을 많이 만들어 봤지만, 그래픽을 이용해서 이해할 때 주의할 점이 있습니다.&lt;/p&gt;

&lt;p&gt;우리가 일반적으로 사용하는 딥 러닝 모델은 수십만, 수백만 개의 파라미터가 있습니다. 다시 말해, $\R^{1,000,000}$ 같은 공간에서 뭔가를 최적화한다는 뜻입니다. 이 글에서 뒤에 설명할 “좋은” 최적화 알고리즘들인 RMSProp, Adam 등등은 이런 고차원 공간에서의 최적화를 빠르게 할 목적으로 개발되었습니다. 이런 상황과는 달리 우리의 그래픽은 $\R^2 \to \R$ 함수의 최적화를 사용하기 때문에, 세팅이 많이 다릅니다. 가장 큰 차이는 learning rate인데, 파라미터가 많다는것은 그만큼 각 파라미터에 대한 의존도는 낮아질 것이고 그러면 미세조정을 위한 작은 learning rate가 일반적입니다. 특히 $\R^2$ 같은 너무 저차원의 공간에서는 Adam같은 알고리즘들은 learning rate가 같아도 훨씬 수렴이 느립니다.&lt;/p&gt;

&lt;p&gt;이걸 보정하기 위해, 달려나가는 점들의 초반의 이동 속도가 비슷하도록 의도적으로 learning rate를 조정했습니다. 즉, 이 그래픽을 보고 “아 Adam이 빠르군” 이런 생각을 하는 것은 &lt;strong&gt;올바른 이해가 아닐 수도&lt;/strong&gt; 있다는 것입니다. 그래픽은 어디까지나 글로 설명한 바를 보여주기 위한 예시이므로, 많은 튜닝이 가해졌음을 염두에 두고, 말하고자 하는 바가 무엇인지를 파악하면 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;이 분야에 대한 제 이해도 아직 많이 부족하기 때문에, 설명에 오류가 있거나 보강할 점, 놓친 점이 있을 수 있습니다. 댓글 등으로 피드백은 항상 환영합니다 :)&lt;/p&gt;

&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;(Stochastic) Gradient Descent&lt;/h3&gt;
&lt;p&gt;이 글에서는 독자가 gradient descent를 이해하고 있다고 가정하지만, 혹시 아니라면 &lt;a href=&quot;/deep-learning-study/opt-and-gd&quot;&gt;Gradient Descent에 대한 포스팅&lt;/a&gt; 를 참고해 주세요.&lt;/p&gt;

&lt;p&gt;Gradient Descent는 한 스텝 한 스텝이 너무 느리기 떄문에 (모든 데이터를 한바퀴 돌아야 해서), 대신 한 데이터 또는 소수의 데이터로 자주 밟는 stochastic gradient descent가 기본이 됩니다. 기본적인 SGD에 대해서는 &lt;a href=&quot;/deep-learning-study/sgd&quot;&gt;Stochastic Gradient Descent 포스팅&lt;/a&gt; 에서 다루었습니다. (언젠가 리폼될 예정) 이하의 모든 알고리즘들은 어떤식으로든 SGD에 기반하기 때문에, SGD의 식은 한번 리뷰할 가치가 있습니다.&lt;/p&gt;

\[i(k) \sim \uniform{1}{N},\quad \theta^{k+1} = \theta^k - \alpha \nabla{f_{i(k)}(\theta^k)}\]

&lt;p&gt;여기서 $\nabla f_{i(k)}$ 대신 다른 적당한 $g_k$를 잡아도 되는데 (Batched-gradient), 대신 $g_k$는 $\nabla F(x^k)$ 의 &lt;strong&gt;Unbiased Estimator&lt;/strong&gt; 여야 합니다. 또한 좀더 식을 간단하게 쓰기 위해, 앞으로 $i(k)$ 의 선택은 논의하지 않겠습니다. 이건 그냥 랜덤하게 돌리면 됩니다. 즉, 위 SGD를 다시 쓸 때,&lt;br /&gt;
\(\theta^{k+1} = x^k - \alpha g^k(\theta^k)\)
이렇게만 쓰더라도, $g^k$를 랜덤하게 골라진 index $i(k)$에 대한 (또는, batch를 사용하는 경우 batch-gradient) $\nabla f_i(k)$의 값으로 읽어주면 됩니다. Batch에 대한 자세한 얘기는 위에 링크걸린 SGD 포스팅을 읽어주세요.&lt;/p&gt;

&lt;p&gt;여기서 다른건 대부분 큰 문제가 없는데, $\alpha$, learning rate의 선택이 문제입니다. Learning rate가 너무 크거나 작으면 최적화가 잘 이루어지지 않습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Learning rate가 너무 작으면, 함수값의 수렴이 너무 느립니다.&lt;/li&gt;
  &lt;li&gt;Learning rate가 너무 크면, 목표하는 점을 지나쳐서 수렴하지 않을 수도 있습니다. 
&lt;img src=&quot;../../images/a68cabe4e3482c8b38d722134c205c9aa3bb238b8214592bd634e2b8ba3565d4.png&quot; alt=&quot;picture 1&quot; /&gt; 
(사진출처 : https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;일반적으로 좋은 Learning rate를 잡는 방법이 있는것은 아니고, 돌려보면서 찾아야 합니다.&lt;/p&gt;

&lt;h4 id=&quot;momentum-sgd&quot;&gt;Momentum SGD&lt;/h4&gt;
&lt;p&gt;저 $\alpha$가 상수여야 할 이유는 별로 없습니다. 즉, 만약 매 순간 현재 시점까지 알고있는 어떤 정보를 이용해서 learning rate를 조정해 줄 수 있다면 더 좋은 알고리즘이 될 것입니다.&lt;/p&gt;

&lt;p&gt;Momentum이란, SGD에 “이전에 갔던 방향으로 조금 더 가고자 하는” 관성을 추가하는 방법입니다. 이 방법을 먼저 수식으로 쓰면…
\(\begin{align*}
v^{k+1} &amp;amp;= g^k + \beta v^k \\ 
\theta^{k+1} &amp;amp;= \theta^k - \alpha v^{k+1}
\end{align*}\)
즉, ‘방금 전에 갔던 속도벡터의 $\beta$배’ 를 현재 가고싶은 방향 (gradient)에 더해주는 것입니다. 이전에 갔던 방향으로 계속 가려는 경향성이 있기 때문에, 이런 함수를 상대적으로 빠르게 탈출할 수 있습니다. 
&lt;img src=&quot;../../images/SGD-momentum.gif&quot; alt=&quot;picture 2&quot; /&gt;&lt;br /&gt;
잘 보면, $x$방향으로는 gradient에 비해 가야할 거리가 먼데 비해 $y$방향은 gradient가 많이 변하고 있습니다. 일반 SGD는 후반 (valley를 내려온 후)에 gradient가 너무 작아서 학습이 잘 되지 않는 반면, Momentum이 추가된 SGD는 이전에 갔던 방향을 잘 이용해서 빠르게 진행하는 것을 관찰할 수 있습니다.&lt;/p&gt;

&lt;p&gt;또한, 작은 learning rate를 쓸 때 발생하는 또하나의 문제는 작은 local minima를 지나치지 못하고 묶여버리는 현상입니다. 이때 momentum은 local minima에서 빠져나올 수 있는 새로운 가능성을 제공하기도 합니다.&lt;/p&gt;

&lt;p&gt;아래 그림은 좀 어거지로 끼워맞춘 함수를 이용해서 만든 예시지만, (4, 1) 부근의 아주 작은 local minima를 지나치지 못하는 SGD와 momentum의 힘 (관성) 으로 지나쳐서 global minima를 향해 가는 momentum SGD를 비교해 볼 수 있습니다. 
&lt;img src=&quot;../../images/SGD-momentum-localmin.gif&quot; alt=&quot;picture 3&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;nesterov-accelerated-gradient&quot;&gt;Nesterov Accelerated Gradient&lt;/h4&gt;
&lt;p&gt;NAG라고도 불리는 이 방법은, 아래 도식에서도 알 수 있듯 momentum을 쓰되, 방금전의 momentum과 여기의 gradient를 합치는게 아니라 방금전의 momentum은 어차피 갈 것이므로 그만큼을 일단 무작정 간 다음 거기서 gradient를 찾는 방법입니다. 
&lt;img src=&quot;../../images/16b09bf73c5ef29f2456574daba5f8b3e8166374f8af555c1122bd682afcb2f6.png&quot; alt=&quot;picture 4&quot; /&gt;&lt;br /&gt;
(사진 출처 : stanford CS231)&lt;/p&gt;

&lt;p&gt;직관적으로, 이 방법이 보다 잘 작동할 수 있을 것 같은 이유는 momentum SGD가 갖는 빠른 수렴속도 (관성) 을 유지하면서도 좀더 안정적이기 때문입니다. 예를 들어 momentum 방향이 $-y$ 방향이고, 지금의 gradient도 $-y$방향이라서 $-y$로 한참동안 가보니까 다시 $+y$ 방향 gradient가 있는 상황을 생각해 볼 수 있습니다. 이는 momentum SGD가 관성때문에 반대로 진동하게 만든다는 뜻인데, NAG는 이때 momentum만큼을 가본다음 거기서 gradient를 재기 때문에 이런 진동이 덜합니다.&lt;/p&gt;

&lt;p&gt;위에서 본 parabola형태에서, 좀 큰 learning rate를 잡아서 momentum이 좀 크게 진동하게 만들면 이런 재밌는 예시를 얻습니다.
&lt;img src=&quot;../../images/SGD-NAG.gif&quot; alt=&quot;picture 5&quot; /&gt;&lt;br /&gt;
SGD는 저 멀리서 다시 평면을 기어다니고 있고 (…) 모멘텀은 위아래 진동이 너무 큰데 비해, NAG가 좀더 안정적으로 움직이고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;rmsprop&quot;&gt;RMSProp&lt;/h3&gt;
&lt;p&gt;G.Hinton. Lecture Notes for csc321&lt;/p&gt;

&lt;p&gt;RMSProp은 인공지능 분야의 선구자이자 최고의 big name중 하나인 Geoffry Hinton 교수님의 Coursera 강의에서 처음 소개된 알고리즘입니다. 대략적인 아이디어는, $g^k$의 지금까지의 히스토리를 볼 때, 변동이 좀 심한 값은 진동중인 값일 가능성이 높아 보이므로 그만큼 learning rate를 깎아서 적용하겠다는 아이디어입니다. 즉 $g^k$의 각 “방향” 마다, 다른 learning rate를 적용한다는 아이디어가 핵심이라고 할 수 있겠습니다.&lt;/p&gt;

&lt;p&gt;이를 위해, $(g^k_i)^2$의 estimation을 $(m^k)_i$ 로 정의하고, 이 값의 square root로 나눠 줍니다. 즉 어떤 파라미터 방향으로의 지금까지의 gradient값의 “Root Mean Square average” 만큼을 이용, 변동이 심한 파라미터가 무엇인지를 찾습니다. 반대로, gradient의 변동이 거의 없으면 비교적 smooth한 길을 (기울어져 있을 수는 있지만, 변동이 심하지 않은) 가고 있을 것이므로, 좀 과감하게 가도 됩니다. 이를 수식으로 표현하면 다음과 같습니다. 
\(\begin{align*}
    m^k &amp;amp;= \beta_2 m^{k-1} + (1 - \beta_2) (g^k \odot g^k) \\
    x^{k+1} &amp;amp;= x^k - \alpha g^k \oslash \sqrt{m^k + \epsilon}
\end{align*}\)
여기서 보통 $\beta_2$ 값은 0.99 정도를 쓰고, 위 식에서 $\odot$ 와 $\oslash$ 는 elementwise 곱셈과 나눗셈을 의미합니다. 위 식을 보면, $m^k$는 (이전 $m^k$의 0.99배) 와 (현재 gradient의 각 방향별 값의 제곱의 0.01배)를 더해서 만들어지는데, 이는 즉 이전의 gradient들이 점점 영향을 덜 미치는 (즉, 가중평균을 내되, 최근값이 좀더 잘 반영되도록 하는 가중평균, 이를 &lt;strong&gt;“Exponentially (decaying) moving average”&lt;/strong&gt; 라 해서 EMA라 씁니다) 형태의 식임을 의미합니다. $\epsilon$은 실수오차에 따라 음수의 square root를 취하는 (수학적으로는 $m^k$의 각 값이 음수가 나올 수 없지만, 계산해서 0인 값은 실수오차때문에 0에 매우 가까운 음수일 수 있습니다) 프로그램적인 오류를 방지하기 위해 추가된 값으로, 수학적으로는 의미가 없습니다.&lt;/p&gt;

&lt;p&gt;RMSProp을 비롯하여, 이후에 다룰 알고리즘들에게 parabola는 너무 쉬운 케이스이므로 Beale’s function으로 그래픽을 그려보겠습니다.
&lt;img src=&quot;../../images/RMSProp-Beale.gif&quot; alt=&quot;picture 5&quot; /&gt;&lt;br /&gt;
마찬가지로 극초반 몇번은 속도가 비슷했지만, SGD는 gradient가 작아지면 갈곳을 잃는 반면 NAG나 RMSProp은 관성의 힘으로 좀 빠르게 나아갈 수 있습니다. 대신 약간 불안정한 모습을 보이는데, RMSProp이 좀더 빠르게 제 길을 돌아오는 모습도 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;adam&quot;&gt;Adam&lt;/h3&gt;
&lt;p&gt;D. P. Kingma and J. Ba, Adam: A method for stochastic optimization, ICLR, 2015.&lt;/p&gt;

&lt;p&gt;Adam은 &lt;strong&gt;Ada&lt;/strong&gt;ptive &lt;strong&gt;M&lt;/strong&gt;oment 의 약자로, 간단히 요약하면 Momentum-SGD와 RMSProp을 섞어놓은 알고리즘입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Momentum-SGD에서 가져오는 아이디어는, $g^k$ 대신 모멘텀을 포함한 gradient 값을 사용하는 것입니다.&lt;/li&gt;
  &lt;li&gt;RMSProp의 $(g^k_i)^2$의 running average를 취하는 아이디어를 그대로 가져옵니다.&lt;/li&gt;
  &lt;li&gt;단, Momentum도 RMSProp처럼 계산합니다. 이 말이 무슨 뜻인지는 수식을 보면서 얘기하겠습니다.
\(\begin{align*}
  m_1^k &amp;amp;= \beta_1m_1^{k-1} + (1-\beta_1)g^k, \tilde{m_1^k} = \frac{m_1^k}{1 - \beta_1^{k+1}} \\
  m_2^k &amp;amp;= \beta_2 m_2^{k-1} + (1 - \beta_2) g^k \odot g^k, \tilde{m_2^k} = \frac{m_2^k}{1 - \beta_2^{k+1}} \\
  x^{k+1} &amp;amp;= x^k - \alpha \tilde{m_1}^{k} \oslash \sqrt{\tilde{m_2}^k + \epsilon}
\end{align*}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;수식에서, $m_1$은 $g$값의 EMA고 (이 표현은 바로 위 RMSProp에서 썼습니다), $m_2$ 값은 $g \odot g$ 의 EMA입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;일반적으로, $\beta_1 = 0.9$, $\beta_2 = 0.99$를 많이 씁니다.&lt;/li&gt;
  &lt;li&gt;$\tilde{m_1}$ 을 쓰는 것을 볼 수 있는데, 이건 처음에 $m_1, m_2$ 의 값을 모르기 때문에 이걸 0으로 초기화할 수밖에 없어서입니다. 0으로 초기화한 $m_1, m_2$ 때문에 초반 gradient가 올바르게 반영되지 않는 일을 막기 위해 (안그러면 처음 $m_1$은 $g_1$의 1/10에 불과하게 됩니다), 이를 bias-correction해 줍니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adam은 현대 Deep Learning에서 가장 많이 사용되는 최적화 알고리즘입니다. 간단히 말해서, CNN같은걸 training하는데 뭘 쓸지 모르면 그냥 Adam을 써보면 됩니다.&lt;/p&gt;

&lt;p&gt;그정도의 중요도를 가진 알고리즘이기 때문에, 역으로 여기서는 짧게만 다루고 언젠가 CS-Adventure 포스팅으로 Adam 논문을 읽고 정리하려고 합니다. 재밌는 일화로, 2018 ICML에는 Adam의 볼록함수에 대한 수렴성의 반례를 찾은 논문이 발표되었습니다. Adam의 원본 논문에는 “Convex하면 수렴한다” 는 증명이 있는데, 이 증명에는 오류가 있고, 실제로는 볼록함수라는 조건 하에서도 수렴하지 않는다고 합니다. Nevertheless, 어차피 그동안 Adam 쓰던게 볼록함수에서 잘 수렴해서 쓰는게 아니었기 때문에 개의치 않고 다들 잘 쓰고 있습니다.&lt;/p&gt;

&lt;p&gt;마찬가지로 Beale’s function으로 그래픽을 그려보겠습니다.
&lt;img src=&quot;../../images/ADAM-Beale.gif&quot; alt=&quot;picture 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;맨 위의 주의에서도 말했지만, 이건 절대 각 알고리즘들의 공정한 비교가 아닙니다. 초반 몇번의 속도가 (눈으로 보기에) 비슷하도록 억지로 learning rate를 키워서 맞췄는데 (안그러면 ‘안정성’ 때문에 Adam이 초반에 너무 느립니다), 우리가 겨우 수백개의 점에 대해 해보는것과는 달리 실제 딥러닝에서는 수천 수만개의 데이터를 수십바퀴 이상씩 돌릴거라서 근본적인 목표가 좀 다릅니다. 함수의 복잡도도 많이 다르고…이 그림은, SGD-NAG의 lr이 0.0015이고, Adam의 LR이 0.7입니다. 변명을 조금 하자면, SGD는 LR 0.1도 감당을 못하고 수렴을 못시키는데 비해 이렇게 높은 LR로도 수렴시키는게 달리말하면 Adam의 &lt;strong&gt;안정성&lt;/strong&gt;을 보여준다고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;일반적으로, Adam과 같은 Adaptive rate (RMSProp도 마찬가지) 알고리즘들은 그 수렴 속도가 매우 빠르지만, &lt;strong&gt;가끔&lt;/strong&gt; 어떤 예시에서는 잘 수렴하지 못하기도 합니다. 이때는 SGD같은 알고리즘들이 (충분히 learning rate를 잘 튜닝하면) 일반적으로 수렴성이 좋다고 알려져 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;other-algorithms&quot;&gt;Other algorithms&lt;/h3&gt;
&lt;p&gt;여기서 다루지 않은 알고리즘 중에도 재밌고 유용한게 많습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;AMSGrad (Reddi et al, 2018) : Adam의 수렴성이 성립하지 않음을 지적한 논문에서 그 대안으로 들고 나온 알고리즘입니다. 언젠가 Adam에 대해 자세히 공부할 때 Adam + Convexity의 반례 + AMSGrad로 다루려고 생각하고 있습니다.&lt;/li&gt;
  &lt;li&gt;NAdam (Dozat, 2016) : Adam의 $m_1$을 Nesterov 방식으로 바꾼 방법입니다.&lt;/li&gt;
  &lt;li&gt;AdamW (Loshchilov et al, 2017) : Adam 에 regularization을 적극적으로 도입해서 Adam의 generalization issue를 해결하는 방법입니다. 언젠가 다룰 수도? 있습니다.&lt;/li&gt;
  &lt;li&gt;AdaDelta, AdaGrad, AdaMax : Adaptive rate 알고리즘들이 굉장히 다양하게 있는데, 약간씩 다른 아이디어가 있지만 기본 아이디어 (gradient와 그 square 등을 EMA해서 계산) 레벨에서는 다르지 않으므로 넘어갑니다.&lt;/li&gt;
  &lt;li&gt;BFGS를 비롯한 2nd-order methods : 수학적으로 흥미롭지만 이 글에서는 일부러 언급을 피했습니다. 차후에 다룰 예정입니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">BOJ 17532, ICPC Brazil Subregional 2019D Denouncing Mafia</title><link href="http://localhost:4000/problem-solving/BOJ-17532/" rel="alternate" type="text/html" title="BOJ 17532, ICPC Brazil Subregional 2019D Denouncing Mafia" /><published>2021-11-19T00:00:00+09:00</published><updated>2021-11-19T00:00:00+09:00</updated><id>http://localhost:4000/problem-solving/BOJ-17532</id><content type="html" xml:base="http://localhost:4000/problem-solving/BOJ-17532/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#풀이&quot; id=&quot;markdown-toc-풀이&quot;&gt;풀이&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#구현&quot; id=&quot;markdown-toc-구현&quot;&gt;구현&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/17532&quot;&gt;문제 링크&lt;/a&gt;&lt;br /&gt;
난이도 : solved.ac 기준 Platinum 4.&lt;/p&gt;

&lt;h2 id=&quot;풀이&quot;&gt;풀이&lt;/h2&gt;
&lt;p&gt;결국 주어진 문제는, 어떤 트리가 주어질 때, 트리에서 최대 $K$개의 path를 택하여 그 path들의 union을 최대화하는 문제입니다.&lt;/p&gt;

&lt;p&gt;문제의 특성 상, 트리 DP를 먼저 생각해 볼 수 있습니다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dp[i][j]&lt;/code&gt; : $i$번째 노드를 루트로 하는 subtree에 대해, $j$개의 path를 택했을 때의 최댓값&lt;/p&gt;

&lt;p&gt;이 DP를 계산하는 방법을 생각해 봅시다. 만약 내 child node에 대해 모든 dp값을 알고 있다면, 내 child node 들에 대해 각 노드당 몇개의 chain을 사용할지를 정해야 합니다. 이는 굳이 열심히 복잡도를 계산해 보지 않더라도, 적어도 $O(NK)$ 칸의 DP를 모두 채워야 하기 때문에 전혀 답이 없습니다. 예를 들어 3개의 자식노드를 가진 노드에 대해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dp[i][5]&lt;/code&gt;를 계산하려면, 5를 3개로 분할하는 모든 경우에 대해 각각 dp값을 더해서 확인해야 하기 때문에 exponential한 시간이 걸릴 것입니다.&lt;/p&gt;

&lt;p&gt;대신해서, 이렇게 생각해 봅시다. 이하, 한줄로 쭉 연결된 path를 경로 또는 체인으로 표현하겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;만약 최종적인 답이, 트리에서 가장 긴 경로 (루트-리프 중 가장 긴 경로)를 포함하지 않는다면 적당한 경로 하나를 빼고 대신에 이 가장 긴 경로를 집어넣으면 더 좋은 답이 됩니다.&lt;/li&gt;
  &lt;li&gt;이를 귀납적으로 반복 적용하면, 무조건 현재 남아 있는 가장 긴 경로를 택해야 한다는 것입니다.&lt;/li&gt;
  &lt;li&gt;단, path의 길이의 합이 아니라 union에 포함된 노드 수를 세기 때문에, 이미 한번 방문된 노드는 더이상 path의 길이에 의미가 없습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;path의 개수는 너무 많고, 우리는 어차피 어떤 노드를 정하면 거기서부터 리프까지 달려가는게 최대한 이득이기 때문에, “어떤 노드를 골라서” 그 노드를 루트로 하는 서브트리에서 가장 깊이 들어가 있는 리프까지의 경로를 택한다고 생각해도 충분합니다. 즉, 트리를 서로 disjoint한 path로 잘라서 생각합니다.&lt;/p&gt;

&lt;p&gt;이제, 미리 모든 path를 priority queue에 넣어놓고, 이를 고르는 식으로 돌립니다. 단, 이미 방문한 노드는 다시 고르지 않도록 조정하면 됩니다. 아래 구현이 충분히 직관적으로 읽힌다고 생각해서, 더이상 설명은 생략하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;bits/stdc++.h&amp;gt;
#define usecppio ios::sync_with_stdio(0);cin.tie(0);cout.tie(0);
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;priority_queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int32_t&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;usecppio&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="problem-solving" /><summary type="html">Contents</summary></entry><entry><title type="html">Autodiff/Backpropagation</title><link href="http://localhost:4000/deep-learning-study/backpropagation/" rel="alternate" type="text/html" title="Autodiff/Backpropagation" /><published>2021-11-16T00:00:00+09:00</published><updated>2021-11-16T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/backpropagation</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/backpropagation/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#backpropagation&quot; id=&quot;markdown-toc-backpropagation&quot;&gt;Backpropagation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#notes&quot; id=&quot;markdown-toc-notes&quot;&gt;Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이 글은 심층신경망 수업에서 공부한 내용에 기반하지만, 제가 나름대로 이해한 바를 덧붙여서 작성했습니다. 특히, 설명하는 방법이 조금 다릅니다.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Multi layer perceptron이 되었든, Convolutionary neural network가 되었든 기본적인 틀은 logistic regression과 다를 것이 없습니다.&lt;/p&gt;

&lt;p&gt;설명의 편의를 위해 이 글에서는 MLP에 대해 설명하겠지만, CNN도 사실은 별로 다르지 않습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MLP는 결국, 다음과 같은 형태의 함수로 나타나는 회귀 모형이라고 볼 수 있습니다.
\(\begin{align*}
  y_L &amp;amp;= W_L y_{L-1} + b_L \\
  y_{L - 1} &amp;amp;= \sigma(W_{L-1} y_{L - 2} + b_{L - 1}) \\
  \cdots &amp;amp; \cdots \\
  y_2 &amp;amp;= \sigma (W_2 y_1 + b_2) \\
  y_1 &amp;amp;= \sigma (W_1 x + b_1)
\end{align*}\)&lt;/li&gt;
  &lt;li&gt;여기서 $W_i, b_i$ 들은 모두 trainable weight 이고, $\sigma$는 어떤 activation function 입니다.&lt;/li&gt;
  &lt;li&gt;우리는, $y_L$의 참값 (이라고 말하면 좀 애매하지만…) 을 반환하는 함수 $\tilde{y_L} = f(x)$ 가 존재한다고 생각합니다. 이를 최대한 &lt;strong&gt;근사&lt;/strong&gt; 하는 것이 목표입니다. 즉, 저 위 형태의 함수 ($W_i, b_i$ 를 이용하여 표현되는 함수) 를 &lt;strong&gt;표현 가능하다&lt;/strong&gt; 라고 정의하면, &lt;strong&gt;Ground-truth 함수에 가장 가까운 표현가능한 함수&lt;/strong&gt; 를 찾고 싶습니다.&lt;/li&gt;
  &lt;li&gt;그러나 우리는 ground truth를 모두 아는게 아니라, 몇몇 데이터 $x^1, x^2, \dots$ 에 대해 알고 있습니다.&lt;br /&gt;
따라서, 어떤 Loss function을 정의하여
\(\sum_{i = 1}^{n} \mathcal{L}(y_L^{i}, \tilde{y_L}^{i})\)
을 정의한 다음, 이 $\mathcal{L}$ 이 어떤 실제 $\tilde{y_L}^i$ 과 $y_L^i$ 간의 거리를 제시하므로, 이를 가능한 최소화하는 방향으로 나아가려고 합니다.&lt;/li&gt;
  &lt;li&gt;그러므로, 우리는 여기서 SGD 또는 그 비슷한 알고리즘들을 사용합니다. 즉, $W_k, b_k$ 행렬 또는 벡터에 들어 있는 각 변수 $W_k(i, j)$ 나 $b_k(i)$ 를 이용해서 전체 공간에서의 Loss function을 그려놓고, 그 minimum을 (iterative하게) 찾을 수 있기를 바랍니다.&lt;/li&gt;
  &lt;li&gt;SGD나 다른 방법을 쓰려면, 결국은 이런 느낌의 편미분계수들을 꼭 알아야 합니다. 
\(\pdv{\mathcal{L}}{W_k(i, j)} \quad \quad \pdv{\mathcal{L}}{b_k(i)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모델이 간단하면 뭐 직접 미분한다고 치지만, 위에 있는 MLP 식 같이 생긴 복잡한 함수를 어떻게 미분할 수 있을까요?&lt;/p&gt;

&lt;h2 id=&quot;backpropagation&quot;&gt;Backpropagation&lt;/h2&gt;
&lt;p&gt;위 형태를 잘 보면, 합성함수 형태임을 알 수 있습니다. 합성함수의 미분은 Chain rule을 이용해서 수행할 수 있습니다.&lt;br /&gt;
$x \in \R^m, y \in \R^n$, $g : \R^m \to \R^n, f : \R^n \to \R$ 정도의 세팅을 생각해 봅시다. $\mathbf{y} = g(\mathbf{x}), z = \mathbf{y}$ 라 할 때, 다음이 성립합니다.
\(\pdv{z}{x_i} = \sum_{j} \pdv{z}{y_j} \pdv{y_j}{x_i}\)
이 방법을 이용해서, 우리는 전체 $P$개의 모든 파라미터에 대해 $\pdv{\mathcal{L}}{w_i}$ 를 구해야 합니다.&lt;/p&gt;

&lt;p&gt;이를 계산하기 위해, 먼저 Computational graph를 만듭니다. Computational graph란, 아래와 같이 각 값들을 노드로, 계산에 필요한 dependency들을 edge로 연결해서 그래프 형태로 만든 것입니다.
&lt;img src=&quot;../../images/40cd6084bc0a4674ff1e61d062fc8f8900db1c435a6b86e723fa32965d94d37f.png&quot; alt=&quot;picture 3&quot; /&gt;&lt;br /&gt;
(사진출처 : 서울대학교 심층신경망의 수학적 기초 강의자료)&lt;/p&gt;

&lt;p&gt;여기서, ‘변수를 다른 변수로 미분한 미분계수’ 들을 구하고, ‘최종 결과를 변수로 미분한 미분계수’ 를 그 결과로 얻을 것입니다. 구체적으로,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;각 edge에 대해, 변수를 변수로 미분한 중간 미분계수를 edge에 적어넣고,&lt;/li&gt;
  &lt;li&gt;마지막에, root 노드 (i.e, 계산의 최종값) 에서 출발해서, 임의의 노드까지 가는 경로를 모두 따라가면서 곱해서 더하면 ‘최종결과를 변수로 미분한’ 미분계수를 얻습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;즉, 알고리즘의 언어로 말하자면 DAG 위에서 depth가 낮은 노드부터 거꾸로 올라가면서 edge의 값을 계산하고 (DP), 돌아올때는 topological order로 계산하겠다는 의미입니다.&lt;/p&gt;

&lt;p&gt;이 사진에 있는 함수를 직접 계산하면서 과정을 따라가 보겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;step이 낮은 것부터 올라갑니다. 즉, 처음에는 step 1인 $a$-노드의 미분계수들을 계산하기 위해 $\pdv{a}{x}$ 를 구하며, 이 값은 $1/x$ 이므로 1/3입니다. 여기서 주목할 점은, 일반적인 symbolic differntiation을 수행할 때는 $1/x$를 들고 가지만, 우리는 어차피 최종적으로 수치연산을 할 것이므로 $1/3$ 이라는 사실만 기억하면 $1/x$ 라는 값은 잊어버려도 됩니다. 이 값은 edge에 적어 넣습니다. 또한 이후에 $a$값도 필요하기 때문에 $a = \log 3$ 이라는 결과를 노드에 적어넣습니다. 이제, step 1까지 왔습니다.&lt;/li&gt;
  &lt;li&gt;step 2에 해당하는 $b$를 구해야 합니다. $\pdv{b}{a} = y, \pdv{b}{y} = a$ 이며, 이는 각각 $a, y$의 &lt;strong&gt;이미 계산한 노드값&lt;/strong&gt; 을 참조해서 계산할 수 있습니다. 각각 $2, \log 3$ 이 될 것이며, 이를 edge에 적어 넣습니다. $b$ 는 $2 \log 3$ 이고. 이건 노드에 적어넣습니다.&lt;/li&gt;
  &lt;li&gt;step 3에 해당하는 $\pdv{c}{b}$ 는 $\frac{1}{2\sqrt{b}} = \frac{1}{2\sqrt{\log 3}}$ 입니다. $c = \sqrt{log 3}$ 입니다.&lt;/li&gt;
  &lt;li&gt;step 4는 마지막으로, $\pdv{f}{c} = 1$, $\pdv{f}{b} = 1$ 이며, $f$ 의 최종적인 값은 $\sqrt{2 \log 3} + 2 \log 3$ 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기까지가 지금 1 과정이 끝난 것입니다. 이를 “Forward pass” 등으로 부릅니다. 여기까지 계산한 결과는 아래와 같습니다.
&lt;img src=&quot;../../images/de99a2ba80e6f53a603bb8047d889a83d9d279550c8e053d5f4ad9f2479dd270.png&quot; alt=&quot;picture 4&quot; /&gt;&lt;br /&gt;
이제, 다시 거꾸로 돌아가면서 계산합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\pdv{f}{c} = 1$. 이번에는, $c$에 해당하는 노드에 이 값을 적어넣습니다.&lt;/li&gt;
  &lt;li&gt;$\pdv{c}{b} = \frac{1}{2 \sqrt{2 \log 3}}$ 이며, $\pdv{f}{b}$ 는 여기에 따로 $b$가 $f$에 영향을 미치는 1이 있으므로 (가장 아래 edge), $\pdv{f}{b} = \frac{1}{2 \sqrt{2 \log 3}} + 1$ 입니다. 마찬가지로 $b$ 노드에 적어 넣습니다.&lt;/li&gt;
  &lt;li&gt;같은 방법으로 뒤로 계속 달립니다. $\pdv{f}{a} = \frac{1}{\sqrt{2 \log 3}} + 2$.&lt;/li&gt;
  &lt;li&gt;결국 다 계산하면, $\pdv{f}{x} = \frac{1}{3\sqrt{2\log 3}} + \frac{2}{3}$ 과 $\pdv{f}{y} = \sqrt{\frac{\log 3}{8}} + \log 3$ 이 남을 것입니다. 
이 방법을 Backpropagation이라고 부릅니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Autodiff란, 사실은 forward autodiff 등 몇가지 방법이 더 있습니다. 그중 가장 대표적인 방법인 backpropagation을 소개했는데, 사실 생각해 보면 반대로 forward pass만으로 계산하는 방법이 있습니다. 
위 과정에서 위로 올라가는 DP를 할 때, $\pdv{b}{a}$ 같은 값들을 계산해서 edge에 적어놓고, 바로 $b$ 노드에는 $\pdv{b}{x}, \pdv{b}{y}$ 를 그자리에서 계산해서 (앞서 $\pdv{a}{x}$ 도 노드에 적어놨을 것이므로) 기억하는 방법이 있습니다.
이렇게 계산하면 한번 forward를 달릴 때 모든 계산이 끝납니다.&lt;/li&gt;
  &lt;li&gt;그럼에도 불구하고, 실제로 사용하는 deep learning에서의 gradient 계산은 대부분 backpropagation입니다. 그 이유는, 지금 위 예시에서는 알 수 없는 부분이긴 하지만 MLP를 다시 생각해 보면 대부분의 연산이 행렬곱이므로 위 예시와는 달리 각 edge에 스칼라값이 아니라 행렬이 쓰여지게 됩니다. 이게 왜 의미가 있냐면, 결국은 ‘행렬들을 순서대로 많이’ 곱해야 한다는 얘기고… 행렬 여러개를 곱할 때는 작은 행렬부터 곱하고 그 결과를 큰 행렬과 곱하는 것이 대체로 보다 효율적입니다. (이 표현은 완벽하게 정확하지는 않지만, 행렬의 크기가 단조증가한다면 참입니다. 사실은 이 자체가 &lt;strong&gt;행렬 곱셈 순서&lt;/strong&gt; 라는 (백준에도 있는..ㅋㅋ) 매우 유명한 DP 문제입니다.) 그런데 MLP든 CNN이든, 네트워크 끝쪽 (출력에 가까운 쪽) 으로 향하면서 점점 feature의 개수를 줄여나가는 것이 일반적이며, 따라서 backpropagation 방법으로 뒤에서부터 곱하면서 오는게 행렬 곱셈을 더 빨리 할 수 있기 때문입니다.&lt;/li&gt;
  &lt;li&gt;Torch 등 딥러닝 라이브러리들은 이 backpropagation을 자동으로 잘 따라가 주기 때문에 일반적으로는 걱정할 필요가 없지만, 새로운 loss function을 정의할 때는 항상 미분가능한지를 생각해야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;서울대학교 심층신경망의 수학적 기초 강의자료 (&lt;a href=&quot;http://www.math.snu.ac.kr/~ernestryu/courses/deep_learning.html&quot;&gt;링크&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Ian Goodfellow, Yoshua Bengio, &amp;amp; Aaron Courville (2016). Deep Learning. MIT Press.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">LeNet으로 MNIST 풀어보기</title><link href="http://localhost:4000/deep-learning-study/LeNet-MNIST/" rel="alternate" type="text/html" title="LeNet으로 MNIST 풀어보기" /><published>2021-11-07T00:00:00+09:00</published><updated>2021-11-07T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/LeNet-MNIST</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/LeNet-MNIST/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#lenet-모델&quot; id=&quot;markdown-toc-lenet-모델&quot;&gt;LeNet 모델&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#구현&quot; id=&quot;markdown-toc-구현&quot;&gt;구현&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 8강 (10월 5일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/deep-learning-study/mnist-mlp/&quot;&gt;MLP로 MNIST 풀어보기&lt;/a&gt;의 코드와 &lt;a href=&quot;/deep-learning-study/convolutionary-neural-networks/&quot;&gt;CNN 기초&lt;/a&gt; 내용에 이어지는 포스팅입니다.&lt;/p&gt;

&lt;h2 id=&quot;lenet-모델&quot;&gt;LeNet 모델&lt;/h2&gt;
&lt;p&gt;여기서는 LeNet-5 모델에 대해 간단히 살펴봅니다.&lt;/p&gt;

&lt;p&gt;LeNet은 거의 최초의 CNN을 이용한 image classification 모델이라고 할 수 있습니다. Turing award 수상자이며, 사실상 CNN의 아버지 격인 Yann Lecun의 연구팀이 1998년에 개발하였고 그 이름을 따서 LeNet이라는 이름을 갖게 되었습니다. “Gradient Based Learning Applied to Document Recognition” 라는 제목의 논문으로 발표되었는데, 제목에서 알 수 있듯 본래 손글씨로 쓰인 글자를 구분하는 task를 해결하기 위해 개발되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/cd97eccdcd206c69165bedbe52ab311cecf6e35e340166c1780794892fed550e.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 구조는 LeNet의 전체적인 모델입니다. &lt;a href=&quot;/deep-learning-study/convolutionary-neural-networks/&quot;&gt;CNN 기초&lt;/a&gt; 에 있는 각 레이어별 설명을 모두 이해했다는 가정하에, LeNet의 ‘선택’ 만 살펴보겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;첫 레이어는 $5 \times 5$ Convolution filter 6개를 사용합니다.&lt;/li&gt;
  &lt;li&gt;Subsampling은 average pooling을 사용하고&lt;/li&gt;
  &lt;li&gt;Activation function으로는 tanh의 약간 변형된 형태를 사용합니다.&lt;/li&gt;
  &lt;li&gt;재밌는 점은 C3 Layer가 일반적인 convolution이 아니라는 점입니다. 원본 논문에 의하면, symmetry를 깨기 위해서 S2-&amp;gt;C3 convolution을 할 때, 6개 채널 전부가 아닌 채널 일부만 사용해서 convolution을 수행합니다. 
&lt;img src=&quot;../../images/591aba20e38405a3f2c2fef76a765f3ac12b5b8abc6c3c9c8410ab22f8abc678.png&quot; alt=&quot;picture 2&quot; /&gt;  이와 같이, 0번째 컨볼루션은 0, 1, 2 채널만 쓰고… 하는 방법입니다.&lt;/li&gt;
  &lt;li&gt;Fully connected layer를 2번 탄 다음, 마지막에는 Gaussian connection이라는 조금 복잡한 방법을 사용합니다. 후술할 이유로 인해 자세히 설명하지는 않겠습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 이어진 후속연구에 의해, 꼭 이런 design choice를 지킬 필요가 없음이 알려졌습니다. 구현의 단순함과 성능을 위해 모델을 조금 수정해서 다음과 같이 구현하겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Subsampling에는 avg pooling이 아닌 max pooling을 사용합니다.&lt;/li&gt;
  &lt;li&gt;Activation으로 ReLU를 사용하겠습니다.&lt;/li&gt;
  &lt;li&gt;굳이 Symmetry를 이런 방법으로 깨지 않아도, initialization을 잘 하면 상관 없다고 합니다. Symmetry-breaking connection은 버리겠습니다.&lt;/li&gt;
  &lt;li&gt;Gaussian connection도 하지 않아도 됩니다. 그냥 Fully connected layer로 충분하다고 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;
&lt;p&gt;구현은 &lt;a href=&quot;/deep-learning-study/mnist-mlp/&quot;&gt;MLP로 MNIST 풀어보기&lt;/a&gt; 와 크게 다르지 않습니다.&lt;/p&gt;

&lt;p&gt;MNIST 데이터 로딩하는 부분의 코드를 그대로 가져옵니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optimizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist_data/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist_data/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cuda&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제, LeNet 모델을 정의합니다. Convolution 연산을 쓴다는것 외에는 여전히 다른점이 없습니다.&lt;/p&gt;

&lt;p&gt;모델의 정의가 위 그림과 다른점이 하나 더 있는데, 그림에서는 첫 layer에 패딩을 쓰지 않는 대신 이미지 크기가 32 by 32였지만, 우리가 가진 MNIST 데이터는 28 by 28이기 때문에 첫 레이어에서 패딩 2를 넣어 줍니다. 이후에는 위 설명과 똑같습니다. Optimizer로는 여기서도 SGD를 쓰겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C5_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C5_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeNetModern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchsummary&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이렇게 얻은 model의 summary는 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 28, 28]             156
              ReLU-2            [-1, 6, 28, 28]               0
         MaxPool2d-3            [-1, 6, 14, 14]               0
            Conv2d-4           [-1, 16, 10, 10]           2,416
              ReLU-5           [-1, 16, 10, 10]               0
         MaxPool2d-6             [-1, 16, 5, 5]               0
            Linear-7                  [-1, 120]          48,120
              ReLU-8                  [-1, 120]               0
            Linear-9                   [-1, 84]          10,164
             ReLU-10                   [-1, 84]               0
           Linear-11                   [-1, 10]             850
================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 0.24
Estimated Total Size (MB): 0.35
----------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;6만 개의 parameter를 갖는 매우 작은 모델입니다.&lt;/p&gt;

&lt;p&gt;이제 데이터를 이용해서 이 모델을 실제로 훈련합니다. Train 방법도 MLP에서와 똑같습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; : loss &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt; 로 기존 MLP 모델에 남아있던 gradient 값들을 다 날리고&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_loss&lt;/code&gt; 는 현재 시점에 모델이 이미지를 받아서 추측을 해보고 그 loss function 값을 확인하고,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.backward()&lt;/code&gt; 로 현재 시점의 gradient를 계산하고&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizer.step()&lt;/code&gt; 으로 실제 optimization (여기선 SGD)를 수행합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;거의 같은 방법으로, Test set에 대해서 실제 정확도를 확인합니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view_as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'''[Test set]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Average loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, 
Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%)'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;저는 20번의 epoch (대략 1분 정도의 training) 후에 98.25%의 정확도를 얻을 수 있었습니다.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">Image Segmentation - Single Layer Model</title><link href="http://localhost:4000/image-segmentation-2021/single-layer-convolution/" rel="alternate" type="text/html" title="Image Segmentation - Single Layer Model" /><published>2021-11-06T00:00:00+09:00</published><updated>2021-11-06T00:00:00+09:00</updated><id>http://localhost:4000/image-segmentation-2021/single-layer-convolution</id><content type="html" xml:base="http://localhost:4000/image-segmentation-2021/single-layer-convolution/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#model-만들기&quot; id=&quot;markdown-toc-model-만들기&quot;&gt;Model 만들기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#training&quot; id=&quot;markdown-toc-training&quot;&gt;Training&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#results&quot; id=&quot;markdown-toc-results&quot;&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이번 포스팅에서는 구현이 &lt;strong&gt;어떤 식으로&lt;/strong&gt; 동작해야 하는지를 대충 알아보기 위해, 생각할 수 있는 가장 단순한 모델인 &lt;strong&gt;1-layer convolution&lt;/strong&gt;을 이용해 semantic segmentation을 시도합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/image-segmentation-2021/preparation&quot;&gt;Preparation post&lt;/a&gt; 에서 이어집니다.&lt;/p&gt;

&lt;h2 id=&quot;model-만들기&quot;&gt;Model 만들기&lt;/h2&gt;
&lt;p&gt;Pytorch에서 model은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torch.nn.Module&lt;/code&gt; 형태의 클래스로 만들 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# models/single_conv.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SingleConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SingleConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;우리는 RGB 3개 채널을 갖는 이미지를 받아서, 23개 클래스 중 하나를 구분할 것입니다. 즉, 입력은 $3 \times W \times H$ 형태일 것이며, 출력은 각 $(i, j)$ 마다 23개의 클래스에 대한 probability를 출력해야 합니다. ($23 \times W \times H$)&lt;/p&gt;

&lt;p&gt;우리가 생각할 수 있는 가장 간단한 형태의 모델은 단 한 번의 convolution layer로 구성된 모델일 것입니다. 이 모델은 $3 \times f \times f$ 크기의 convolution filter 23개가 각 클래스에 대응하며, 각 filter는 trainable weight과 bias를 갖습니다. 즉 파라미터는 여기서 $27 \times 23$개의 weight과 23개의 bias로 총 644개가 됩니다. 각 클래스의 확률값은 convolution연산과 ReLU 한번으로 바로 결과값이 도출됩니다.&lt;/p&gt;

&lt;p&gt;이 모델을 정의하는 것까지를 코드로 옮기면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# main.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datautils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;evaluate&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 

&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import_drone_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SingleConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;여기서 batch size는 GPU 메모리에 들어가는 한 많이 욱여넣는 것이 일반적입니다. 저는 1070Ti를 쓰기 때문에 6정도는 괜찮은것 같습니다. 다른 함수들은 앞서 Prep에서 준비한 함수들입니다. summary가 반환하는 결과가 아래와 같이 나타납니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 23, 600, 400]             644
              ReLU-2         [-1, 23, 600, 400]               0
================================================================
Total params: 644
Trainable params: 644
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 2.75
Forward/backward pass size (MB): 84.23
Params size (MB): 0.00
Estimated Total Size (MB): 86.98
----------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;우리가 예상했던 대로 644개의 trainable param을 갖는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;
&lt;p&gt;이제 모델을 정의했다면, 이 모델의 633개의 parameter를 실제로 train해 줘야 합니다. Train은 크게 두 과정으로 이루어집니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Forward pass로 훈련용 데이터를 먹여서, 최종 결과를 도출한 다음, 이 결과를 ground truth와 비교해서 얼마나 다른지 (loss function)의 값을 측정&lt;/li&gt;
  &lt;li&gt;그 값을 최소화하는 방향으로 뭔가 optimization 알고리즘을 적용.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;전체적인 CNN 모델 훈련의 이론에 대해서 다룬 포스팅들과, LeNet을 이용해서 pytorch에서 classification 하는 포스팅 (&lt;a href=&quot;/deep-learning-study/LeNet-MNIST&quot;&gt;LeNet으로 MNIST 풀어보기&lt;/a&gt;)가 있으므로 이쪽을 참고해 주세요.&lt;/p&gt;

&lt;p&gt;여기서의 훈련과정은 LeNet MNIST훈련과 크게 다르지 않습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# train.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;acc_metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel_accuracy&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;EPOCH &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; training begins...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc_metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Train epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; / &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Loss &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Accr &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Time &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; min&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train_loss'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'train_acc'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Total training time &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; minutes taken&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;LeNet으로 MNIST 풀어보는 포스팅에서 다뤘던 것과 거의 같습니다. 여러 모델에 대해 실험하기 위해 함수로 만들었다는 정도만 차이가 있습니다. 달라지는 부분이 거의 없으므로, LeNet 포스팅을 참조해 주세요.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;train data를 로딩할 data loader를 받고&lt;/li&gt;
  &lt;li&gt;몇 epoch 돌릴지를 파라미터로 받고&lt;/li&gt;
  &lt;li&gt;어떤 loss function을 어떤 optimizer로 훈련하고&lt;/li&gt;
  &lt;li&gt;어떤 방법으로 accuracy를 측정할지 (사실 훈련 자체에는 상관이 없는데, 눈으로 보기 위해서입니다) 정합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제, 마지막으로 이 모두를 합쳐서 최종 로직을 작성합니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# main.py
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.003&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;evaluator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ModelEvaluation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;evaluator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 모델에 뭔가 노력을 기울이는 것은 의미가 없으므로, 아무렇게나 5 epoch를 돌립니다. loss function과 optimizer도 일반적인 Cross Entropy Loss 와 Adam을 그대로 집어넣습니다. 이렇게 좀 기다려 보면…&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;../../images/5016c106c073b550e189e3d0242abd0ba532280a4eed9c4c27025aed43c46510.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;br /&gt;
이 결과는 8번 이미지에 대한 결과입니다. 모델이 대부분을 void로 잡아내긴 했는데, 뭔가 이미지의 큰 청크들에 대해 분명 trivial하지 않게 뭔가를 잡아낸 것 같아 보입니다.&lt;/p&gt;

&lt;p&gt;이는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;show_qualitative&lt;/code&gt;로 뽑은 결과인데, evaluate한 결과는 평균 pixel accuracy 47%정도가 나왔습니다. 이 프로젝트는 앞으로 다양한 방법을 이용해 이를 85% 내지는 그 이상으로 올릴 계획입니다.&lt;/p&gt;</content><author><name></name></author><category term="image-segmentation-2021" /><summary type="html">Contents</summary></entry><entry><title type="html">Image Segmentation - Preparation</title><link href="http://localhost:4000/image-segmentation-2021/preparation/" rel="alternate" type="text/html" title="Image Segmentation - Preparation" /><published>2021-11-01T00:00:00+09:00</published><updated>2021-11-01T00:00:00+09:00</updated><id>http://localhost:4000/image-segmentation-2021/preparation</id><content type="html" xml:base="http://localhost:4000/image-segmentation-2021/preparation/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data-preparation&quot; id=&quot;markdown-toc-data-preparation&quot;&gt;Data preparation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dataset&quot; id=&quot;markdown-toc-dataset&quot;&gt;Dataset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#evaluation-of-model&quot; id=&quot;markdown-toc-evaluation-of-model&quot;&gt;Evaluation of Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;앞으로 이 프로젝트에서 사용하는 코드는 모두 &lt;a href=&quot;https://github.com/gratus907/Image-Segmentation-Study&quot;&gt;Github Repo&lt;/a&gt; 에 올라갈 예정입니다. 오늘은 먼저, 데이터 등을 준비하는 과정을 진행합니다.&lt;/p&gt;

&lt;h2 id=&quot;data-preparation&quot;&gt;Data preparation&lt;/h2&gt;
&lt;p&gt;TU Graz에서 제공하는 &lt;strong&gt;Drone aerial image&lt;/strong&gt; 데이터를 이용하려고 합니다. &lt;a href=&quot;https://www.tugraz.at/index.php?id=22387&quot;&gt;링크&lt;/a&gt; 에서 다운로드받을 수 있습니다. 사진 400장의 데이터셋이지만 굉장히 용량이 크고 (4.1GB, 각 이미지가 무려 &lt;strong&gt;6000 by 4000&lt;/strong&gt; 입니다) pixel-accurate한 라벨이 달려있는데다 클래스는 23개로 많지 않아서 적당하다고 생각했습니다. 여기서는 360개를 training에, 40개를 test에 쓰겠습니다.&lt;/p&gt;

&lt;p&gt;먼저, 필요한 모듈들을 import해서 때려넣습니다. 별로 좋은 practice는 아니지만, 다양한 모델들을 테스트해보는 의미가 있으므로 코드의 아름다움은 잠시 접어두기로 합시다. Jupyter Notebook이나 Colab을 사용한다면 훨씬 편하게 테스트할 수 있겠지만, 전체를 깃헙에 올려서 바로 볼 수 있게 하기 위해 그냥 일반 파이썬 코딩할때처럼 하겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# basics.py 
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PIL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchsummary&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cuda&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.485&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.456&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.406&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;device 등은 사실 모든 딥러닝에서 공통적으로 쓰는 GPU 코드이므로 별로 특별한 의미가 있지는 않고, 특이한 점은 mean과 std입니다. 이 값은 RGB 각 채널을 normalize하기 위한 값인데요. 0.5가 아닌 이유는 이 값들이 사실 ImageNet에서 훈련된 결과 값인데, 원칙적으로는 새로운 mean과 std를 train하는 것이 의미가 있겠지만 100만장의 ImageNet 데이터를 믿고 그냥 써도 큰 문제가 없습니다.&lt;/p&gt;

&lt;h2 id=&quot;dataset&quot;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;pytorch에서 custom dataset을 사용할 때는, torch.utils.data.Dataset 클래스를 만들면 됩니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# datautils.py 
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DroneDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cvtColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COLOR_BGR2RGB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interpolation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTER_NEAREST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMREAD_GRAYSCALE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interpolation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTER_NEAREST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;일단은 data augmentation 등은 아무것도 생각하지 말고, 정말 순수한 bare minimum만 생각합니다.&lt;/p&gt;

&lt;p&gt;간단히 해석해보면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__&lt;/code&gt; 는 img_path, mask_path 등을 받아서 이 데이터셋의 위치와, 어떤 transform을 적용할지 (transform이란, 이미지를 텐서로 바꾸는 연산) 기억합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__getitem__&lt;/code&gt;은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data[3]&lt;/code&gt; 과 같이 쓰기 위해서 override하는 method로, 이미지를 잘 읽고 적절하게 변환해서 뱉어줍니다.&lt;/li&gt;
  &lt;li&gt;6000 * 4000은 진짜 좀 너무 크기 때문에, 이미지 크기는 600 * 400으로 줄였습니다. 줄일때는 NEAREST를 써야 mask의 라벨이 이상해지지 않습니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test&lt;/code&gt; 데이터에 대해서는 Image를 그대로 저장하고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;training&lt;/code&gt; 데이터에 대해서는 이를 torch tensor로 바꿔서 저장합니다. 이렇게 하는 이유는, 나중에 정성적으로 segmentation의 퀄리티를 확인하고 싶을 때 이미지를 같이 display하려면 test에 대해서는 이미지를 갖고있는게 편하기 때문이&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 이 파일을 실제 모델에 적용하기 위해, training / test 데이터셋으로 잘라줘야 합니다. 이를 편하게 잘라주는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sklearn.model_selection.train_test_split&lt;/code&gt;이 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# datautils.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;import_drone_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;../dataset/semantic_drone_dataset/original_images/&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;MASK_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;../dataset/semantic_drone_dataset/label_images_semantic/&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dirname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;walk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DroneDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MASK_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DroneDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MASK_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;evaluation-of-model&quot;&gt;Evaluation of Model&lt;/h2&gt;
&lt;p&gt;모델을 만들기 전에 일단 모델이 있다면 어떻게 동작해야 할지를 먼저 생각해 봅니다. 좀 오래된 말이긴 하지만, 머신러닝을 정의하는 방법 중 한가지는 T, P, E 라고 해서…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;T&lt;/strong&gt;ask : 어떤 명확하게 정의되는 작업을 수행하고 싶고,&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;P&lt;/strong&gt;erformance Measure : 현재 가지고 있는 프로그램의 성능을 측정하는 방법이 있으며,&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;E&lt;/strong&gt;xperience : 데이터로부터 프로그램이 &lt;strong&gt;P&lt;/strong&gt;를 발전시키기 위해 노력한다는 것입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우리는 아직 프로그램을 작성하지 않았지만, semantic segmentation이라는 &lt;strong&gt;T&lt;/strong&gt;에 집중할 것입니다. &lt;strong&gt;P&lt;/strong&gt;를 어떻게 할지는 이 자체로도 독립된 포스팅이 필요한데, mIoU, Hausdorff distance등 재밌는게 많습니다. 이중 가장 생각하기 쉬운 것은 그냥 pixel단위로 맞은 픽셀수 / 전체 픽셀수를 세는 것입니다.&lt;/p&gt;

&lt;p&gt;Pytorch에서는 모델이 어떤 input image를 받아서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model(x)&lt;/code&gt; 과 같은 식으로 call해서 inference를 진행합니다. 그 결과를 실제 mask와 비교해서 정확도를 측정해야 합니다.&lt;/p&gt;

&lt;p&gt;Bare minimum의 철학에 따라 일단 pixel accuracy만을 구현합니다. 다만 나중에 여러 다른 metric을 구현할 수 있음을 염두에 두고, metrics.py로 따로 파일을 빼겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# metrics.py 
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pixel_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Pixel accuracy를 계산할때는 backpropagation용 gradient가 필요하지 않으므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with torch.no_grad():&lt;/code&gt; 로 감싸서 제낍니다.&lt;/p&gt;

&lt;p&gt;이제, 편하게 테스트를 여러번 시도하기 위해 테스트를 돌리는 클래스를 따로 만들겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# evaluate.py 
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ModelEvaluation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Mean accruacy = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;show_qualitative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pred_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inv_normalize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.485&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.456&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.406&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inv_normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapaxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapaxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Picture'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Ground truth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_axis_off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Model | score &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_axis_off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__&lt;/code&gt;에서는 어떤 모델을 테스트하는지, 어떤 데이터에 대해 테스트하는지, 그리고 어떤 metric을 사용할 것인지를 정합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;evaluate_single()&lt;/code&gt; 은 이미지 한 개를 받아서 이를 normalize한다음 실제로 inference해 봅니다. 결과로 predicted mask와 그 정확도를 반환합니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unsqueeze&lt;/code&gt;는 간단히 그냥 텐서를 쭉 잡아펴주는 연산으로 생각하면 됩니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;evaluate_all()&lt;/code&gt; 은 평균 정확도를 측정합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;show_qualitative()&lt;/code&gt; 는 결과의 정성적 평가를 위한 것으로, 특정 이미지에 대한 image, ground truth, prediction을 동시에 띄워줍니다. 실제로 이미지를 띄워야 하기 때문에, Dataset을 만들때 ToTensor와 Normalize했던 것을 다시 거꾸로 돌려줘야 합니다. Normalize의 정의를 이용하여 이부분은 적당히 처리해줄 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음 포스팅에서는 train을 어떻게 실제로 실행할지와, 이를 이용해서 아주 간단한 모델을 한번 확인해보는 정도를 진행할 예정입니다.&lt;/p&gt;</content><author><name></name></author><category term="image-segmentation-2021" /><summary type="html">Contents 앞으로 이 프로젝트에서 사용하는 코드는 모두 Github Repo 에 올라갈 예정입니다. 오늘은 먼저, 데이터 등을 준비하는 과정을 진행합니다.</summary></entry><entry><title type="html">Aho-Corasick Multiple Pattern Matching</title><link href="http://localhost:4000/advanced-algorithms/aho-corasick-algorithm/" rel="alternate" type="text/html" title="Aho-Corasick Multiple Pattern Matching" /><published>2021-10-27T00:00:00+09:00</published><updated>2021-10-27T00:00:00+09:00</updated><id>http://localhost:4000/advanced-algorithms/aho-corasick-algorithm</id><content type="html" xml:base="http://localhost:4000/advanced-algorithms/aho-corasick-algorithm/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#motivation&quot; id=&quot;markdown-toc-motivation&quot;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#algorithm&quot; id=&quot;markdown-toc-algorithm&quot;&gt;Algorithm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#complexity&quot; id=&quot;markdown-toc-complexity&quot;&gt;Complexity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#구현&quot; id=&quot;markdown-toc-구현&quot;&gt;구현&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;(아직 작성 중인 글입니다)&lt;/p&gt;

&lt;p&gt;이 글은 KMP 알고리즘과 Trie 자료구조에 대한 이해를 선행으로 요구합니다.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;어떤 $n$글자의 긴 텍스트 $T$에 대해, 짧은 $m$글자의 패턴 $P$를 매칭하는 문제를 생각해 보겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;가장 Naive하게 $T$의 모든 위치에 대해 $m$글자를 매칭해보는 알고리즘은 $O(nm)$ 입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm&quot;&gt;KMP 알고리즘&lt;/a&gt; 은 (언젠가 작성할 계획은 있지만 우선순위는 낮습니다) 이를 $O(n + m)$ 으로 줄인 엄청난 성과를 보입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;KMP가 이를 가능하게 하는 방법은, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T[i..i+L-1]&lt;/code&gt; 과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P&lt;/code&gt;를 매칭하다가 중간에 실패했다고 할 때, Naive 매칭은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T[i+1..i+L]&lt;/code&gt; 을 시도하면서 앞서의 정보를 전혀 이용하지 못합니다. 그러나, 패턴이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abababa&lt;/code&gt;인데, ababa까지 맞고 여섯번째 b가 틀렸다면, 앞 다섯글자까지 맞았다는 정보를 최대한 이용하고 싶습니다. 이를 정말 가능한 최대로 이용하는 것이 KMP 알고리즘이며, 위 위키피디아의 링크와 함께 &lt;a href=&quot;https://bowbowbow.tistory.com/6&quot;&gt;BowBowBow님의 블로그&lt;/a&gt; 글을 참고하면 그렇게 어렵지 않게 배울 수 있습니다. 요점은, 앞 몇글자가 맞았음을 이용해서 절대 맞을리가 없는 위치들을 스킵하는 것입니다. 이를 &lt;strong&gt;실패함수&lt;/strong&gt; 라고 부릅니다.&lt;/p&gt;

&lt;p&gt;이제, 이를 패턴이 여러 개인 경우로 확장하고자 합니다. 패턴이 $m_1, m_2, \dots m_k$ 글자의 $P_1, \dots P_k$ 라고 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;실패함수는 결국 어떤 prefix까지는 맞았다는 것을 알고 있는 데서 오는데, 우리는 여러 개의 패턴에 대해 비슷한 정보를 관리하고 싶습니다.&lt;/p&gt;

&lt;p&gt;Prefix 여러개를 동시에 관리하는 것은 Trie를 이용할 수 있습니다. 
&lt;img src=&quot;../../images/a9c2c1743cbd0e6d4b5a6ec257e0bd5864552d77867f1eadf2eb9747fb4a87c5.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 그림을 보면, 파란 간선과 함께 빨간 간선이 그려져 있습니다. 파란 간선은 우리가 일반적으로 알고 있는 Trie의 간선이고, 빨간 간선은 Failure function을 의미합니다. 우리는 다음과 같이 Failure function을 정의합니다.&lt;/p&gt;

&lt;p&gt;“패턴 $P$에 대해, 그 prefix $P’$ 까지를 현재 매칭했다고 하자. 이때, $P’$에 해당하는 노드의 실패-노드 $f(P’)$ 을 찾는데, 이는 $P’$의 &lt;strong&gt;proper suffix&lt;/strong&gt;이면서, &lt;strong&gt;다른 패턴의 prefix&lt;/strong&gt; 인 가장 깊은 노드여야 한다”&lt;/p&gt;

&lt;p&gt;이 조건이 무슨 뜻인지 생각해보면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$P’$을 매칭하다가 실패했다고 하겠습니다. 이제 더이상 이 패턴은 진행할 수 없습니다.&lt;/li&gt;
  &lt;li&gt;그러면 이제, 무슨 패턴을 노릴지 결정해야 합니다. 그림에서 cacba를 텍스트 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T[i..]&lt;/code&gt;에다가 대고 매칭하다가 실패했다면 현재 위치에서 당장 노릴 수 있는 패턴은 acba, cba, ba, a 등으로 시작하는 패턴을 노릴 수 있습니다.&lt;/li&gt;
  &lt;li&gt;이들 중 어떤 다른 패턴의 prefix여야 노리는 것이 의미가 있을 것입니다.&lt;/li&gt;
  &lt;li&gt;이러한 노드들이 여러 개 있다면, acba 노드와 cba 노드 중에는 acba 노드를 먼저 확인해야 합니다. 이유는, acba… 를 매칭하다가 실패하면 cba… 패턴은 그 다음에 노려도 되기 때문입니다.&lt;/li&gt;
  &lt;li&gt;즉, 텍스트를 스캔하면서 트라이를 따라서 움직이다가, 트라이에서 더이상 갈곳이 없으면 최대한 다른 끝점을 노릴 수 있는 곳으로 이동해서 계속 시도한다는 의미가 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;트라이는 빠르게 construct할 수 있으므로, 이러한 실패함수를 어떻게 계산할지만 따로 생각하면 됩니다. 실패함수는 BFS를 이용하여, depth가 얕은 노드부터 깊은 노드로 건설합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;지금 노드 $x$를 보고 있다면, 이 $x$보다 깊이가 얕은 노드 중 반드시 $f(x)$ 가 존재합니다. (proper suffix의 길이는 자기자신보다 짧으므로)&lt;/li&gt;
  &lt;li&gt;$x$의 바로 위 부모노드 $p(x)$ 와, $p(x)$에서 $x$로 오는 edge의 알파벳 (즉 $x$의 마지막 글자에 해당하는 알파벳)을 알고 있습니다. 이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c&lt;/code&gt; 라고 하겠습니다.&lt;/li&gt;
  &lt;li&gt;또한, 실패함수는 depth가 얕은 노드부터 계산했으므로 $f(p(x))$ 도 알고 있습니다. 만약 $f(p(x))$ 에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c&lt;/code&gt;를 이용하여 전진하는 edge가 있다면, 이를 따라 전진합니다.&lt;/li&gt;
  &lt;li&gt;그렇지 않다면, $f(f(p(x)))$ 에다 대고 시도하고… 를 반복하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;만약 트라이를 따라가다가 어떤 패턴의 끝을 만나면, 그 패턴을 찾았다고 report하면 됩니다. 즉 각 노드는 혹시 내가 어떤 패턴의 끝은 아닌지를 미리 기억하고 있어야 합니다. 이 정보는 사실 Trie에 문자열들을 집어넣을때 미리 잡아줄 수 있으므로 크게 문제될 것이 없습니다.&lt;/p&gt;

&lt;p&gt;스캔의 과정을 pseudocode로 표현해 보면 다음과 같습니다.
&lt;img src=&quot;../../images/6027d1807c7529d3d303be17844021b919f73bbb3ead7fdfbafc7590b459126b.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;complexity&quot;&gt;Complexity&lt;/h2&gt;
&lt;p&gt;알파벳 크기를 $q$, 패턴 전체의 글자수의 총합을 $M$, 텍스트의 글자수를 $n$이라고 하겠습니다. 이때,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pseudocode를 보면 자명하게 스캔은 $O(n)$ 인것 같지만, 실제로는 $n$에 next 함수가 소모하는 시간만큼이 걸립니다.&lt;/li&gt;
  &lt;li&gt;트라이를 구성하는 방법은 구현에 따라 다른데, 가장 일반적인 구현인 child pointer array 방식을 쓰는 경우 $O(qM)$ 시간에 트라이를 구성할 수 있으며 (BFS를 돌려야 해서 이만큼이 소모됩니다) $O(qM)$ 메모리를 소비합니다.&lt;/li&gt;
  &lt;li&gt;$q$가 크면 이것이 비효율적일 수 있는데, 트라이의 각 노드에 BBST같은걸 쓴다거나 링크드 리스트를 쓰면 복잡도가 달라집니다. 대표적으로 BBST를 쓰면 $O(M \log q)$ 시간에 트라이를 구성할 수 있고, $O(M \log q)$ 메모리를 소비하는 대신, next가 $O(\log q)$ 시간이 들게 되므로 스캔이 $O(n \log q)$ 걸립니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서, 종합하면 간단하게는 $O(qM + n)$ 시간과 $O(qM)$ 공간을 이용하여 multiple pattern matching을 할 수 있게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;
&lt;p&gt;추가 예정.&lt;/p&gt;</content><author><name></name></author><category term="advanced-algorithms" /><summary type="html">Contents</summary></entry></feed>