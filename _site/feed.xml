<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-10-22T20:47:47+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
</subtitle><entry><title type="html">Convolutionary Neural Networks : Introduction</title><link href="http://localhost:4000/deep-learning-study/convolutionary-neural-networks/" rel="alternate" type="text/html" title="Convolutionary Neural Networks : Introduction" /><published>2021-10-17T00:00:00+09:00</published><updated>2021-10-17T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/convolutionary-neural-networks</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/convolutionary-neural-networks/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#convolution&quot; id=&quot;markdown-toc-convolution&quot;&gt;Convolution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pooling&quot; id=&quot;markdown-toc-pooling&quot;&gt;Pooling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#convolutionary-neural-network&quot; id=&quot;markdown-toc-convolutionary-neural-network&quot;&gt;Convolutionary Neural Network&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-cnn&quot; id=&quot;markdown-toc-why-cnn&quot;&gt;Why CNN?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#next-posts&quot; id=&quot;markdown-toc-next-posts&quot;&gt;Next posts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 7강 (9월 28일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;매우 유명한 &lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;Standford CS231n 자료&lt;/a&gt; 도 참고하면 좋습니다.&lt;/p&gt;

&lt;h2 id=&quot;convolution&quot;&gt;Convolution&lt;/h2&gt;
&lt;p&gt;Convolution은 수학적으로 굉장히 다양한 대상들에 대해서 잘 정의된 연산인데, 우리는 $n$차원 텐서 (배열) 에 대해서만 생각하겠습니다.&lt;/p&gt;

&lt;p&gt;다음 그림과 같이, Convolution은 Filter 또는 Kernel 이라는 (그림의 노란색 행렬) 을 “밀면서” 내적을 반복해서 새로운 행렬을 얻는 연산입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/86b0e614b1f1445063f784261b4925e98524f0af7c7c3ec0692c3662bb9e631d.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;br /&gt;
&lt;a href=&quot;https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&quot;&gt;이미지 출처 : towardsdatascience.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;일반적으로, 이미지 처리에서 CNN을 가장 많이 쓰기 때문에 CNN의 입력은 3차원 텐서 (배열) 로 가정하고, filter도 3차원 텐서 (배열) 로 가정합니다. 이미지가 2차원임에도 3차원 텐서를 쓰는 이유는 이 텐서의 정체를 보면 알 수 있습니다. 보통은 세 차원을 Channel * Width * Height 으로 부르는데, Channel은 초기 입력 단계에서는 &lt;strong&gt;R G B&lt;/strong&gt; 의 색 정보를 나타냅니다.&lt;/p&gt;

&lt;p&gt;그래서, 3차원 텐서지만 실재로는 여러 채널이 있는 W * H 크기의 행렬의 묶음으로 생각하면 됩니다. $C * W * H$ 입력 이미지에 대해 $C * 3 * 3$ 필터를 쓰게 되면 실제로 공간적으로 필터를 밀어 볼 수 있는 방향은 (가로, 세로) 방향으로만 밀면 되므로, $(W - 2) * (H - 2)$ 크기의 결과를 얻습니다. 그러나 우리는 여러 정보를 동시에 인코딩해서 가져가고 싶기 때문에, 실제로는 동시에 $D$개의 $C * 3 * 3$ 필터를 사용합니다.&lt;/p&gt;

&lt;p&gt;이렇게 해서 얻어진 각 행렬들을 모두 연결하면, $D * (W - 2) * (H - 2)$ 크기의 output을 얻습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Padding :&lt;/strong&gt; 우리가 $W * H$ 크기의 이미지를 가지고 있고, 이 이미지에 $3 * 3$ filter를 convolution하면, $(W - 2) * (H - 2)$ 크기가 된다는 것은 쉽게 알 수 있습니다. 이는 맨 외곽 칸까지 밀게 되면 필터가 이미지 바깥으로 일부가 나가버리기 때문인데, 이를 보정하기 위해 이미지의 맨 외곽선을 0으로 쭉 한칸 더 만들어 주는 방법이 있습니다. 이를 Padding이라고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stride :&lt;/strong&gt; Filter를 평면상에서 “민다” 고 표현했는데, 위 설명은 매번 “한 칸 씩” 미는 경우를 생각하고 있습니다. 꼭 그럴 필요는 없고, $s$칸씩 한번에 밀 수도 있습니다. 그렇게 하면 당연히 출력의 크기는 더 줄어들게 됩니다. 이 $s$를 Stride라 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bias :&lt;/strong&gt; Convolution한 결과물 전체에 어떤 특정한 상수값을 더해줄 수도 있고, 이를 bias라고 부릅니다.&lt;/p&gt;

&lt;p&gt;여기까지 내용의 요약이 다음 image에 잘 드러나 있습니다. &lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;이미지 출처인 Standford CS231n 자료&lt;/a&gt; 에서는 저 필터가 진짜 움직이는걸 볼 수 있으니 한번쯤 보면 이해하기 좋은 것 같습니다. 그림에는 3개 채널의 5 by 5 이미지에, padding 1을 주었고, 3채널 by 3 by 3 크기의 필터를 쓰며, stride = 2 인 케이스를 보여주고 있습니다. 아래에는 bias도 포함되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/67486f42036dc6a5e62931ee5ca802f2c420dc43111f872087eacb39a9417a1c.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;입력이 $C_i * W_i * H_i$ 이고, padding이 $p$, stride가 $s$이며, 크기가 $C_i * F * F$ 인 필터 $K$개를 쓴다고 하면, convolution을 한번 하고 나면 다음과 같이 계산되는 $C_o * W_o * H_o$ 출력을 얻습니다. 
\(C_o = K \quad \quad W_o = \floor{\frac{W_i - F + 2P}{S} + 1} \quad \quad H_o = \floor{\frac{H_i - F + 2P}{S} + 1}\)&lt;/p&gt;

&lt;h2 id=&quot;pooling&quot;&gt;Pooling&lt;/h2&gt;
&lt;p&gt;CNN은 보통 큰 이미지 데이터를 대상으로 하며, 최초에는 이미지를 분류하는 목적으로 개발되었습니다. 그렇다 보니, 이미지 전체의 수만 픽셀의 데이터를 전부 보기보다는 그 특징을 잡아내는 것이 필요합니다. 또한 만약 신경망에서 잡아낼 수 있는 특징을 크게 훼손하지 않으면서 돌아다니는 데이터의 양을 줄일 수 있다면, training 및 inference 시간을 크게 개선할 수 있을 것입니다.&lt;/p&gt;

&lt;p&gt;이를 위해 pooling이라는 연산을 수행합니다. pooling은 단순히 지금 보고 있는 부분의 max나 avg를 택하는 연산인데, 다음 그림을 보면 쉽게 이해할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/f0d16cb834ed161fb9bc6d2930499da42a45d639ef36dcdd8cc51ea8b2f9a0d6.png&quot; alt=&quot;picture 3&quot; /&gt;&lt;br /&gt;
[이미지 출처 : Stanford CS231n]&lt;/p&gt;

&lt;p&gt;위 그림에서 볼 수 있듯, pooling도 convolution처럼 filter라는 표현을 자주 쓰며, stride와 padding을 줄 수 있습니다. 다만 convolution처럼 뭔가를 train할 필요는 없고, 그냥 그 연산을 수행한다고 생각하면 됩니다. 가장 일반적인 형태의 pooling은 2 by 2 필터에 stride 2로 연산하는 것으로, 2 * 2 정사각형에서 max 또는 avg 하나씩을 남김으로서 데이터의 양을 1/4로 줄입니다.&lt;/p&gt;

&lt;p&gt;Pooling은 각 채널별로 독립적으로 실행할 수 있으므로, 2D 에서만 생각해도 충분합니다. 3D pooling도 똑같이 정의하면 생각할 수는 있겠지만요.&lt;/p&gt;

&lt;h2 id=&quot;convolutionary-neural-network&quot;&gt;Convolutionary Neural Network&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;/deep-learning-study/multilayer-perceptron&quot;&gt;Multi Layer Perceptron&lt;/a&gt; 에서는, Linear Layer - Activation - Linear Layer - Activation - … 의 형태로 깊게 이어진 신경망을 구축했고 이를 Multi-Layer Perceptron이라고 불렀습니다.&lt;/p&gt;

&lt;p&gt;Convolutinary Neural Network, CNN도 큰 틀에서는 비슷합니다. 다만, 좀더 복잡한 아이디어들이 들어가 있습니다.&lt;/p&gt;

&lt;p&gt;가장 기본적인 CNN은 크게 Convolution, Pooling, Activation의 세가지 Layer를 잘 반복해서 구성됩니다.&lt;/p&gt;

&lt;p&gt;Convolution은 앞서 설명한 convolution 연산을 적당한 필터에 대해서 수행하는 것으로, MLP에서 weight 행렬이 train의 대상인 것처럼 여기서는 필터 전체가 training의 대상입니다.&lt;/p&gt;

&lt;p&gt;Activation은 MLP에서처럼 모든 항에 적당한 activation function을 씌워서 신경망에 non-linearity를 제공하는 것입니다. 역시 MLP에서와 마찬가지로 ReLU, sigmoid, tanh 같은 함수들을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;Pooling은 앞서 설명한 pooling을 수행하는 layer입니다.&lt;/p&gt;

&lt;h2 id=&quot;why-cnn&quot;&gt;Why CNN?&lt;/h2&gt;
&lt;p&gt;CNN의 효용에 대해 얘기하려면 기존의 MLP의 특징을 먼저 이야기할 필요가 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;장점 : 간단하고, 이론적으로 굉장히 general합니다. 모든 연속함수를 어떤 정해진 구간에서는 충분히 큰 MLP로 approximate 가능하다는 굉장한 정리가 있는데 (Universal Approximation Theorem) 제가 찾아본 증명은 실해석학 수준의 해석학 지식을 (Hahn-Banach, Riesz Repr thm) 요구하기 때문에 다룰 수가 없습니다.&lt;/li&gt;
  &lt;li&gt;단점 : Parameter가 매우 많아서, overfitting의 문제와 training speed 문제가 발생합니다.&lt;/li&gt;
  &lt;li&gt;단점 : Computer vision에 쓰기에는 shift invariance 같은 것을 잘 처리하지 못한다는 심각한 문제가 있습니다. 특히 image classification 같은 경우, 이미지의 일부를 shift해도 그대로 같은 이미지인데 MLP는 이를 처리하기 어렵습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Convolution은 그 자체로 shift invaraince를 가지기 때문에, 단점 2번을 잘 해결합니다. 또한, 단점 1번의 경우, Convolution의 파라미터가 꽤 많아 보이지만 $W * H$ 이미지를 던져주고 $W * H$ 출력을 만들기 위해서 Linear layer는 파라미터 $W^2H^2$ 개가 필요합니다. 입출력이 200 by 200이면 이 값이 16억인데, convolution은 파라미터가 훨씬 적습니다.&lt;/p&gt;

&lt;p&gt;자연스러운 질문은, 파라미터가 그렇게 적으면 충분히 general하게 학습하지 못하는게 아니냐는 의문이 들 수 있습니다. &lt;a href=&quot;https://arxiv.org/abs/1804.10306&quot;&gt;2018년 논문&lt;/a&gt; 에 따르면 수학적으로는 CNN도 universal approximation theorem이 있다고 하는데, 굳이 이런 놀라운 수학적 결과를 들이밀지 않더라도 이미지 처리에서 CNN이 그동안 보여준 놀라운 성과를 보면 이정도 파라미터로도 Convolution 자체가 어떤 이미지를 ‘대략적으로’ 보는 느낌이 굉장히 직관적으로 좋아서, 잘 작동하는 것으로 보입니다.&lt;/p&gt;

&lt;p&gt;또한, CNN은 MLP보다 같은 크기에서 훨씬 깊은 네트워크를 만들 수 있습니다 (레이어당 파라미터가 적으므로) 이 점도 장점이 될 수 있겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;next-posts&quot;&gt;Next posts&lt;/h2&gt;
&lt;p&gt;CNN의 여러 Model들에 대해 살펴볼 계획입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;LeNet&lt;/li&gt;
  &lt;li&gt;AlexNet&lt;/li&gt;
  &lt;li&gt;VGGNet&lt;/li&gt;
  &lt;li&gt;GoogLeNet&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/deep-learning-study/semantic-segmentation&quot;&gt;Semantic Segmentation&lt;/a&gt; 에서 다룰 모델들.
    &lt;ul&gt;
      &lt;li&gt;U-Net&lt;/li&gt;
      &lt;li&gt;FCN&lt;/li&gt;
      &lt;li&gt;DeepLab&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Convolution Pooling Convolutionary Neural Network Why CNN? Next posts 심층 신경망의 수학적 기초 7강 (9월 28일) 에 기반합니다. 매우 유명한 Standford CS231n 자료 도 참고하면 좋습니다. Convolution Convolution은 수학적으로 굉장히 다양한 대상들에 대해서 잘 정의된 연산인데, 우리는 $n$차원 텐서 (배열) 에 대해서만 생각하겠습니다. 다음 그림과 같이, Convolution은 Filter 또는 Kernel 이라는 (그림의 노란색 행렬) 을 “밀면서” 내적을 반복해서 새로운 행렬을 얻는 연산입니다. 이미지 출처 : towardsdatascience.com 일반적으로, 이미지 처리에서 CNN을 가장 많이 쓰기 때문에 CNN의 입력은 3차원 텐서 (배열) 로 가정하고, filter도 3차원 텐서 (배열) 로 가정합니다. 이미지가 2차원임에도 3차원 텐서를 쓰는 이유는 이 텐서의 정체를 보면 알 수 있습니다. 보통은 세 차원을 Channel * Width * Height 으로 부르는데, Channel은 초기 입력 단계에서는 R G B 의 색 정보를 나타냅니다. 그래서, 3차원 텐서지만 실재로는 여러 채널이 있는 W * H 크기의 행렬의 묶음으로 생각하면 됩니다. $C * W * H$ 입력 이미지에 대해 $C * 3 * 3$ 필터를 쓰게 되면 실제로 공간적으로 필터를 밀어 볼 수 있는 방향은 (가로, 세로) 방향으로만 밀면 되므로, $(W - 2) * (H - 2)$ 크기의 결과를 얻습니다. 그러나 우리는 여러 정보를 동시에 인코딩해서 가져가고 싶기 때문에, 실제로는 동시에 $D$개의 $C * 3 * 3$ 필터를 사용합니다. 이렇게 해서 얻어진 각 행렬들을 모두 연결하면, $D * (W - 2) * (H - 2)$ 크기의 output을 얻습니다. Padding : 우리가 $W * H$ 크기의 이미지를 가지고 있고, 이 이미지에 $3 * 3$ filter를 convolution하면, $(W - 2) * (H - 2)$ 크기가 된다는 것은 쉽게 알 수 있습니다. 이는 맨 외곽 칸까지 밀게 되면 필터가 이미지 바깥으로 일부가 나가버리기 때문인데, 이를 보정하기 위해 이미지의 맨 외곽선을 0으로 쭉 한칸 더 만들어 주는 방법이 있습니다. 이를 Padding이라고 합니다. Stride : Filter를 평면상에서 “민다” 고 표현했는데, 위 설명은 매번 “한 칸 씩” 미는 경우를 생각하고 있습니다. 꼭 그럴 필요는 없고, $s$칸씩 한번에 밀 수도 있습니다. 그렇게 하면 당연히 출력의 크기는 더 줄어들게 됩니다. 이 $s$를 Stride라 합니다. Bias : Convolution한 결과물 전체에 어떤 특정한 상수값을 더해줄 수도 있고, 이를 bias라고 부릅니다. 여기까지 내용의 요약이 다음 image에 잘 드러나 있습니다. 이미지 출처인 Standford CS231n 자료 에서는 저 필터가 진짜 움직이는걸 볼 수 있으니 한번쯤 보면 이해하기 좋은 것 같습니다. 그림에는 3개 채널의 5 by 5 이미지에, padding 1을 주었고, 3채널 by 3 by 3 크기의 필터를 쓰며, stride = 2 인 케이스를 보여주고 있습니다. 아래에는 bias도 포함되어 있습니다. 입력이 $C_i * W_i * H_i$ 이고, padding이 $p$, stride가 $s$이며, 크기가 $C_i * F * F$ 인 필터 $K$개를 쓴다고 하면, convolution을 한번 하고 나면 다음과 같이 계산되는 $C_o * W_o * H_o$ 출력을 얻습니다. \(C_o = K \quad \quad W_o = \floor{\frac{W_i - F + 2P}{S} + 1} \quad \quad H_o = \floor{\frac{H_i - F + 2P}{S} + 1}\) Pooling CNN은 보통 큰 이미지 데이터를 대상으로 하며, 최초에는 이미지를 분류하는 목적으로 개발되었습니다. 그렇다 보니, 이미지 전체의 수만 픽셀의 데이터를 전부 보기보다는 그 특징을 잡아내는 것이 필요합니다. 또한 만약 신경망에서 잡아낼 수 있는 특징을 크게 훼손하지 않으면서 돌아다니는 데이터의 양을 줄일 수 있다면, training 및 inference 시간을 크게 개선할 수 있을 것입니다. 이를 위해 pooling이라는 연산을 수행합니다. pooling은 단순히 지금 보고 있는 부분의 max나 avg를 택하는 연산인데, 다음 그림을 보면 쉽게 이해할 수 있습니다. [이미지 출처 : Stanford CS231n] 위 그림에서 볼 수 있듯, pooling도 convolution처럼 filter라는 표현을 자주 쓰며, stride와 padding을 줄 수 있습니다. 다만 convolution처럼 뭔가를 train할 필요는 없고, 그냥 그 연산을 수행한다고 생각하면 됩니다. 가장 일반적인 형태의 pooling은 2 by 2 필터에 stride 2로 연산하는 것으로, 2 * 2 정사각형에서 max 또는 avg 하나씩을 남김으로서 데이터의 양을 1/4로 줄입니다. Pooling은 각 채널별로 독립적으로 실행할 수 있으므로, 2D 에서만 생각해도 충분합니다. 3D pooling도 똑같이 정의하면 생각할 수는 있겠지만요. Convolutionary Neural Network Multi Layer Perceptron 에서는, Linear Layer - Activation - Linear Layer - Activation - … 의 형태로 깊게 이어진 신경망을 구축했고 이를 Multi-Layer Perceptron이라고 불렀습니다. Convolutinary Neural Network, CNN도 큰 틀에서는 비슷합니다. 다만, 좀더 복잡한 아이디어들이 들어가 있습니다. 가장 기본적인 CNN은 크게 Convolution, Pooling, Activation의 세가지 Layer를 잘 반복해서 구성됩니다. Convolution은 앞서 설명한 convolution 연산을 적당한 필터에 대해서 수행하는 것으로, MLP에서 weight 행렬이 train의 대상인 것처럼 여기서는 필터 전체가 training의 대상입니다. Activation은 MLP에서처럼 모든 항에 적당한 activation function을 씌워서 신경망에 non-linearity를 제공하는 것입니다. 역시 MLP에서와 마찬가지로 ReLU, sigmoid, tanh 같은 함수들을 쓸 수 있습니다. Pooling은 앞서 설명한 pooling을 수행하는 layer입니다. Why CNN? CNN의 효용에 대해 얘기하려면 기존의 MLP의 특징을 먼저 이야기할 필요가 있습니다. 장점 : 간단하고, 이론적으로 굉장히 general합니다. 모든 연속함수를 어떤 정해진 구간에서는 충분히 큰 MLP로 approximate 가능하다는 굉장한 정리가 있는데 (Universal Approximation Theorem) 제가 찾아본 증명은 실해석학 수준의 해석학 지식을 (Hahn-Banach, Riesz Repr thm) 요구하기 때문에 다룰 수가 없습니다. 단점 : Parameter가 매우 많아서, overfitting의 문제와 training speed 문제가 발생합니다. 단점 : Computer vision에 쓰기에는 shift invariance 같은 것을 잘 처리하지 못한다는 심각한 문제가 있습니다. 특히 image classification 같은 경우, 이미지의 일부를 shift해도 그대로 같은 이미지인데 MLP는 이를 처리하기 어렵습니다. Convolution은 그 자체로 shift invaraince를 가지기 때문에, 단점 2번을 잘 해결합니다. 또한, 단점 1번의 경우, Convolution의 파라미터가 꽤 많아 보이지만 $W * H$ 이미지를 던져주고 $W * H$ 출력을 만들기 위해서 Linear layer는 파라미터 $W^2H^2$ 개가 필요합니다. 입출력이 200 by 200이면 이 값이 16억인데, convolution은 파라미터가 훨씬 적습니다. 자연스러운 질문은, 파라미터가 그렇게 적으면 충분히 general하게 학습하지 못하는게 아니냐는 의문이 들 수 있습니다. 2018년 논문 에 따르면 수학적으로는 CNN도 universal approximation theorem이 있다고 하는데, 굳이 이런 놀라운 수학적 결과를 들이밀지 않더라도 이미지 처리에서 CNN이 그동안 보여준 놀라운 성과를 보면 이정도 파라미터로도 Convolution 자체가 어떤 이미지를 ‘대략적으로’ 보는 느낌이 굉장히 직관적으로 좋아서, 잘 작동하는 것으로 보입니다. 또한, CNN은 MLP보다 같은 크기에서 훨씬 깊은 네트워크를 만들 수 있습니다 (레이어당 파라미터가 적으므로) 이 점도 장점이 될 수 있겠습니다. Next posts CNN의 여러 Model들에 대해 살펴볼 계획입니다. LeNet AlexNet VGGNet GoogLeNet Semantic Segmentation 에서 다룰 모델들. U-Net FCN DeepLab</summary></entry><entry><title type="html">ICPC Korea First Round 2021 후기 / 풀이</title><link href="http://localhost:4000/cp-rounds/icpc-2021-prelim/" rel="alternate" type="text/html" title="ICPC Korea First Round 2021 후기 / 풀이" /><published>2021-10-14T00:00:00+09:00</published><updated>2021-10-14T00:00:00+09:00</updated><id>http://localhost:4000/cp-rounds/icpc-2021-prelim</id><content type="html" xml:base="http://localhost:4000/cp-rounds/icpc-2021-prelim/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#preperation--our-team&quot; id=&quot;markdown-toc-preperation--our-team&quot;&gt;Preperation / Our Team&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#본-대회&quot; id=&quot;markdown-toc-본-대회&quot;&gt;본 대회&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-i--sport-climbing-combined&quot; id=&quot;markdown-toc-problem-i--sport-climbing-combined&quot;&gt;Problem I : Sport Climbing Combined&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-e--histogram&quot; id=&quot;markdown-toc-problem-e--histogram&quot;&gt;Problem E : Histogram&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-j--ten&quot; id=&quot;markdown-toc-problem-j--ten&quot;&gt;Problem J : Ten&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-h--similarity&quot; id=&quot;markdown-toc-problem-h--similarity&quot;&gt;Problem H : Similarity&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-b--carrot-field&quot; id=&quot;markdown-toc-problem-b--carrot-field&quot;&gt;Problem B : Carrot Field&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-k--treasure-hunter&quot; id=&quot;markdown-toc-problem-k--treasure-hunter&quot;&gt;Problem K : Treasure Hunter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-c--colorful-tower-of-hanoi&quot; id=&quot;markdown-toc-problem-c--colorful-tower-of-hanoi&quot;&gt;Problem C : Colorful Tower of Hanoi&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#retrospect&quot; id=&quot;markdown-toc-retrospect&quot;&gt;Retrospect&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#about-problemset--our-result&quot; id=&quot;markdown-toc-about-problemset--our-result&quot;&gt;About Problemset / Our result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#about-my-icpc&quot; id=&quot;markdown-toc-about-my-icpc&quot;&gt;About my ICPC&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#대회를-마치며&quot; id=&quot;markdown-toc-대회를-마치며&quot;&gt;대회를 마치며&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;Little Piplup 팀으로 복귀해서 ICPC 2021을 재밌게 치고 왔습니다.&lt;/p&gt;

&lt;p&gt;늘 대회가 끝나고 나면 Whining을 해왔지만, 이번 대회는 솔직히 말하면 Whining할게 별로 없습니다. 18등의 성적을 거두었는데, &lt;strong&gt;풀었어야 할 문제&lt;/strong&gt; 는 다 풀지 않았나 싶습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/ffc1cbe195617fa7de716c8086404b340a6b3419bdc0e214ec7e660b077149b5.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Prep - 대회과정 타임라인에 따른 의식의 흐름 - Retrospect의 순서로 작성합니다.&lt;/p&gt;

&lt;p&gt;평소보다 앞뒤 글이 많이 길고 장황하기 때문에, 왼쪽 아래 Table of Content를 보면 문제에 대한 이야기만 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;preperation--our-team&quot;&gt;Preperation / Our Team&lt;/h2&gt;
&lt;p&gt;팀연습 두번을 했습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;GCPC 2020 : &lt;a href=&quot;/cp-rounds/team-practice-gcpc-2020/&quot;&gt;팀연습 기록 링크&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;BAPC 2020 (기록 미작성)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 팀의 객관적인 전력을 저는 개인적으로 적어도 2100 3명 정도 수준, 내지는 문제셋을 조금 잘 타면 1레드가 섞인 팀과도 비벼볼 수 있다고 생각합니다. 가장 최근의 팀 대회는 Hashcode 2021이었는데, 그때와 지금 팀을 비교하면 (dlwocks31의 부재를 제외하고 세명만) 크게 달라진 것은 없으므로 그때 썼던 기록에 더하여 팀원들에 대한 얘기를 조금 해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Gratus907&lt;/code&gt; : 수학적인 문제에 비교적 강하고, 말리지 않을때까지는 구현이 빠르지만 말리면 한없이 말리는 경향이 있습니다.
    &lt;ul&gt;
      &lt;li&gt;그래도 제 코딩 경험이 쌓이면서 예전만큼 코딩이 말리지 않습니다.&lt;/li&gt;
      &lt;li&gt;반면에, 한번 어떤 방면으로 빠지면 무한한 뇌절을 이어가는 경향이 있습니다. 이는 &lt;a href=&quot;/cp-rounds/SCPC-2021-Round2&quot;&gt;FFT에 패배한 SCPC 2021&lt;/a&gt; 같은 상황에서 정말 끔찍했습니다.&lt;/li&gt;
      &lt;li&gt;수학 복수전공을 통해 얻은 지식은 딱히 PS에 도움이 되지 않지만, 씹덕같은 정수론 문제 한두개를 가끔 쳐낼 수 있는것 같습니다.&lt;/li&gt;
      &lt;li&gt;아카데믹한 알고리즘 공부를 그래도 이중에 가장 많이 했었습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DHDroid&lt;/code&gt; : Constructive한 문제에 매우 강하고, 관찰을 정당화 (증명) 하는 능력이 뛰어납니다.
    &lt;ul&gt;
      &lt;li&gt;이 능력을 실제로 보여준 대회가 역시 SCPC 2021입니다. Round 2 하노이탑에서 일부 레드들도 달성을 어려워했던 250점을 달성하고, 저보다 훨씬 높은 성적으로 2라운드를 마친후 본선에서 5등상을 받는 쾌거를 보여줬습니다.&lt;/li&gt;
      &lt;li&gt;본인의 표현을 빌리자면 정말 어려운 문제에 도전해서 몇 시간 고민을 이어가는 본인의 연습방식이 도움이 된다고 합니다.&lt;/li&gt;
      &lt;li&gt;학과 동기이고 친구지만 이렇게 어려운 문제를 대하는 자세를 보면서 항상 많은 것을 배웁니다.&lt;/li&gt;
      &lt;li&gt;반대로 제한시간이 짧은 대회에 살짝 약합니다. 2시간짜리 코드포스가 가장 대표적이죠.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coffeetea&lt;/code&gt; : 그리디하거나 휴리스틱한 관찰, 대략적인 경향성의 파악에 강합니다. 뭔가 문제에 빙의하는 특성이 있어서 글쓸때 Coffeetea의 표현을 많이 빌리게 됩니다 :)
    &lt;ul&gt;
      &lt;li&gt;저는 그때 이 팀에 없었지만, &lt;a href=&quot;https://www.acmicpc.net/problem/20041&quot;&gt;작년 ICPC F번&lt;/a&gt; 같은 문제에서 가장 잘 느낄 수 있습니다. (이 문제는 그렇게 어렵지 않지만요)&lt;/li&gt;
      &lt;li&gt;Hashcode 스타일의 대회에서 초기 아이디어를 정말 잘 던져주고, 데이터를 슥 보고 특성을 빠르게 캐치합니다.&lt;/li&gt;
      &lt;li&gt;많이 복잡한 구현은 저보다 잘 합니다. 저보다 좀더 구현에 대해 체계적으로 고민하고, 놓치는 케이스가 비교적 적으며, 디버깅할때의 끈기와 자세가 뛰어납니다. 역시 항상 많은 것을 배우게 되는 친구입니다.&lt;/li&gt;
      &lt;li&gt;개발 공부에 많은 시간과 노력을 투자했기 때문에 이런 구현 실력을 갖춘 것 같은데, 반대로 소위 ‘고인물 알고리즘’ 에 대한 공부를 많이 하지는 않았습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;대회 시작 전날까지 팀노트를 작년 제 팀노트에 얹어서 나름대로 열심히 준비했습니다. 후술하지만, 약간의 부족함은 있었습니다.&lt;/p&gt;

&lt;p&gt;팀노트를 준비할 때 생각해야 하는 기준은, (보편 타당한 생각을 제가 나름대로 표현해 보자면) “어 이거 그건데” 와 AC를 받는 시점 사이의 시간의 expectation을 minimize하는 것입니다. 이 말의 의미는, 구현 실수가 날만한 부분들이나 구현이 복잡한 자료구조, 알지만 구글링 없이는 코딩이 불가능한 알고리즘 등을 적어 가야 한다는 것입니다. 저희 팀을 예로 들자면&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;수많은 기하 구현을 준비했습니다. 대회 시간 중에 선분 - 선분 교차를 구현해 보셨나요? ㅋㅋ!&lt;/li&gt;
  &lt;li&gt;segment tree에서 lazy propagation의 개념은 잘 알고 있으나 구현시 실수할 것을 대비하여 적어 갔습니다.&lt;/li&gt;
  &lt;li&gt;Dinic과 HeavyLight Decomposition 등을 적어 갔습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;25페이지는 효율적으로 잘 꾹꾹 눌러 쓰면 생각보다 꽤 많습니다. 저희 팀노트는 [링크] 에서 볼 수 있는데, ICPC 전날 급하게 많은 것을 추가하느라 외관의 아름다움을 많이 잃어버렸습니다만 앞으로 계속 업데이트될 것입니다 (제 개인적으로는 archive의 의미가 있어서요.)&lt;/p&gt;

&lt;p&gt;팀노트 맨 끝장에는 Checkpoint를 붙여 갔습니다. 이 체크포인트는 제가 계속 관리하고 있는 노트인데, 제가 나가는 팀대회에서는 팀노트 맨 끝장에 붙여 나갑니다. 
&lt;img src=&quot;../../images/3767c2dd32cfce8f0d2abd4a81f13d248d4a154766ffde8e9929c218b5ebfe59.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;br /&gt;
(이미지를 우클릭-새 탭으로 열기해서 큰 화면으로 볼 수 있습니다)&lt;/p&gt;

&lt;p&gt;모든 포인트들은 제가 문제를 풀면서 경험해본 것들입니다. PS 오답노트라고나 할까요.&lt;/p&gt;

&lt;h2 id=&quot;본-대회&quot;&gt;본 대회&lt;/h2&gt;

&lt;p&gt;저희는 스터디카페에서 대회를 치렀기 때문에, 문제지가 뜨는걸 확인하는 즉시 제가 인쇄를 하러 나가면서 팀원들이 화면을 반으로 나눠서 A, B를 읽었습니다. 문제지 인쇄까지는 프린터가 느린데다 문제지 합본 pdf 파일이 바로 넘어오지 않아서, 거의 7분 가까운 시간이 소요되었습니다. 그러나 문제지를 인쇄하는 프린터 앞에 서서 저도 문제를 볼 수 있었기 때문에 실질적인 시간상의 로스는 거의 없습니다. 대회 규정상 팀원 1인 이상이 오랜 시간 자리를 비워서는 안되고 (아마도 이 규정이 strictly enforce되는 것은 어차피 기술적으로 불가능했을 것입니다만), 팀원들의 효율을 위해 문제지가 1/3정도 인쇄될 때마다 제가 계속 팀원들에게 배달했습니다.&lt;/p&gt;

&lt;p&gt;그 사이에, I번의 첫 Solve들이 등장하기 시작했습니다. 처음에 어떻게 다른 팀들이 12문제 중 9번째에 있는 문제를 찾아내서 풀었는지 의아했지만, 생각해보니 4/4/4로 분배하면 팀원중 한명에게는 가장 먼저 읽는 문제니까 그런것 같습니다. (그럼에도 약간의 의문이 있습니다. 찾아보니 작년에도 I번이 가장 쉬운 문제였고, 그 전까지는 등록이 있는 자리였는데 혹시 그 사실을 인지하고 있는 팀들이 있을까요?)&lt;/p&gt;

&lt;p&gt;인쇄 중에 저는 팀원들이 A, B 부터 읽고 있음을 감안하여 적당히 몇개 떼고 E를 읽었습니다. 한국어길래 슬쩍 B, C도 한번씩 읽었는데 B는 딱봐도 구현이 노답이고 C는 엄청나게 어려워 보였기 때문에… 제가 인쇄를 마치면서 2시 8분쯤 방에 복귀했는데, 이미 팀원들이 I번을 읽고 솔루션을 제시했으며 B가 구현 노답이라는 사실도 인지하고 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-i--sport-climbing-combined&quot;&gt;Problem I : Sport Climbing Combined&lt;/h3&gt;
&lt;p&gt;Solve : DHdroid&lt;br /&gt;
Code : DHDroid&lt;/p&gt;

&lt;p&gt;무슨 문제인지 방금 처음 읽었는데, 딱히 할말이 없습니다. $p_i \times q_i \times r_i$를 기준으로 정렬해서 그 $b_i$를 출력하면 됩니다. 13분에 AC를 받았습니다.&lt;/p&gt;

&lt;p&gt;이때 저는 E번의 풀이가 간단한 $O(B N^2)$ DP로 가능하다는 것을 이미 인지했기 때문에 ($30 * 4000^2$ 이면 4.8억이지만 실제로는 그 절반만 써서 괜찮습니다), 바로 제가 E를 잡겠다고 주장했습니다. 아무도 E를 풀지 않았다는 사실이 좀 마음에 걸리지만…&lt;/p&gt;

&lt;h3 id=&quot;problem-e--histogram&quot;&gt;Problem E : Histogram&lt;/h3&gt;
&lt;p&gt;Solve : Gratus907&lt;br /&gt;
Code : Gratus907&lt;/p&gt;

&lt;p&gt;배열을 최대 B개의 구간으로 나누어, 각 구간에서의 분산의 합을 최소화하는 문제입니다. $n$이 더 커지면 DP 최적화 기법 등을 생각해 볼 수 있겠지만, 이정도는 $B \times N$ 테이블을 칸당 $O(N)$ 에 구해도 충분합니다.&lt;/p&gt;

&lt;p&gt;먼저, 어떤 구간 $[j, i]$ 의 분산 $V(j, i)$ 을 $O(1)$에 구할 수 있다면, 이 문제는 간단히 다음과 같이 환원됩니다.
\(D(b, i) = \min_{j &amp;lt; i} V(j, i) + D(b-1, j-1)\)
그런데, 분산은 원소의 합과 제곱의 합을 안다면 $O(1)$에 구할 수 있고 (제평-평제 공식), 이는 prefix sum으로 최적화 가능한 문제입니다.&lt;/p&gt;

&lt;p&gt;이 문제의 구현은 금방 했지만, 실수로 n을 써야 할 자리에 MAXN 인 4000을 써넣어서 한번 틀렸습니다. 이후 이를 바로 캐치하고, 고쳤으나 맥북에 연결한 외장 키보드의 단축키가 익숙하지 않아서(변명같겠지만 진짜입니다….) 제출과 동시에 어 저장 안된거 아닌가? 라는 비명을 지르며 1번 더 틀리고 2틀 후 23분에 AC를 받았습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;저희 팀이 이 문제 First Solve를 받았습니다. 개인적으로 ICPC같은 큰 대회에서 퍼솔은 처음이라 굉장히 기분이 좋았습니다. ㅋㅋ!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이제, Coffeetea가 ‘B번은 미친듯이 케이스를 나눠야 한다. 일단 구현을 시작하겠지만 누군가 짤게있으면 바로 인터셉트해서 다른거 구현 하는게 좋겠다’ 는 말을 했고, 곧 DHDroid가 J를 바로 짤수있다고 선언해서 컴퓨터를 내줬습니다.&lt;/p&gt;

&lt;p&gt;추가로, 저는 A번을 읽고 바로 ‘수쿼 어딘가에 있을 법한 문제다’, ‘Mo’s Algorithm으로 풀 수 있을 것 같은데, 내가 그거 구현을 못한다. 정확히 이해한게 아니라서 팀노트에도 못적어왔다’ 고 말했습니다. 이때 또 웰노운 당했다는 생각에 굉장히 화가 났습니다. ㅋㅋ…&lt;/p&gt;

&lt;h3 id=&quot;problem-j--ten&quot;&gt;Problem J : Ten&lt;/h3&gt;
&lt;p&gt;Solve : DHDroid &lt;br /&gt;
Code : DHDroid&lt;/p&gt;

&lt;p&gt;숫자가 가득 주어지고 합이 10이 되는 직사각형의 개수를 세는 문제입니다. 일반적으로는 모든 직사각형을 볼 수 없으나, 이 문제에서는 각 숫자가 1 이상이다보니 크기가 10을 넘는 직사각형들을 볼 필요가 없어서 bruteforce할 수 있습니다. DHDroid가 2차원 부분합 잘 짜냐고 물어봐서 못한다고 대답하니까 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;아니;;;&lt;/code&gt; 이러면서 알아서 잘 짜더군요…ㅋㅋㅋ 40분 AC.&lt;/p&gt;

&lt;p&gt;이시점 저희의 순위는 최상위권이었기 때문에 (정확히 40분 시점에 저희는 E, I, J를 풀었고, 3솔 팀 다섯 팀이 각각 E, E, B, H, K를 풀었으며 4솔 이상 팀이 없어서 &lt;strong&gt;저희는 5등이었습니다&lt;/strong&gt;) 스코어보드를 보고 다음 풀 문제를 바로 알 수 없었고, B번의 케이스를 열심히 나누던 coffeetea와 제가 좀 얘기를 해보니까 H번을 금방 풀 수 있을 것 같았습니다. 제가 풀이의 확실함을 잠깐 고민하는 동안 Coffeetea가 한 7~8분? 정도 코딩을 좀 하다가, 제가 H번 풀 수 있다고 말해서 바로 바꿨습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-h--similarity&quot;&gt;Problem H : Similarity&lt;/h3&gt;
&lt;p&gt;Solve : Gratus907, Coffeetea (B번에 대해 생각하느라 많은 참여는 못했습니다)&lt;br /&gt;
Code : Gratus907&lt;/p&gt;

&lt;p&gt;두 배열 $P, Q$가 주어졌을 때, $p_i &amp;lt; p_j &amp;lt; p_k$ 이면서 $q_i &amp;lt; q_j &amp;lt; q_k$ 인 인덱스 $(i, j, k)$ 의 개수를 세는 문제입니다.&lt;/p&gt;

&lt;p&gt;$i$번째 인덱스를 점 $(p_i, q_i)$로 표현해 보겠습니다. 그렇다면, 2차원 배열 위에서, 우리가 원하는 인덱스들은 나의 ‘왼쪽 아래’ 직사각형에 있는 점들과, ‘오른쪽 위’ 직사각형에 있는 점들입니다. 즉 2차원 평면에서 어떤 직사각형 안에 점이 몇 개 있는지를 빠르게 셀 수 있다면 - 구체적으로, 내 ‘왼쪽 아래’ 와 ‘오른쪽 위’ 직사각형 - 이 문제를 풀 수 있습니다.&lt;/p&gt;

&lt;p&gt;언뜻 생각하면 2D segment tree 같은게 필요할 것 같지만, 잘 알려진 테크닉으로 이를 1D 세그만으로 할 수 있습니다. 세그먼트 트리는 업데이트 순서에 영향을 받기 때문에, 축 하나의 정보를 ‘업데이트 순서’ 를 이용해서 표현하는 것입니다. $x$좌표를 이용한 세그먼트 트리를 구현하되, $y$좌표가 큰 원소부터 업데이트한다고 하겠습니다. 이때, 어떤 점을 업데이트하기 직전에 $[x+1, \infty]$ 의 쿼리를 날려서 점의 개수를 세면, 아직 나보다 아래 있는 점은 업데이트를 안 했기 때문에 실제로 보이는 공간은 내 오른쪽 반평면이 아니라 내 오른쪽 위 사분면입니다. 이를 두개 이용해서 우상단과 좌하단을 각각 세면 됩니다. 같은 $y$좌표인 경우 누가 누구를 볼 수 있어야 하는지를 고려하면 되는데 여기서는 $x$좌표가 작은쪽부터 업데이트해주면 됩니다. 왼쪽에 있는 원소가 오른쪽 원소를 보게되면 ‘오른쪽 위’ 가 아니라 ‘오른쪽’ 인데도 포함하는 경우가 있어서, 왼쪽 원소는 자기랑 $y$좌표가 같고 $x$좌표가 큰 원소를 볼 수 없어야 합니다.&lt;/p&gt;

&lt;p&gt;여름에 다른학교 컴공과에 다니는 여자친구랑 세그먼트 트리, DP, 그래프 같은 주제 몇개로 플레 문제 일주일에 5-10개씩 밀었는데 &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, 그때 비슷한 문제를 풀어 봤습니다. &lt;a href=&quot;/ps-weekly/ps-weekly-21Jul1/&quot;&gt;링크&lt;/a&gt; 에 있는 ‘북서풍’, ‘여우가 정보섬에 올라온 이유’ 등 문제들에서 똑같이 쓰입니다. 72분에 AC를 받았습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;대회시간의 대략 40%가 지난 지금, 잠시 전체 상황을 조망해보자면&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;4 Solve. 1등은 6솔브, 2/3등은 5솔브로 최상위팀인 서울대 팀은 저희 + B, C를 풀었고, KAIST 팀과 다른 서울대 팀 하나가 각각 저희보다 K를 추가 / (B, C) 를 풀고 H 미해결인 상태였습니다. 많이 틀려서 페널티를 쌓기는 했지만, 대회 시간 40% 시점까지 상위권 솔브수를 따라붙을 수 있었습니다.&lt;/li&gt;
  &lt;li&gt;B번은 Coffeetea가 ‘충분한 시간이 주어지면 풀 수 있다’ 는 식으로 말했는데, 이게 참 어려운 말입니다. 반대로 ‘충분한 시간이 주어지지 않는’ 경우도 고려해야 합니다.&lt;/li&gt;
  &lt;li&gt;K번은 DHDroid가 고민을 좀 해보고 있었는데, ‘그리디일텐데… 복잡도가…’ 정도 상황이었습니다.&lt;/li&gt;
  &lt;li&gt;다른 문제에 대해서는 솔직하게 No clue. 저는 C번을 읽어봤기에, 최상위권 팀들이 C를 풀었다는 점 + 일부 4솔팀들이 H, 심지어 E보다도 C를 먼저 풀었다는 점이 좀 신기했습니다.&lt;/li&gt;
  &lt;li&gt;객관적으로 이때의 4솔팀들중에는 2400급 강팀들도 있지만, 2019-2020 시즌 Cafe mountain처럼 말도안되는 팀은 없는 것으로 알기 때문에 이들의 액션은 유의미합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이것들을 고려해서, 다시 Coffeetea가 키보드를 잡은채로 저희는 K를 풀고자 했습니다. 대회가 끝날 때까지 아마도 B, K는 풀 수 있을것 같았고, 하나 더 풀면 괜찮은 등수가 나오지 않겠느냐는 말을 했습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-b--carrot-field&quot;&gt;Problem B : Carrot Field&lt;/h3&gt;
&lt;p&gt;Solve : Coffeetea&lt;br /&gt;
Code : Coffeetea&lt;/p&gt;

&lt;p&gt;중학교 1학년 수학 교재를 보면, 말 같은걸 직사각형 한 점에 길이가 $L$인 줄로 묶어놓고 그 말이 움직일 수 있는 부분의 넓이를 구하는 문제가 많이 나옵니다. 그거랑 똑같은데, 대신에 격자점의 개수를 구하는 문제입니다. 
&lt;img src=&quot;../../images/9f32a25e45ffeac8ca959f5feb433785802b04c6cdd47724d613900ee6c924c7.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;br /&gt;
언뜻 보면 충격적으로 쉬워 보이지만, 이 문제가 끔찍한 점은 경우를 나눠야 한다는 것입니다. 편의상 $w \geq h$ 를 가정한다고 할 때, 크게 $L &amp;lt; h$ 인 경우 (원의 3/4 만큼), $h &amp;lt; L &amp;lt; w$ 인 경우 (이때는 가로쪽으로는 딱 사분원만큼을 먹을 수 있지만, 그려보면 위쪽으로는 작은 부채꼴을 더 생각해야 합니다), $w &amp;lt; L$ 인 경우가 있으며, $w &amp;lt; L$ 인 경우에는 두 점에서의 부채꼴이 겹치는 부분을 따로 세서 빼야 합니다.&lt;/p&gt;

&lt;p&gt;Coffeetea는 이 문제를 꽤 오랜 시간 붙잡았고 (구현이 체계적이려면 어쩔 수 없습니다), 구현해보았으나 틀렸습니다. 아마도 sqrt의 수치에러일 것으로 보고 다른 두 사람이 epsilon을 더하거나 이분탐색으로 직접 integer sqrt를 짤 것을 제안했고, 결국 이것 외에도 여러 자잘한 버그들을 고친 끝에 4번째만에 맞을 수 있었습니다. 119분 AC.&lt;/p&gt;

&lt;h3 id=&quot;problem-k--treasure-hunter&quot;&gt;Problem K : Treasure Hunter&lt;/h3&gt;
&lt;p&gt;Solve : Gratus907, DHDroid (Coffeetea도 잠깐 얘기를 듣는것 같던데, 여전히 B에 빠져 있던 것으로 기억합니다)&lt;br /&gt;
Code : Gratus907&lt;/p&gt;

&lt;p&gt;2차원 그리드에서 오른쪽 또는 아래로 내려가면서 보물을 먹을 수 있습니다. 그런데 왼쪽 또는 위로 돌아갈 수 없으므로 첫 경로에는 먹지 못하는 보물이 있을 수 있습니다. 모든 보물을 먹기 위해 필요한 경로의 개수 구하기.&lt;/p&gt;

&lt;p&gt;제가 이 문제를 잡았을때는 이미 DHDroid가 ‘그리디하게’ 라는 대략적인 각은 재 놨습니다. 즉, 한쪽의 convex hull을 따라 가면서 하나 먹고, 다 지운 다음 다시 먹고.. 하는 아이디어입니다. 이 방식이 답이 된다는 것은 약간의 논증을 통해 증명할 수 있었지만, 이 ‘외곽선 따는 경로’ 의 개수를 빠르게 구하는 방법에 대해서는 좀 어려움이 있었습니다.&lt;/p&gt;

&lt;p&gt;한참 동안을 생각하다가, 제가 ‘이 보물을 먹으면, 이 보물보다 오른쪽 위에 있는 보물은 같은 경로에서는 먹을 수 없다’ 는 사실을 관찰했습니다. 이제 이를 이용하면, ‘매번 upper convex hull을 따면서 먹는다고 할 때, 이 보물을 먹기 위해 필요한 최소 횟수’ 를 구할 수 있습니다. 구체적으로는, ‘나보다 오른쪽 위에 있는 보물들을 먹는 데 필요한 개수 + 1’ 만큼이 필요합니다.&lt;/p&gt;

&lt;p&gt;이는 다시 뭔가 오른쪽 위에 대한 max-2D query를 하는 연산인데, &lt;strong&gt;좀아까 푼 H번에서처럼&lt;/strong&gt; 1D 세그에다가 업데이트 순서를 잘 줘서 해결할 수 있습니다! 한 대회에 같은 아이디어를 두개 낸다는 점이 좀 의심스러웠지만 이걸 코딩하기로 했습니다. 코딩 결과 WA를 받았는데, 이게 무슨 에러인지 당장 알 수 없었기 때문에, 1틀 한 후 저는 잠시 알고리즘 자체에 대해 생각해보겠다고 하고 컴퓨터를 넘겨줬습니다. 다행히 제가 K번을 코딩하고 내는 사이에 계속 생각하던 DHdroid와 B번을 풀고 온 Coffeetea가 C번에 대한 뭔가 유의미한 관찰들을 빌드업했고, 잠시 구현을 시도해서 C번에서 WA를 받았습니다. C번도 다시 생각해보기로 하고 제가 다시 컴퓨터를 잡은 후, 간단한 실수임을 발견해서 148분에 AC를 받았습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-c--colorful-tower-of-hanoi&quot;&gt;Problem C : Colorful Tower of Hanoi&lt;/h3&gt;
&lt;p&gt;Solve : DHDroid, Coffeetea&lt;br /&gt;
Code : DHDroid&lt;/p&gt;

&lt;p&gt;남은 32분동안, Coffeetea와 DHDroid는 C번에 대한 기존의 풀이가 해결하지 못하는 케이스들을 찾아내서 이를 잡고자 했습니다. 결과적으로 풀이의 큰 틀은 DhDroid가 제시했고, 여러 edge case들을 Coffeetea가 발견해서 계속 풀이의 사소한 오류를 수정했습니다. 저는 30분 남은 시간동안 이 풀이를 설명해달라고 할지, 다른 뭘 할지 고민해봤지만 풀이 설명을 듣는 시간이 두명에게 굉장히 아까울 것 같아서 제가 스스로 종이들을 보면서 이해해 보려고 했고, 결국 뭔가 재귀적으로 잘 한다는 아이디어임은 주워들어서 납득했지만 그 후로는 잘 모르겠습니다.&lt;/p&gt;

&lt;p&gt;아주 간략한 아이디어는, 일반 하노이탑처럼 움직이는데 크기가 같은 판 두개가 있으면 일반 탑처럼 움직이면 그 판 두개의 위치는 서로 바뀐다는 사실을 관찰하는 것입니다. 이후 이를 바로잡아야 하는지 / 그렇지 않은지에 따라서 추가로 얼만큼 더 움직여야 하는지를 계산합니다. 시간이 될 때 DHDroid가 설명해 주기로 했습니다. [ 풀이 들어갈 자리 ]&lt;/p&gt;

&lt;p&gt;마지막에는 $n = 1, 2$ 같은 작은 케이스들이 계속 문제가 되었지만, 영혼을 바친 5틀 끝에 173분에 AC를 받을 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;retrospect&quot;&gt;Retrospect&lt;/h2&gt;
&lt;p&gt;저희는 7솔브로 18등의 성적을 거두었습니다. 10솔 2팀, 9솔 2팀, 8솔 2팀, 7솔 12팀이고 페널티싸움에서 맨 끝으로 밀렸네요.&lt;/p&gt;

&lt;p&gt;여기부터는 대회 자체와는 큰 상관 없는 얘기고, &lt;strong&gt;정확한 사실이 아닌 개인의 의견&lt;/strong&gt; (Factual하지 않다는 말이 아닙니다. Controversial / Personal이 가장 정확한 말일 것 같습니다) 에 해당하는 말들이 많습니다. 건전하고 건설적인 비판은 언제든 환영합니다. 대회와 상관있는 말부터 상관없는 말들 순서대로 적었습니다.&lt;/p&gt;

&lt;h3 id=&quot;about-problemset--our-result&quot;&gt;About Problemset / Our result&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;먼저, ICPC의 문제들은 OI와는 다르게 Syllabus가 없습니다. 정말 논문에 나오는 문제들부터, 복잡한 알고리즘 없이 construction으로 승부보는 문제까지 widely ranged 입니다. OI가 아이디어 싸움인 것과는 좀 다릅니다&lt;/li&gt;
  &lt;li&gt;그래서, 진입 장벽이 좀 있습니다. 특히 MO나 다른 수학적 사고력을 요구하는 백그라운드를 가진 사람들이 construction은 잘 할수 있지만, 매년 인예에는 FFT, LiChao Tree 등 &lt;strong&gt;학부 알고리즘 수업에서 다루지 않는 알고리즘&lt;/strong&gt; 한두개를 그냥 &lt;strong&gt;알고 있는지&lt;/strong&gt; 묻는 문제가 나옵니다. 올해는 A번이 저는 Mo’s algorithm에 대한 비슷한 스타일의 문제라고 판단했고, 결과적으로 Mo를 쓰는 것은 맞지만 그렇게까지 단순한 문제는 아니라고 (단순한 방법은 $n \sqrt{n} \log{n}$ 이고 통과하기 힘들다고 합니다) 하니 반만 맞은 말입니다.&lt;/li&gt;
  &lt;li&gt;L번이 USACO 문제와 비슷한, 나름 아는 팀들은 아는 문제라고 합니다. 그래서인지 저는 프리즈후 A번을 제출한 팀들이 대부분 맞았을 것이라고 주장했는데 그러지 않았고, 대신 L번이 생각보다 많이 풀렸습니다.&lt;/li&gt;
  &lt;li&gt;그리고 솔직히 H와 K가 같은 아이디어인 것은 충격이었습니다만, K는 LIS를 이용한 더 쉬운 풀이가 있다고 하므로 이것도 반만 맞는 말인것 같습니다.&lt;/li&gt;
  &lt;li&gt;웰노운을 출제하는게 어떤 의미가 있는지는 사람마다 생각이 다를 것입니다. 저는 딱히 지지하지도, 반대하지도 않습니다. 물론 제가 모르는 웰노운이 나오면 욕하는건 당연하지만, 그건 솔직히 말하면 어쩔 수 없는 거죠.&lt;/li&gt;
  &lt;li&gt;저희의 이번 대회는 현재 실력에 비추어 볼 때 잘 치른게 맞습니다. 다만, Coffeetea가 실력을 발휘할만한 직관싸움 문제가 딱히 없었고, 결정적으로 저희팀의 오래된 전략이지만 개선점이 있는 ‘복잡한 구현이 있으면, Coffeetea를 밀어 넣고, 나머지 2명이 기도하면서 다른 문제를 푼다’ 는 전략을 또 써야 했습니다. B번 하나에 Coffeetea의 시간을 거의 절반이나 갈아 버린 것은 좋은 전략은 아닙니다.&lt;/li&gt;
  &lt;li&gt;그럼에도 불구하고, 그러지 않았으면 저는 B번 AC를 못 받았을 것입니다. DHDroid도 딱히 이런 문제를 저보다 잘 하진 않습니다. ㅋㅋ…&lt;/li&gt;
  &lt;li&gt;특별히 아쉬움이 남는건 없습니다. 사소한 실수로 페널티 싸움을 많이 밀렸다는건 좀 아쉽지만, 솔브수에서 상위권 팀들을 따라붙었다는 의의는 확실히 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;about-my-icpc&quot;&gt;About my ICPC&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;저는 ICPC에 네 번 나가 봤고, 모두 본선에는 못 갔습니다. 사실 올해는 저를 제외한 두명이 휴학생이기 때문에, 저희가 몇 등을 했든 저는 본선 진출권이 없었습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;솔직히 말하자면 예선 성적으로는 본선에 진출하고도 남을 만한 성적을 2019년부터 받아 왔지만, ICPC는 많은 대학의 출전을 위해 상위권 대학에 더 엄격한 기준을 적용하여 본선 팀을 선발합니다. 구체적으로는, 먼저 $x$ 문제를 푼 팀들을 모두 선발하고, 이후에는 $x-1$ 문제를 푼 팀들 중 각 대학의 $y_i$ 위 이상인 팀… 을 선발하는 식입니다. 이 방식을 적용하는 데 있어, 어떤 학교도 총 출전팀의 50% 이상을 본선에 보내지 못한다는 (과거엔 explicit하게 적혀 있었다고 하지만, 지금은 찾을 수 없고, 그럼에도 아직 적용되는 것으로 보이는) 룰 이 있습니다. 맨 위의 선발 기준은 사실상 서울대를 위해 만들어졌으며 (서울대 15팀 중 7팀 이하를 자르는 컷을 찾습니다), 본선 진출 경계선인 60위에 (작년에는 90위였을 거고 그럼 얘기가 다릅니다) 50% 이상의 팀을 보낼 수 있는 학교는 몇 없기 때문에 (서울대, KAIST, 고려대 정도. 아마 해에 따라 다른 학교들도 가능한 해가 있을 것입니다) 사실상 저격밴이 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;제가 이번에 휴학생 팀으로 나간 이유도 여기에 있습니다. 저랑 비슷한 수준의 팀원 두명을 모으면 본선 진출이 어차피 어려울 것이고, 저보다 월등히 잘하는 팀원을 찾으면 어떻게 나가볼 수 있을지는 모르겠지만 첫째로는 그런 사람이 저랑 팀을 해줄지도 의문이고 두번째로는 해준다고 해도 제가 대회를 재밌게 즐기지 못할 것 같았습니다. 그래서 휴학생 팀이지만, 대회 자체를 진심으로 즐길 수 있는 - 일종의 즐겜팀이라고 할까요 - Little Piplup에 다시 함께했습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이 monotonic하지 않은 선발 기준에 대해 어떻게 생각하는지는 사람마다 다른 영역인 것 같습니다. 저는 당연히 이 기준으로 본선 무대를 못 밟았으므로 굉장히 화가 나지만, 대학 대항전인 ICPC에서 서울대 15팀이 나타나는 것이 그럼 맞느냐? 고 말하면 뭐 그렇게 볼 수도 있습니다. 다만, 이 부분은 조금 나아질 기미가 보이는데, PS판에서 서울대가 보여줬던 갭이 점점 줄어드는게 눈에 보이기 때문입니다. 올해의 인예 순위에서 솔브수로 격차를 낸 최상위권은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;서울-서울-고려-카이-카이-유니&lt;/code&gt; 입니다. (7솔에 저희를 포함 무려 12팀이 물려 있습니다) 참고로, 작년 인예는 9솔 이상이 7팀이었는데, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;서울-서울-서울-서울-카이-서울-숭실&lt;/code&gt; 이었습니다. PS판의 저변이 넓어져서 그런 것인지, 서울대의 수많은 레드들이 PS판을 떠나고 ML 같은 보다 쓸모있는 뭔가를 공부하러 갔기 때문인지, 최근 여러 학교에서 레드 이상의 CP-er를 배출한 데 어떤 요소들이 작용했는지는 잘 모르겠지만 아무튼 그렇습니다. 레드 한명이 졸업할때까지 뛸수있는 ICPC판을 보니 내년에도 이럴 것 같고, 작년처럼 서울대 리저널 6팀인가? 보내 줬더니 모든 상을 서울대가 쓸어버리는 참사가 벌어지지는 않을 것입니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;저는 내년이 마지막 ICPC고, 알고리즘을 공부하면서 / PS를 즐기면서 ICPC 본선 리저널 무대를 한번도 가보지 못했다는 것이 개인적으로 굉장히 아쉽습니다. 어떻게 보면 아카데믹하게 알고리즘을 공부하겠다는 목표를 갖게 된 지금은 PS 자체에 큰 의미는 없겠지만, 개인적으로 느낀 바가 그렇습니다. 그래서, 겨울방학에 좀 빡세게 돌면서 레드 정도 수준까지 폼을 맞춰놓고, 내년에는 레드 3명 또는 그에 근접한, 진출을 노리는 팀을 만들어 마지막 ICPC에 도전할 계획입니다. 좋은 팀원을 모은다면 80% 이상 가능하다고 확신하고 있습니다. 혹시 이 블로그를 보신 &lt;strong&gt;서울대 재학생 중&lt;/strong&gt;, 내년 10월까지 &lt;strong&gt;CF 2300 또는 Equivalent한&lt;/strong&gt; 실력을 갖출 수 있으며, &lt;strong&gt;휴학 계획이 없고&lt;/strong&gt;, &lt;strong&gt;같이 공부하고 싶은&lt;/strong&gt; 분은 연락주시면 좋을것 같네요. ㅋㅋ!!! (당연한 말이지만 이런 허공에 돌던지는 식으로 모을 생각으로 쓴 말은 아닙니다…)&lt;/p&gt;

&lt;h3 id=&quot;대회를-마치며&quot;&gt;대회를 마치며&lt;/h3&gt;
&lt;p&gt;항상 PS 대회를 뛰고 나면, PS를 즐기는 마인드와 대회 성적에 따른 competitive 한 마인드가 서로 충돌하게 됩니다. 이번 대회는 정말 간만에 그런 것 없이 순수하게 즐길 수 있었는데, 대회가 끝나고 나니 competitive mind가 잠깐 지배하고 있어서 위 500단어 정도를 ranting했습니다. 학기중에는 어차피 매우 바쁘기 때문에, 겨울방학에나 다시 손댈 수 있지 않을까 싶습니다.&lt;/p&gt;

&lt;p&gt;끝나고 팀원들과 치킨을 먹으면서 대회에 대한 얘기도 하고, 재밌게 놀고 왔습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;네. 이 문장은 &lt;del&gt;기만질&lt;/del&gt; 자랑하려고 적었습니다. ㅋㅋ!!! &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="cp-rounds" /><summary type="html">Contents Preperation / Our Team 본 대회 Problem I : Sport Climbing Combined Problem E : Histogram Problem J : Ten Problem H : Similarity Problem B : Carrot Field Problem K : Treasure Hunter Problem C : Colorful Tower of Hanoi Retrospect About Problemset / Our result About my ICPC 대회를 마치며 Little Piplup 팀으로 복귀해서 ICPC 2021을 재밌게 치고 왔습니다. 늘 대회가 끝나고 나면 Whining을 해왔지만, 이번 대회는 솔직히 말하면 Whining할게 별로 없습니다. 18등의 성적을 거두었는데, 풀었어야 할 문제 는 다 풀지 않았나 싶습니다. Prep - 대회과정 타임라인에 따른 의식의 흐름 - Retrospect의 순서로 작성합니다. 평소보다 앞뒤 글이 많이 길고 장황하기 때문에, 왼쪽 아래 Table of Content를 보면 문제에 대한 이야기만 볼 수 있습니다. Preperation / Our Team 팀연습 두번을 했습니다. GCPC 2020 : 팀연습 기록 링크 BAPC 2020 (기록 미작성) 이 팀의 객관적인 전력을 저는 개인적으로 적어도 2100 3명 정도 수준, 내지는 문제셋을 조금 잘 타면 1레드가 섞인 팀과도 비벼볼 수 있다고 생각합니다. 가장 최근의 팀 대회는 Hashcode 2021이었는데, 그때와 지금 팀을 비교하면 (dlwocks31의 부재를 제외하고 세명만) 크게 달라진 것은 없으므로 그때 썼던 기록에 더하여 팀원들에 대한 얘기를 조금 해보겠습니다. Gratus907 : 수학적인 문제에 비교적 강하고, 말리지 않을때까지는 구현이 빠르지만 말리면 한없이 말리는 경향이 있습니다. 그래도 제 코딩 경험이 쌓이면서 예전만큼 코딩이 말리지 않습니다. 반면에, 한번 어떤 방면으로 빠지면 무한한 뇌절을 이어가는 경향이 있습니다. 이는 FFT에 패배한 SCPC 2021 같은 상황에서 정말 끔찍했습니다. 수학 복수전공을 통해 얻은 지식은 딱히 PS에 도움이 되지 않지만, 씹덕같은 정수론 문제 한두개를 가끔 쳐낼 수 있는것 같습니다. 아카데믹한 알고리즘 공부를 그래도 이중에 가장 많이 했었습니다. DHDroid : Constructive한 문제에 매우 강하고, 관찰을 정당화 (증명) 하는 능력이 뛰어납니다. 이 능력을 실제로 보여준 대회가 역시 SCPC 2021입니다. Round 2 하노이탑에서 일부 레드들도 달성을 어려워했던 250점을 달성하고, 저보다 훨씬 높은 성적으로 2라운드를 마친후 본선에서 5등상을 받는 쾌거를 보여줬습니다. 본인의 표현을 빌리자면 정말 어려운 문제에 도전해서 몇 시간 고민을 이어가는 본인의 연습방식이 도움이 된다고 합니다. 학과 동기이고 친구지만 이렇게 어려운 문제를 대하는 자세를 보면서 항상 많은 것을 배웁니다. 반대로 제한시간이 짧은 대회에 살짝 약합니다. 2시간짜리 코드포스가 가장 대표적이죠. Coffeetea : 그리디하거나 휴리스틱한 관찰, 대략적인 경향성의 파악에 강합니다. 뭔가 문제에 빙의하는 특성이 있어서 글쓸때 Coffeetea의 표현을 많이 빌리게 됩니다 :) 저는 그때 이 팀에 없었지만, 작년 ICPC F번 같은 문제에서 가장 잘 느낄 수 있습니다. (이 문제는 그렇게 어렵지 않지만요) Hashcode 스타일의 대회에서 초기 아이디어를 정말 잘 던져주고, 데이터를 슥 보고 특성을 빠르게 캐치합니다. 많이 복잡한 구현은 저보다 잘 합니다. 저보다 좀더 구현에 대해 체계적으로 고민하고, 놓치는 케이스가 비교적 적으며, 디버깅할때의 끈기와 자세가 뛰어납니다. 역시 항상 많은 것을 배우게 되는 친구입니다. 개발 공부에 많은 시간과 노력을 투자했기 때문에 이런 구현 실력을 갖춘 것 같은데, 반대로 소위 ‘고인물 알고리즘’ 에 대한 공부를 많이 하지는 않았습니다. 대회 시작 전날까지 팀노트를 작년 제 팀노트에 얹어서 나름대로 열심히 준비했습니다. 후술하지만, 약간의 부족함은 있었습니다. 팀노트를 준비할 때 생각해야 하는 기준은, (보편 타당한 생각을 제가 나름대로 표현해 보자면) “어 이거 그건데” 와 AC를 받는 시점 사이의 시간의 expectation을 minimize하는 것입니다. 이 말의 의미는, 구현 실수가 날만한 부분들이나 구현이 복잡한 자료구조, 알지만 구글링 없이는 코딩이 불가능한 알고리즘 등을 적어 가야 한다는 것입니다. 저희 팀을 예로 들자면 수많은 기하 구현을 준비했습니다. 대회 시간 중에 선분 - 선분 교차를 구현해 보셨나요? ㅋㅋ! segment tree에서 lazy propagation의 개념은 잘 알고 있으나 구현시 실수할 것을 대비하여 적어 갔습니다. Dinic과 HeavyLight Decomposition 등을 적어 갔습니다. 25페이지는 효율적으로 잘 꾹꾹 눌러 쓰면 생각보다 꽤 많습니다. 저희 팀노트는 [링크] 에서 볼 수 있는데, ICPC 전날 급하게 많은 것을 추가하느라 외관의 아름다움을 많이 잃어버렸습니다만 앞으로 계속 업데이트될 것입니다 (제 개인적으로는 archive의 의미가 있어서요.) 팀노트 맨 끝장에는 Checkpoint를 붙여 갔습니다. 이 체크포인트는 제가 계속 관리하고 있는 노트인데, 제가 나가는 팀대회에서는 팀노트 맨 끝장에 붙여 나갑니다. (이미지를 우클릭-새 탭으로 열기해서 큰 화면으로 볼 수 있습니다) 모든 포인트들은 제가 문제를 풀면서 경험해본 것들입니다. PS 오답노트라고나 할까요. 본 대회 저희는 스터디카페에서 대회를 치렀기 때문에, 문제지가 뜨는걸 확인하는 즉시 제가 인쇄를 하러 나가면서 팀원들이 화면을 반으로 나눠서 A, B를 읽었습니다. 문제지 인쇄까지는 프린터가 느린데다 문제지 합본 pdf 파일이 바로 넘어오지 않아서, 거의 7분 가까운 시간이 소요되었습니다. 그러나 문제지를 인쇄하는 프린터 앞에 서서 저도 문제를 볼 수 있었기 때문에 실질적인 시간상의 로스는 거의 없습니다. 대회 규정상 팀원 1인 이상이 오랜 시간 자리를 비워서는 안되고 (아마도 이 규정이 strictly enforce되는 것은 어차피 기술적으로 불가능했을 것입니다만), 팀원들의 효율을 위해 문제지가 1/3정도 인쇄될 때마다 제가 계속 팀원들에게 배달했습니다. 그 사이에, I번의 첫 Solve들이 등장하기 시작했습니다. 처음에 어떻게 다른 팀들이 12문제 중 9번째에 있는 문제를 찾아내서 풀었는지 의아했지만, 생각해보니 4/4/4로 분배하면 팀원중 한명에게는 가장 먼저 읽는 문제니까 그런것 같습니다. (그럼에도 약간의 의문이 있습니다. 찾아보니 작년에도 I번이 가장 쉬운 문제였고, 그 전까지는 등록이 있는 자리였는데 혹시 그 사실을 인지하고 있는 팀들이 있을까요?) 인쇄 중에 저는 팀원들이 A, B 부터 읽고 있음을 감안하여 적당히 몇개 떼고 E를 읽었습니다. 한국어길래 슬쩍 B, C도 한번씩 읽었는데 B는 딱봐도 구현이 노답이고 C는 엄청나게 어려워 보였기 때문에… 제가 인쇄를 마치면서 2시 8분쯤 방에 복귀했는데, 이미 팀원들이 I번을 읽고 솔루션을 제시했으며 B가 구현 노답이라는 사실도 인지하고 있었습니다. Problem I : Sport Climbing Combined Solve : DHdroid Code : DHDroid 무슨 문제인지 방금 처음 읽었는데, 딱히 할말이 없습니다. $p_i \times q_i \times r_i$를 기준으로 정렬해서 그 $b_i$를 출력하면 됩니다. 13분에 AC를 받았습니다. 이때 저는 E번의 풀이가 간단한 $O(B N^2)$ DP로 가능하다는 것을 이미 인지했기 때문에 ($30 * 4000^2$ 이면 4.8억이지만 실제로는 그 절반만 써서 괜찮습니다), 바로 제가 E를 잡겠다고 주장했습니다. 아무도 E를 풀지 않았다는 사실이 좀 마음에 걸리지만… Problem E : Histogram Solve : Gratus907 Code : Gratus907 배열을 최대 B개의 구간으로 나누어, 각 구간에서의 분산의 합을 최소화하는 문제입니다. $n$이 더 커지면 DP 최적화 기법 등을 생각해 볼 수 있겠지만, 이정도는 $B \times N$ 테이블을 칸당 $O(N)$ 에 구해도 충분합니다. 먼저, 어떤 구간 $[j, i]$ 의 분산 $V(j, i)$ 을 $O(1)$에 구할 수 있다면, 이 문제는 간단히 다음과 같이 환원됩니다. \(D(b, i) = \min_{j &amp;lt; i} V(j, i) + D(b-1, j-1)\) 그런데, 분산은 원소의 합과 제곱의 합을 안다면 $O(1)$에 구할 수 있고 (제평-평제 공식), 이는 prefix sum으로 최적화 가능한 문제입니다. 이 문제의 구현은 금방 했지만, 실수로 n을 써야 할 자리에 MAXN 인 4000을 써넣어서 한번 틀렸습니다. 이후 이를 바로 캐치하고, 고쳤으나 맥북에 연결한 외장 키보드의 단축키가 익숙하지 않아서(변명같겠지만 진짜입니다….) 제출과 동시에 어 저장 안된거 아닌가? 라는 비명을 지르며 1번 더 틀리고 2틀 후 23분에 AC를 받았습니다. 저희 팀이 이 문제 First Solve를 받았습니다. 개인적으로 ICPC같은 큰 대회에서 퍼솔은 처음이라 굉장히 기분이 좋았습니다. ㅋㅋ!! 이제, Coffeetea가 ‘B번은 미친듯이 케이스를 나눠야 한다. 일단 구현을 시작하겠지만 누군가 짤게있으면 바로 인터셉트해서 다른거 구현 하는게 좋겠다’ 는 말을 했고, 곧 DHDroid가 J를 바로 짤수있다고 선언해서 컴퓨터를 내줬습니다. 추가로, 저는 A번을 읽고 바로 ‘수쿼 어딘가에 있을 법한 문제다’, ‘Mo’s Algorithm으로 풀 수 있을 것 같은데, 내가 그거 구현을 못한다. 정확히 이해한게 아니라서 팀노트에도 못적어왔다’ 고 말했습니다. 이때 또 웰노운 당했다는 생각에 굉장히 화가 났습니다. ㅋㅋ… Problem J : Ten Solve : DHDroid Code : DHDroid 숫자가 가득 주어지고 합이 10이 되는 직사각형의 개수를 세는 문제입니다. 일반적으로는 모든 직사각형을 볼 수 없으나, 이 문제에서는 각 숫자가 1 이상이다보니 크기가 10을 넘는 직사각형들을 볼 필요가 없어서 bruteforce할 수 있습니다. DHDroid가 2차원 부분합 잘 짜냐고 물어봐서 못한다고 대답하니까 아니;;; 이러면서 알아서 잘 짜더군요…ㅋㅋㅋ 40분 AC. 이시점 저희의 순위는 최상위권이었기 때문에 (정확히 40분 시점에 저희는 E, I, J를 풀었고, 3솔 팀 다섯 팀이 각각 E, E, B, H, K를 풀었으며 4솔 이상 팀이 없어서 저희는 5등이었습니다) 스코어보드를 보고 다음 풀 문제를 바로 알 수 없었고, B번의 케이스를 열심히 나누던 coffeetea와 제가 좀 얘기를 해보니까 H번을 금방 풀 수 있을 것 같았습니다. 제가 풀이의 확실함을 잠깐 고민하는 동안 Coffeetea가 한 7~8분? 정도 코딩을 좀 하다가, 제가 H번 풀 수 있다고 말해서 바로 바꿨습니다. Problem H : Similarity Solve : Gratus907, Coffeetea (B번에 대해 생각하느라 많은 참여는 못했습니다) Code : Gratus907 두 배열 $P, Q$가 주어졌을 때, $p_i &amp;lt; p_j &amp;lt; p_k$ 이면서 $q_i &amp;lt; q_j &amp;lt; q_k$ 인 인덱스 $(i, j, k)$ 의 개수를 세는 문제입니다. $i$번째 인덱스를 점 $(p_i, q_i)$로 표현해 보겠습니다. 그렇다면, 2차원 배열 위에서, 우리가 원하는 인덱스들은 나의 ‘왼쪽 아래’ 직사각형에 있는 점들과, ‘오른쪽 위’ 직사각형에 있는 점들입니다. 즉 2차원 평면에서 어떤 직사각형 안에 점이 몇 개 있는지를 빠르게 셀 수 있다면 - 구체적으로, 내 ‘왼쪽 아래’ 와 ‘오른쪽 위’ 직사각형 - 이 문제를 풀 수 있습니다. 언뜻 생각하면 2D segment tree 같은게 필요할 것 같지만, 잘 알려진 테크닉으로 이를 1D 세그만으로 할 수 있습니다. 세그먼트 트리는 업데이트 순서에 영향을 받기 때문에, 축 하나의 정보를 ‘업데이트 순서’ 를 이용해서 표현하는 것입니다. $x$좌표를 이용한 세그먼트 트리를 구현하되, $y$좌표가 큰 원소부터 업데이트한다고 하겠습니다. 이때, 어떤 점을 업데이트하기 직전에 $[x+1, \infty]$ 의 쿼리를 날려서 점의 개수를 세면, 아직 나보다 아래 있는 점은 업데이트를 안 했기 때문에 실제로 보이는 공간은 내 오른쪽 반평면이 아니라 내 오른쪽 위 사분면입니다. 이를 두개 이용해서 우상단과 좌하단을 각각 세면 됩니다. 같은 $y$좌표인 경우 누가 누구를 볼 수 있어야 하는지를 고려하면 되는데 여기서는 $x$좌표가 작은쪽부터 업데이트해주면 됩니다. 왼쪽에 있는 원소가 오른쪽 원소를 보게되면 ‘오른쪽 위’ 가 아니라 ‘오른쪽’ 인데도 포함하는 경우가 있어서, 왼쪽 원소는 자기랑 $y$좌표가 같고 $x$좌표가 큰 원소를 볼 수 없어야 합니다. 여름에 다른학교 컴공과에 다니는 여자친구랑 세그먼트 트리, DP, 그래프 같은 주제 몇개로 플레 문제 일주일에 5-10개씩 밀었는데 1, 그때 비슷한 문제를 풀어 봤습니다. 링크 에 있는 ‘북서풍’, ‘여우가 정보섬에 올라온 이유’ 등 문제들에서 똑같이 쓰입니다. 72분에 AC를 받았습니다. 대회시간의 대략 40%가 지난 지금, 잠시 전체 상황을 조망해보자면 4 Solve. 1등은 6솔브, 2/3등은 5솔브로 최상위팀인 서울대 팀은 저희 + B, C를 풀었고, KAIST 팀과 다른 서울대 팀 하나가 각각 저희보다 K를 추가 / (B, C) 를 풀고 H 미해결인 상태였습니다. 많이 틀려서 페널티를 쌓기는 했지만, 대회 시간 40% 시점까지 상위권 솔브수를 따라붙을 수 있었습니다. B번은 Coffeetea가 ‘충분한 시간이 주어지면 풀 수 있다’ 는 식으로 말했는데, 이게 참 어려운 말입니다. 반대로 ‘충분한 시간이 주어지지 않는’ 경우도 고려해야 합니다. K번은 DHDroid가 고민을 좀 해보고 있었는데, ‘그리디일텐데… 복잡도가…’ 정도 상황이었습니다. 다른 문제에 대해서는 솔직하게 No clue. 저는 C번을 읽어봤기에, 최상위권 팀들이 C를 풀었다는 점 + 일부 4솔팀들이 H, 심지어 E보다도 C를 먼저 풀었다는 점이 좀 신기했습니다. 객관적으로 이때의 4솔팀들중에는 2400급 강팀들도 있지만, 2019-2020 시즌 Cafe mountain처럼 말도안되는 팀은 없는 것으로 알기 때문에 이들의 액션은 유의미합니다. 이것들을 고려해서, 다시 Coffeetea가 키보드를 잡은채로 저희는 K를 풀고자 했습니다. 대회가 끝날 때까지 아마도 B, K는 풀 수 있을것 같았고, 하나 더 풀면 괜찮은 등수가 나오지 않겠느냐는 말을 했습니다. Problem B : Carrot Field Solve : Coffeetea Code : Coffeetea 중학교 1학년 수학 교재를 보면, 말 같은걸 직사각형 한 점에 길이가 $L$인 줄로 묶어놓고 그 말이 움직일 수 있는 부분의 넓이를 구하는 문제가 많이 나옵니다. 그거랑 똑같은데, 대신에 격자점의 개수를 구하는 문제입니다. 언뜻 보면 충격적으로 쉬워 보이지만, 이 문제가 끔찍한 점은 경우를 나눠야 한다는 것입니다. 편의상 $w \geq h$ 를 가정한다고 할 때, 크게 $L &amp;lt; h$ 인 경우 (원의 3/4 만큼), $h &amp;lt; L &amp;lt; w$ 인 경우 (이때는 가로쪽으로는 딱 사분원만큼을 먹을 수 있지만, 그려보면 위쪽으로는 작은 부채꼴을 더 생각해야 합니다), $w &amp;lt; L$ 인 경우가 있으며, $w &amp;lt; L$ 인 경우에는 두 점에서의 부채꼴이 겹치는 부분을 따로 세서 빼야 합니다. Coffeetea는 이 문제를 꽤 오랜 시간 붙잡았고 (구현이 체계적이려면 어쩔 수 없습니다), 구현해보았으나 틀렸습니다. 아마도 sqrt의 수치에러일 것으로 보고 다른 두 사람이 epsilon을 더하거나 이분탐색으로 직접 integer sqrt를 짤 것을 제안했고, 결국 이것 외에도 여러 자잘한 버그들을 고친 끝에 4번째만에 맞을 수 있었습니다. 119분 AC. Problem K : Treasure Hunter Solve : Gratus907, DHDroid (Coffeetea도 잠깐 얘기를 듣는것 같던데, 여전히 B에 빠져 있던 것으로 기억합니다) Code : Gratus907 2차원 그리드에서 오른쪽 또는 아래로 내려가면서 보물을 먹을 수 있습니다. 그런데 왼쪽 또는 위로 돌아갈 수 없으므로 첫 경로에는 먹지 못하는 보물이 있을 수 있습니다. 모든 보물을 먹기 위해 필요한 경로의 개수 구하기. 제가 이 문제를 잡았을때는 이미 DHDroid가 ‘그리디하게’ 라는 대략적인 각은 재 놨습니다. 즉, 한쪽의 convex hull을 따라 가면서 하나 먹고, 다 지운 다음 다시 먹고.. 하는 아이디어입니다. 이 방식이 답이 된다는 것은 약간의 논증을 통해 증명할 수 있었지만, 이 ‘외곽선 따는 경로’ 의 개수를 빠르게 구하는 방법에 대해서는 좀 어려움이 있었습니다. 한참 동안을 생각하다가, 제가 ‘이 보물을 먹으면, 이 보물보다 오른쪽 위에 있는 보물은 같은 경로에서는 먹을 수 없다’ 는 사실을 관찰했습니다. 이제 이를 이용하면, ‘매번 upper convex hull을 따면서 먹는다고 할 때, 이 보물을 먹기 위해 필요한 최소 횟수’ 를 구할 수 있습니다. 구체적으로는, ‘나보다 오른쪽 위에 있는 보물들을 먹는 데 필요한 개수 + 1’ 만큼이 필요합니다. 이는 다시 뭔가 오른쪽 위에 대한 max-2D query를 하는 연산인데, 좀아까 푼 H번에서처럼 1D 세그에다가 업데이트 순서를 잘 줘서 해결할 수 있습니다! 한 대회에 같은 아이디어를 두개 낸다는 점이 좀 의심스러웠지만 이걸 코딩하기로 했습니다. 코딩 결과 WA를 받았는데, 이게 무슨 에러인지 당장 알 수 없었기 때문에, 1틀 한 후 저는 잠시 알고리즘 자체에 대해 생각해보겠다고 하고 컴퓨터를 넘겨줬습니다. 다행히 제가 K번을 코딩하고 내는 사이에 계속 생각하던 DHdroid와 B번을 풀고 온 Coffeetea가 C번에 대한 뭔가 유의미한 관찰들을 빌드업했고, 잠시 구현을 시도해서 C번에서 WA를 받았습니다. C번도 다시 생각해보기로 하고 제가 다시 컴퓨터를 잡은 후, 간단한 실수임을 발견해서 148분에 AC를 받았습니다. Problem C : Colorful Tower of Hanoi Solve : DHDroid, Coffeetea Code : DHDroid 남은 32분동안, Coffeetea와 DHDroid는 C번에 대한 기존의 풀이가 해결하지 못하는 케이스들을 찾아내서 이를 잡고자 했습니다. 결과적으로 풀이의 큰 틀은 DhDroid가 제시했고, 여러 edge case들을 Coffeetea가 발견해서 계속 풀이의 사소한 오류를 수정했습니다. 저는 30분 남은 시간동안 이 풀이를 설명해달라고 할지, 다른 뭘 할지 고민해봤지만 풀이 설명을 듣는 시간이 두명에게 굉장히 아까울 것 같아서 제가 스스로 종이들을 보면서 이해해 보려고 했고, 결국 뭔가 재귀적으로 잘 한다는 아이디어임은 주워들어서 납득했지만 그 후로는 잘 모르겠습니다. 아주 간략한 아이디어는, 일반 하노이탑처럼 움직이는데 크기가 같은 판 두개가 있으면 일반 탑처럼 움직이면 그 판 두개의 위치는 서로 바뀐다는 사실을 관찰하는 것입니다. 이후 이를 바로잡아야 하는지 / 그렇지 않은지에 따라서 추가로 얼만큼 더 움직여야 하는지를 계산합니다. 시간이 될 때 DHDroid가 설명해 주기로 했습니다. [ 풀이 들어갈 자리 ] 마지막에는 $n = 1, 2$ 같은 작은 케이스들이 계속 문제가 되었지만, 영혼을 바친 5틀 끝에 173분에 AC를 받을 수 있었습니다. Retrospect 저희는 7솔브로 18등의 성적을 거두었습니다. 10솔 2팀, 9솔 2팀, 8솔 2팀, 7솔 12팀이고 페널티싸움에서 맨 끝으로 밀렸네요. 여기부터는 대회 자체와는 큰 상관 없는 얘기고, 정확한 사실이 아닌 개인의 의견 (Factual하지 않다는 말이 아닙니다. Controversial / Personal이 가장 정확한 말일 것 같습니다) 에 해당하는 말들이 많습니다. 건전하고 건설적인 비판은 언제든 환영합니다. 대회와 상관있는 말부터 상관없는 말들 순서대로 적었습니다. About Problemset / Our result 먼저, ICPC의 문제들은 OI와는 다르게 Syllabus가 없습니다. 정말 논문에 나오는 문제들부터, 복잡한 알고리즘 없이 construction으로 승부보는 문제까지 widely ranged 입니다. OI가 아이디어 싸움인 것과는 좀 다릅니다 그래서, 진입 장벽이 좀 있습니다. 특히 MO나 다른 수학적 사고력을 요구하는 백그라운드를 가진 사람들이 construction은 잘 할수 있지만, 매년 인예에는 FFT, LiChao Tree 등 학부 알고리즘 수업에서 다루지 않는 알고리즘 한두개를 그냥 알고 있는지 묻는 문제가 나옵니다. 올해는 A번이 저는 Mo’s algorithm에 대한 비슷한 스타일의 문제라고 판단했고, 결과적으로 Mo를 쓰는 것은 맞지만 그렇게까지 단순한 문제는 아니라고 (단순한 방법은 $n \sqrt{n} \log{n}$ 이고 통과하기 힘들다고 합니다) 하니 반만 맞은 말입니다. L번이 USACO 문제와 비슷한, 나름 아는 팀들은 아는 문제라고 합니다. 그래서인지 저는 프리즈후 A번을 제출한 팀들이 대부분 맞았을 것이라고 주장했는데 그러지 않았고, 대신 L번이 생각보다 많이 풀렸습니다. 그리고 솔직히 H와 K가 같은 아이디어인 것은 충격이었습니다만, K는 LIS를 이용한 더 쉬운 풀이가 있다고 하므로 이것도 반만 맞는 말인것 같습니다. 웰노운을 출제하는게 어떤 의미가 있는지는 사람마다 생각이 다를 것입니다. 저는 딱히 지지하지도, 반대하지도 않습니다. 물론 제가 모르는 웰노운이 나오면 욕하는건 당연하지만, 그건 솔직히 말하면 어쩔 수 없는 거죠. 저희의 이번 대회는 현재 실력에 비추어 볼 때 잘 치른게 맞습니다. 다만, Coffeetea가 실력을 발휘할만한 직관싸움 문제가 딱히 없었고, 결정적으로 저희팀의 오래된 전략이지만 개선점이 있는 ‘복잡한 구현이 있으면, Coffeetea를 밀어 넣고, 나머지 2명이 기도하면서 다른 문제를 푼다’ 는 전략을 또 써야 했습니다. B번 하나에 Coffeetea의 시간을 거의 절반이나 갈아 버린 것은 좋은 전략은 아닙니다. 그럼에도 불구하고, 그러지 않았으면 저는 B번 AC를 못 받았을 것입니다. DHDroid도 딱히 이런 문제를 저보다 잘 하진 않습니다. ㅋㅋ… 특별히 아쉬움이 남는건 없습니다. 사소한 실수로 페널티 싸움을 많이 밀렸다는건 좀 아쉽지만, 솔브수에서 상위권 팀들을 따라붙었다는 의의는 확실히 있습니다. About my ICPC 저는 ICPC에 네 번 나가 봤고, 모두 본선에는 못 갔습니다. 사실 올해는 저를 제외한 두명이 휴학생이기 때문에, 저희가 몇 등을 했든 저는 본선 진출권이 없었습니다. 솔직히 말하자면 예선 성적으로는 본선에 진출하고도 남을 만한 성적을 2019년부터 받아 왔지만, ICPC는 많은 대학의 출전을 위해 상위권 대학에 더 엄격한 기준을 적용하여 본선 팀을 선발합니다. 구체적으로는, 먼저 $x$ 문제를 푼 팀들을 모두 선발하고, 이후에는 $x-1$ 문제를 푼 팀들 중 각 대학의 $y_i$ 위 이상인 팀… 을 선발하는 식입니다. 이 방식을 적용하는 데 있어, 어떤 학교도 총 출전팀의 50% 이상을 본선에 보내지 못한다는 (과거엔 explicit하게 적혀 있었다고 하지만, 지금은 찾을 수 없고, 그럼에도 아직 적용되는 것으로 보이는) 룰 이 있습니다. 맨 위의 선발 기준은 사실상 서울대를 위해 만들어졌으며 (서울대 15팀 중 7팀 이하를 자르는 컷을 찾습니다), 본선 진출 경계선인 60위에 (작년에는 90위였을 거고 그럼 얘기가 다릅니다) 50% 이상의 팀을 보낼 수 있는 학교는 몇 없기 때문에 (서울대, KAIST, 고려대 정도. 아마 해에 따라 다른 학교들도 가능한 해가 있을 것입니다) 사실상 저격밴이 됩니다. 제가 이번에 휴학생 팀으로 나간 이유도 여기에 있습니다. 저랑 비슷한 수준의 팀원 두명을 모으면 본선 진출이 어차피 어려울 것이고, 저보다 월등히 잘하는 팀원을 찾으면 어떻게 나가볼 수 있을지는 모르겠지만 첫째로는 그런 사람이 저랑 팀을 해줄지도 의문이고 두번째로는 해준다고 해도 제가 대회를 재밌게 즐기지 못할 것 같았습니다. 그래서 휴학생 팀이지만, 대회 자체를 진심으로 즐길 수 있는 - 일종의 즐겜팀이라고 할까요 - Little Piplup에 다시 함께했습니다. 이 monotonic하지 않은 선발 기준에 대해 어떻게 생각하는지는 사람마다 다른 영역인 것 같습니다. 저는 당연히 이 기준으로 본선 무대를 못 밟았으므로 굉장히 화가 나지만, 대학 대항전인 ICPC에서 서울대 15팀이 나타나는 것이 그럼 맞느냐? 고 말하면 뭐 그렇게 볼 수도 있습니다. 다만, 이 부분은 조금 나아질 기미가 보이는데, PS판에서 서울대가 보여줬던 갭이 점점 줄어드는게 눈에 보이기 때문입니다. 올해의 인예 순위에서 솔브수로 격차를 낸 최상위권은 서울-서울-고려-카이-카이-유니 입니다. (7솔에 저희를 포함 무려 12팀이 물려 있습니다) 참고로, 작년 인예는 9솔 이상이 7팀이었는데, 서울-서울-서울-서울-카이-서울-숭실 이었습니다. PS판의 저변이 넓어져서 그런 것인지, 서울대의 수많은 레드들이 PS판을 떠나고 ML 같은 보다 쓸모있는 뭔가를 공부하러 갔기 때문인지, 최근 여러 학교에서 레드 이상의 CP-er를 배출한 데 어떤 요소들이 작용했는지는 잘 모르겠지만 아무튼 그렇습니다. 레드 한명이 졸업할때까지 뛸수있는 ICPC판을 보니 내년에도 이럴 것 같고, 작년처럼 서울대 리저널 6팀인가? 보내 줬더니 모든 상을 서울대가 쓸어버리는 참사가 벌어지지는 않을 것입니다. 저는 내년이 마지막 ICPC고, 알고리즘을 공부하면서 / PS를 즐기면서 ICPC 본선 리저널 무대를 한번도 가보지 못했다는 것이 개인적으로 굉장히 아쉽습니다. 어떻게 보면 아카데믹하게 알고리즘을 공부하겠다는 목표를 갖게 된 지금은 PS 자체에 큰 의미는 없겠지만, 개인적으로 느낀 바가 그렇습니다. 그래서, 겨울방학에 좀 빡세게 돌면서 레드 정도 수준까지 폼을 맞춰놓고, 내년에는 레드 3명 또는 그에 근접한, 진출을 노리는 팀을 만들어 마지막 ICPC에 도전할 계획입니다. 좋은 팀원을 모은다면 80% 이상 가능하다고 확신하고 있습니다. 혹시 이 블로그를 보신 서울대 재학생 중, 내년 10월까지 CF 2300 또는 Equivalent한 실력을 갖출 수 있으며, 휴학 계획이 없고, 같이 공부하고 싶은 분은 연락주시면 좋을것 같네요. ㅋㅋ!!! (당연한 말이지만 이런 허공에 돌던지는 식으로 모을 생각으로 쓴 말은 아닙니다…) 대회를 마치며 항상 PS 대회를 뛰고 나면, PS를 즐기는 마인드와 대회 성적에 따른 competitive 한 마인드가 서로 충돌하게 됩니다. 이번 대회는 정말 간만에 그런 것 없이 순수하게 즐길 수 있었는데, 대회가 끝나고 나니 competitive mind가 잠깐 지배하고 있어서 위 500단어 정도를 ranting했습니다. 학기중에는 어차피 매우 바쁘기 때문에, 겨울방학에나 다시 손댈 수 있지 않을까 싶습니다. 끝나고 팀원들과 치킨을 먹으면서 대회에 대한 얘기도 하고, 재밌게 놀고 왔습니다. 네. 이 문장은 기만질 자랑하려고 적었습니다. ㅋㅋ!!! &amp;#8617;</summary></entry><entry><title type="html">[P] Multi Layer Perceptron</title><link href="http://localhost:4000/deep-learning-study/multilayer-perceptron/" rel="alternate" type="text/html" title="[P] Multi Layer Perceptron" /><published>2021-10-12T00:00:00+09:00</published><updated>2021-10-12T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/multilayer-perceptron</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/multilayer-perceptron/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#linear-layer&quot; id=&quot;markdown-toc-linear-layer&quot;&gt;Linear Layer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#multi-layer-perceptron&quot; id=&quot;markdown-toc-multi-layer-perceptron&quot;&gt;Multi Layer Perceptron&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#weight-initialization&quot; id=&quot;markdown-toc-weight-initialization&quot;&gt;Weight Initialization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gradient-computation--back-propagation&quot; id=&quot;markdown-toc-gradient-computation--back-propagation&quot;&gt;Gradient Computation : Back propagation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 6강 (9월 23일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 글은 SVM과 Logistic Regression &lt;a href=&quot;/deep-learning-study/svm-and-lr&quot;&gt;링크&lt;/a&gt;, Softmax Regression &lt;a href=&quot;/deep-learning-study/softmax-regression&quot;&gt;링크&lt;/a&gt; 에 이어지는 내용입니다.&lt;/p&gt;

&lt;p&gt;나중에 설명을 보강해서 다시 작성될 예정입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Logistic regression 같은 $f_\theta(x) = a^T x + b$ case를 1-layer (linear layer) neural network로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;Softmax Regression 설명 마지막에 했던 것처럼, 적절한 loss function $\ell$ 을 도입한 다음, $\ell(f_\theta(x), y)$ 를 최적화하는 경우를 생각하자. Logistic regression은 여기에 $\ell$로 logistic loss를, $f_\theta$ 자리에 linear model을 넣은 특수한 케이스이다. 이를 좀더 엄밀하게 생각하기 위해, Linear layer를 생각하자.&lt;/p&gt;

&lt;h3 id=&quot;linear-layer&quot;&gt;Linear Layer&lt;/h3&gt;
&lt;p&gt;입력으로 $X \in \R^{B \x n}$, where $B = $ batch size, $n = $ 입력 크기를 받아서, 출력 $Y \in \R^{B \x m}$ 크기의 텐서를 출력하는데,
\(Y_{k, i} = \sum_{j = 1}^{n} A_{i, j} X_{k, j} + b_i\)
이와 같이 작동하는 layer 를, batch의 각 벡터 $x_k$ 에 대해 $y_k = A x_k + b$ 형태의 선형으로 나타난다는 의미에서 linear layer라 한다. 이때 $A$ 행렬을 weight, $b$ 벡터를 bias라 한다.&lt;/p&gt;

&lt;p&gt;따라서, Logistic Regression이란, 하나의 Linear layer를 이용하고, loss function으로 logistic loss (KL-divergence with logistic probability) 를 사용하는 Shallow neural network 라고 다시 정의할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;multi-layer-perceptron&quot;&gt;Multi Layer Perceptron&lt;/h3&gt;
&lt;p&gt;Multi-Layer (Deep Network) 를 생각하면, linear function의 깊은 결합은 어차피 linear하므로 아무 의미가 없다.&lt;/p&gt;

&lt;p&gt;그러나, 적당한 non-linear activation function $\sigma$ 를 도입하여, 다음과 같은 layer를 구축하면 의미가 있게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/ff57f23d2850f3930f519254ad5691f7b02dee930010d30ffa0e4a39b57b8d93.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;즉, 이를 식으로 쓰면…
\(\begin{align*}
    y_L &amp;amp;= W_L y_{L-1} + b_L \\
    y_{L - 1} &amp;amp;= \sigma(W_{L-1} y_{L - 2} + b_{L - 1}) \\
    \cdots &amp;amp; \cdots \\
    y_2 &amp;amp;= \sigma (W_2 y_1 + b_2) \\
    y_1 &amp;amp;= \sigma (W_1 x + b_1)
\end{align*}\)
where $x \in \R^{n_0}, W_l \in \R^{n_l \x n_{l-1}}, n_L = 1$. (Binary classification만 잠깐 생각하기로 하자)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;주로 $\sigma$ 로는 ReLU $ = \max(z, 0)$, Sigmoid $\frac{1}{1 + e^{-z}}$, Hyperbolic tangent $\frac{1 - e^{-2z}}{1 + e^{-2z}}$ 를 쓴다.&lt;/li&gt;
  &lt;li&gt;관례적으로 마지막 layer에는 $\sigma$를 넣지 않는 경향이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 모델을 &lt;strong&gt;MultiLayer Perceptron (MLP)&lt;/strong&gt; 또는 Fully connected neural network 라 한다.&lt;/p&gt;

&lt;h3 id=&quot;weight-initialization&quot;&gt;Weight Initialization&lt;/h3&gt;
&lt;p&gt;SGD $\theta^{k + 1} = \theta^k - \alpha g^k$ 에서, $\theta^0$ 은 convex optimization에서는 어떤 점을 골라도 global solution으로 수렴하므로 의미가 없지만, deep learning에서는 $\theta^0$ 을 잘 주는 것이 중요한 문제가 된다.&lt;/p&gt;

&lt;p&gt;단순하게 $\theta^0 = 0$ 을 쓰면, vanishing gradient 의 문제가 발생한다. Pytorch에서는 따로 이를 처리하는 방법이 있음.&lt;/p&gt;

&lt;h3 id=&quot;gradient-computation--back-propagation&quot;&gt;Gradient Computation : Back propagation&lt;/h3&gt;
&lt;p&gt;다시 잠깐 logistic regression을 생각하면, loss function을 다 셋업한 다음 결국 마지막에는 stochastic gradient descent 같은 방법을 이용해서 최적화할 계획으로 진행했다. 그렇다는 말은, 결국 어떻게든 뭔가 저 loss function의 gradient를 계산할 방법이 있기는 해야 한다는 의미가 된다. 즉, 각 layer의 weight들과 bias들의 각 원소들 $A_{i, j, k}$에 대해, $\pdv{y_L}{A_{i, j, k}}$ 를 계산할 수 있어야 한다.&lt;/p&gt;

&lt;p&gt;MLP에서는 이 gradient 계산이 직접 수행하기에는 매우 어렵기 때문에, 이를 pytorch에서는 autograd 함수로 제공한다. 다만 기본적인 원리는 vector calculus의 chain rule에 기반한다. 나중에 이를 따로 다룬다.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Linear Layer Multi Layer Perceptron Weight Initialization Gradient Computation : Back propagation 심층 신경망의 수학적 기초 6강 (9월 23일) 에 기반합니다. 이 글은 SVM과 Logistic Regression 링크, Softmax Regression 링크 에 이어지는 내용입니다. 나중에 설명을 보강해서 다시 작성될 예정입니다. Logistic regression 같은 $f_\theta(x) = a^T x + b$ case를 1-layer (linear layer) neural network로 볼 수 있다. Softmax Regression 설명 마지막에 했던 것처럼, 적절한 loss function $\ell$ 을 도입한 다음, $\ell(f_\theta(x), y)$ 를 최적화하는 경우를 생각하자. Logistic regression은 여기에 $\ell$로 logistic loss를, $f_\theta$ 자리에 linear model을 넣은 특수한 케이스이다. 이를 좀더 엄밀하게 생각하기 위해, Linear layer를 생각하자. Linear Layer 입력으로 $X \in \R^{B \x n}$, where $B = $ batch size, $n = $ 입력 크기를 받아서, 출력 $Y \in \R^{B \x m}$ 크기의 텐서를 출력하는데, \(Y_{k, i} = \sum_{j = 1}^{n} A_{i, j} X_{k, j} + b_i\) 이와 같이 작동하는 layer 를, batch의 각 벡터 $x_k$ 에 대해 $y_k = A x_k + b$ 형태의 선형으로 나타난다는 의미에서 linear layer라 한다. 이때 $A$ 행렬을 weight, $b$ 벡터를 bias라 한다. 따라서, Logistic Regression이란, 하나의 Linear layer를 이용하고, loss function으로 logistic loss (KL-divergence with logistic probability) 를 사용하는 Shallow neural network 라고 다시 정의할 수 있다. Multi Layer Perceptron Multi-Layer (Deep Network) 를 생각하면, linear function의 깊은 결합은 어차피 linear하므로 아무 의미가 없다. 그러나, 적당한 non-linear activation function $\sigma$ 를 도입하여, 다음과 같은 layer를 구축하면 의미가 있게 된다. 즉, 이를 식으로 쓰면… \(\begin{align*} y_L &amp;amp;= W_L y_{L-1} + b_L \\ y_{L - 1} &amp;amp;= \sigma(W_{L-1} y_{L - 2} + b_{L - 1}) \\ \cdots &amp;amp; \cdots \\ y_2 &amp;amp;= \sigma (W_2 y_1 + b_2) \\ y_1 &amp;amp;= \sigma (W_1 x + b_1) \end{align*}\) where $x \in \R^{n_0}, W_l \in \R^{n_l \x n_{l-1}}, n_L = 1$. (Binary classification만 잠깐 생각하기로 하자) 주로 $\sigma$ 로는 ReLU $ = \max(z, 0)$, Sigmoid $\frac{1}{1 + e^{-z}}$, Hyperbolic tangent $\frac{1 - e^{-2z}}{1 + e^{-2z}}$ 를 쓴다. 관례적으로 마지막 layer에는 $\sigma$를 넣지 않는 경향이 있다. 이 모델을 MultiLayer Perceptron (MLP) 또는 Fully connected neural network 라 한다. Weight Initialization SGD $\theta^{k + 1} = \theta^k - \alpha g^k$ 에서, $\theta^0$ 은 convex optimization에서는 어떤 점을 골라도 global solution으로 수렴하므로 의미가 없지만, deep learning에서는 $\theta^0$ 을 잘 주는 것이 중요한 문제가 된다. 단순하게 $\theta^0 = 0$ 을 쓰면, vanishing gradient 의 문제가 발생한다. Pytorch에서는 따로 이를 처리하는 방법이 있음. Gradient Computation : Back propagation 다시 잠깐 logistic regression을 생각하면, loss function을 다 셋업한 다음 결국 마지막에는 stochastic gradient descent 같은 방법을 이용해서 최적화할 계획으로 진행했다. 그렇다는 말은, 결국 어떻게든 뭔가 저 loss function의 gradient를 계산할 방법이 있기는 해야 한다는 의미가 된다. 즉, 각 layer의 weight들과 bias들의 각 원소들 $A_{i, j, k}$에 대해, $\pdv{y_L}{A_{i, j, k}}$ 를 계산할 수 있어야 한다. MLP에서는 이 gradient 계산이 직접 수행하기에는 매우 어렵기 때문에, 이를 pytorch에서는 autograd 함수로 제공한다. 다만 기본적인 원리는 vector calculus의 chain rule에 기반한다. 나중에 이를 따로 다룬다.</summary></entry><entry><title type="html">[P] Softmax Regression</title><link href="http://localhost:4000/deep-learning-study/softmax-regression/" rel="alternate" type="text/html" title="[P] Softmax Regression" /><published>2021-10-12T00:00:00+09:00</published><updated>2021-10-12T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/softmax-regression</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/softmax-regression/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#softmax-regression&quot; id=&quot;markdown-toc-softmax-regression&quot;&gt;Softmax Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 6강 (9월 23일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 글은 SVM과 Logistic Regression &lt;a href=&quot;/deep-learning-study/svm-and-lr&quot;&gt;링크&lt;/a&gt; 에 이어지는 내용입니다.&lt;/p&gt;

&lt;p&gt;나중에 설명을 보강해서 다시 작성될 예정입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨
$Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이번에는 그런데, $Y_i$ 가 $-1$ 과 $1$ 중에서 고르는 것이 아니라 $\Set{1, 2, \dots k}$ 중 하나이다.&lt;/p&gt;

&lt;h2 id=&quot;softmax-regression&quot;&gt;Softmax Regression&lt;/h2&gt;
&lt;p&gt;Logistic Regression의 확장된 버전으로, multi-class classification을 하고 싶다. 여전히 empirical distribution의 개념을 사용한다. $\mathcal{P}(y)$ 는 크기 $k$의 벡터로, one-hot encoding 된 것으로 보자.&lt;/p&gt;

&lt;p&gt;Softmax 함수를 이용하여, $\argmax$ 를 in some sense smooth- 한다. Define $\mu : \R^k \to \R^k$ as
\(\mu(z)_i = \frac{e^{z_i}}{\sum_{j = 1}^{k} e^{z_j}}\)&lt;/p&gt;

&lt;p&gt;이 함수값의 모든 index $i$에 대한 합이 1이기 때문에, $\mu(z)_i$ 를 일종의 confidence 확률로 생각할 수 있다.&lt;/p&gt;

&lt;p&gt;이제, 모델 $\mu(f_{A, b}(x)) = \mu(Ax + b)$ 를 택하자. 이때, $x \in \R^n$ 에 대해, $A$의 각 row vector 를 $a_i^T$ 라 하면, $f_{A, b}(x)$ 는 다음 그림과 같이 $(f_{A, b}(x))_i = (a_i^Tx + b_i)$ 인 크기 $k$의 벡터가 되고, $\mu$ 를 붙이면 각 index에 softmax를 쓴 결과가 된다. 결국은 어떤 행렬곱을 해서 벡터를 얻은 다음, 그 벡터에다가 softmax를 붙인 셈.&lt;/p&gt;

&lt;p&gt;우리는 다음과 같은 최적화 문제를 해결하고자 한다.
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \sum_{i = 1}^{N} \DKL{\mathcal{P}(Y_i)}{\mu(f_{a, b}(X_i))}\)
이 식을 정리하면, Logistic regression 때처럼 다음 문제와 동치임을 안다.
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \sum_{i = 1}^{N} H(\mathcal{P}(Y), \mu(f_{a, b}(X)))\)
이제, 다시 cross entropy 항을 전개하여 정리한다.
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ -\sum_{i = 1}^{N} \sum_{j = 1}^{k} \mathcal{P}(Y_i)_j \log (\mu(f_{A, b}(X_i))_j)\)
여기서 $\mathcal{P}(Y_i)_j$ 는 $j = Y_i$ 일 때 1이고 나머지는 0이므로,
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ -\sum_{i = 1}^{N} \log \mu(f_{A, b}(X_{i}))_{Y_i} =
\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ -\sum_{i = 1}^{N} \log \left(
\frac{e^{a_{Y_i}^T X_i + b_{Y_i}}}{\sum_{j = 1}^{k} e^{a_j^TX_i + b_j}}\right)\)
이 식을 정리하여,
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \sum_{i = 1}^{N} \left(-(a_{Y_i}^T X_i + b_{Y_i}) + \log\left(\sum_{j = 1}^{k} e^{a_j^TX_i + b_j}\right)\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Interesting fact&lt;/strong&gt; : Softmax regression은 잘 보면 결과 식이 사실 convex하다. 또한, $n = 2$ 일 때, 이 식은 Logistic regression과 동치이다.&lt;/p&gt;

&lt;p&gt;이를 편하게 쓰기 위해, Cross Entropy Loss 라는 함수를 정의한다.
\(\ell^{\text{CE}} (f, y) = - \log\left(\frac{e^{f_y}}{\sum_{j = 1}^{k} e^{f_j}}\right)\)
이제, 이 함수를 이용하여 쉽게 Softmax Regression을 정의할 수 있다.
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell^{\text{CE}}(f_{A, b}(X_i), Y_i)\)&lt;/p&gt;

&lt;p&gt;이는 즉, Softmax Regression을 정의하는 데 있어서…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;단순한 Linear model을 Cross Entropy Loss로 최적화하기&lt;/li&gt;
  &lt;li&gt;Softmax-ed Linear model의 KL Divergence로 최적화하기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결국은 둘이 같은 말이지만 (CE Loss가 결국 softmax처리한 확률분포를 고려하겠다는 의미이므로), 전자의 표현이 좀더 일반화가 쉽다.&lt;/p&gt;

&lt;p&gt;전자의 표현을 이용하여 SR을 자연스럽게 확장하면, linear model $f_{A, b}$ 대신 어떤 임의의 model $f_\theta(X_i)$ 와의 cross entropy loss를 minimize하는 것처럼 생각해 볼 수도 있다.
\(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell^{\text{CE}}(f_{\theta}(X_i), Y_i)\)&lt;/p&gt;

&lt;p&gt;이는 cross entropy loss가 기본적으로는 어떤 arg-max 스러운 (by softmax) choice를 해서 그 결과값의 empirical distribution과의 KL-Divergence를 minimize하는 개념으로 적용되기 때문.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Softmax Regression 심층 신경망의 수학적 기초 6강 (9월 23일) 에 기반합니다. 이 글은 SVM과 Logistic Regression 링크 에 이어지는 내용입니다. 나중에 설명을 보강해서 다시 작성될 예정입니다. 데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨 $Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이번에는 그런데, $Y_i$ 가 $-1$ 과 $1$ 중에서 고르는 것이 아니라 $\Set{1, 2, \dots k}$ 중 하나이다. Softmax Regression Logistic Regression의 확장된 버전으로, multi-class classification을 하고 싶다. 여전히 empirical distribution의 개념을 사용한다. $\mathcal{P}(y)$ 는 크기 $k$의 벡터로, one-hot encoding 된 것으로 보자. Softmax 함수를 이용하여, $\argmax$ 를 in some sense smooth- 한다. Define $\mu : \R^k \to \R^k$ as \(\mu(z)_i = \frac{e^{z_i}}{\sum_{j = 1}^{k} e^{z_j}}\) 이 함수값의 모든 index $i$에 대한 합이 1이기 때문에, $\mu(z)_i$ 를 일종의 confidence 확률로 생각할 수 있다. 이제, 모델 $\mu(f_{A, b}(x)) = \mu(Ax + b)$ 를 택하자. 이때, $x \in \R^n$ 에 대해, $A$의 각 row vector 를 $a_i^T$ 라 하면, $f_{A, b}(x)$ 는 다음 그림과 같이 $(f_{A, b}(x))_i = (a_i^Tx + b_i)$ 인 크기 $k$의 벡터가 되고, $\mu$ 를 붙이면 각 index에 softmax를 쓴 결과가 된다. 결국은 어떤 행렬곱을 해서 벡터를 얻은 다음, 그 벡터에다가 softmax를 붙인 셈. 우리는 다음과 같은 최적화 문제를 해결하고자 한다. \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \sum_{i = 1}^{N} \DKL{\mathcal{P}(Y_i)}{\mu(f_{a, b}(X_i))}\) 이 식을 정리하면, Logistic regression 때처럼 다음 문제와 동치임을 안다. \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \sum_{i = 1}^{N} H(\mathcal{P}(Y), \mu(f_{a, b}(X)))\) 이제, 다시 cross entropy 항을 전개하여 정리한다. \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ -\sum_{i = 1}^{N} \sum_{j = 1}^{k} \mathcal{P}(Y_i)_j \log (\mu(f_{A, b}(X_i))_j)\) 여기서 $\mathcal{P}(Y_i)_j$ 는 $j = Y_i$ 일 때 1이고 나머지는 0이므로, \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ -\sum_{i = 1}^{N} \log \mu(f_{A, b}(X_{i}))_{Y_i} = \underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ -\sum_{i = 1}^{N} \log \left( \frac{e^{a_{Y_i}^T X_i + b_{Y_i}}}{\sum_{j = 1}^{k} e^{a_j^TX_i + b_j}}\right)\) 이 식을 정리하여, \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \sum_{i = 1}^{N} \left(-(a_{Y_i}^T X_i + b_{Y_i}) + \log\left(\sum_{j = 1}^{k} e^{a_j^TX_i + b_j}\right)\right)\) Interesting fact : Softmax regression은 잘 보면 결과 식이 사실 convex하다. 또한, $n = 2$ 일 때, 이 식은 Logistic regression과 동치이다. 이를 편하게 쓰기 위해, Cross Entropy Loss 라는 함수를 정의한다. \(\ell^{\text{CE}} (f, y) = - \log\left(\frac{e^{f_y}}{\sum_{j = 1}^{k} e^{f_j}}\right)\) 이제, 이 함수를 이용하여 쉽게 Softmax Regression을 정의할 수 있다. \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell^{\text{CE}}(f_{A, b}(X_i), Y_i)\) 이는 즉, Softmax Regression을 정의하는 데 있어서… 단순한 Linear model을 Cross Entropy Loss로 최적화하기 Softmax-ed Linear model의 KL Divergence로 최적화하기 결국은 둘이 같은 말이지만 (CE Loss가 결국 softmax처리한 확률분포를 고려하겠다는 의미이므로), 전자의 표현이 좀더 일반화가 쉽다. 전자의 표현을 이용하여 SR을 자연스럽게 확장하면, linear model $f_{A, b}$ 대신 어떤 임의의 model $f_\theta(X_i)$ 와의 cross entropy loss를 minimize하는 것처럼 생각해 볼 수도 있다. \(\underset{A \in \R^{k \x n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell^{\text{CE}}(f_{\theta}(X_i), Y_i)\) 이는 cross entropy loss가 기본적으로는 어떤 arg-max 스러운 (by softmax) choice를 해서 그 결과값의 empirical distribution과의 KL-Divergence를 minimize하는 개념으로 적용되기 때문.</summary></entry><entry><title type="html">Softmax Regression / MLP로 MNIST 풀어보기</title><link href="http://localhost:4000/deep-learning-study/mnist-mlp/" rel="alternate" type="text/html" title="Softmax Regression / MLP로 MNIST 풀어보기" /><published>2021-10-06T00:00:00+09:00</published><updated>2021-10-06T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/mnist-mlp</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/mnist-mlp/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#problem--dataset&quot; id=&quot;markdown-toc-problem--dataset&quot;&gt;Problem / Dataset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#softmax-regression&quot; id=&quot;markdown-toc-softmax-regression&quot;&gt;Softmax Regression&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#multi-layer-perceptron&quot; id=&quot;markdown-toc-multi-layer-perceptron&quot;&gt;Multi-Layer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 5강, 6강 (9월 16일, 23일) 에 기반합니다. 이번 내용은 대부분이 코드에 대한 내용이라서, $\LaTeX$ 노트를 변환하지 않고 여기에 바로 작성했습니다.&lt;/p&gt;

&lt;p&gt;아직 읽지 않았다면, 최소한 &lt;a href=&quot;/deep-learning-study/softmax-regression&quot;&gt;Softmax(링크)&lt;/a&gt;와 &lt;a href=&quot;/deep-learning-study/multilayer-perceptron&quot;&gt;MLP(링크)&lt;/a&gt;에 대한 포스팅 을, 되도록 &lt;a href=&quot;/deep-learning-study/&quot;&gt;링크&lt;/a&gt; 에 있는 포스팅 중 shallow-nn과 SVM, LR에 대한 내용을 읽으면 이론적 배경이 충분할 것으로 생각합니다 (제가 이 내용을 공부해서 이해한대로 정리했으니까요..?)&lt;/p&gt;

&lt;h2 id=&quot;problem--dataset&quot;&gt;Problem / Dataset&lt;/h2&gt;
&lt;p&gt;이번에 해결하고자 하는 문제는, MNIST라는 매우 유명한 데이터셋을 이용합니다. MNIST는 Hand-written 숫자로 구성된 데이터셋으로, 널리 알려진 CNN 모델을 처음 제시한 LeCun의 연구에 사용되었던 데이터셋이기도 합니다. 실제로 작동하는 딥 러닝을 만들기에는 너무 작은 데이터셋이지만 공부하는 목적으로 주로 사용됩니다.&lt;/p&gt;

&lt;p&gt;각 이미지는 28 by 28 grayscale image로, 편의상 $\R^{28 \times 28}$ 으로 생각하면 됩니다.&lt;/p&gt;

&lt;p&gt;가장 먼저 해야할 일은 pytorch module을 import하고, 데이터를 받아오고 정리하는 것입니다.&lt;br /&gt;
Pytorch에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt;라는 모듈을 이용하여, 편하게 데이터를 Batch로 먹인다거나 하는 작업을 할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optimizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist_data/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist_data/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cuda&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;device =&lt;/code&gt; 부분은 가능하다면 cuda GPU를 사용하도록 하는 부분인데, 사실 이번 태스크는 너무 작기 때문에 GPU를 쓰면 이득이 없거나 오히려 더 느려질 수도 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;softmax-regression&quot;&gt;Softmax Regression&lt;/h2&gt;
&lt;p&gt;먼저, 우리는 Softmax regression을 시도해 보겠습니다. Pytorch에서는 다음과 같은 과정으로 머신러닝 모델을 학습합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Model 정의 : 입력 $x$를 어떤 과정을 거쳐 출력값으로 만들지를 정의합니다. 이 모델에는 훈련가능한 parameter가 있습니다.&lt;/li&gt;
  &lt;li&gt;Loss function 정의 : 모델이 어떤 방법으로 현재 정확도를 측정할지를 정의합니다.&lt;/li&gt;
  &lt;li&gt;학습 : Training data를 이용하여 모델의 파라미터를 조정합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제, Model을 정의해야 합니다. Model은 기본적으로 softmax regression에서 공부했던 모델로, $Ax + b$ 를 10개 만들어야 합니다.&lt;/p&gt;

&lt;p&gt;여기서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__&lt;/code&gt; 을 이용하여 이 모델에서 쓸 Layer들을 정의하고, 그 Layer들을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;forward&lt;/code&gt; 메서드를 통해 사용해서 넘겨주면 됩니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SoftMax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SoftMax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Softmax Regression은 이렇게 정의된 model에 다음과 같은 최적화 문제를 푸는 방법입니다. 
\(\underset{a \in \R^{k \times n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N}  \left(-(a_{Y_i}^T X_i + b_{Y_i} + \log\left(\sum_{j = 1}^{k} e^{a_j^TX_i + b}\right)\right)\)&lt;/p&gt;

&lt;p&gt;pytorch에는 $Ax + b$의 결과만 받아내면 이를 계산해주는 함수가 있으므로, 모델은 $Ax + b$만 해주면 됩니다.&lt;br /&gt;
대신 Loss function을 다음과 같이 사용합니다. 여기서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lr&lt;/code&gt; 은 learning rate, $\alpha$ 값을 의미합니다. 최적화 자체에는 Stochastic Gradient Descent를 사용하겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;    
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.03&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제, 우리에게 필요한 모델의 훈련 과정은 이렇게 진행됩니다. Epoch를 많이 돌릴수록 정확해지긴 하지만, 투입하는 시간 대비 얼만큼의 효율이 있는지는 상황마다 다르므로 적당히 판단할 필요가 있습니다.&lt;/p&gt;

&lt;p&gt;워낙 단순한 모델이라 학습할게 많지 않으므로 여기서는 epoch=2 (즉, 전체 데이터를 두바퀴 돌립니다) 만 돌리겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;NUM_EPOCH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUM_EPOCH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이를 뜯어보면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt; 로 기존 MLP 모델에 남아있던 gradient 값들을 다 날리고&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_loss&lt;/code&gt; 는 현재 시점에 모델이 이미지를 받아서 추측을 해보고 그 loss function 값을 확인하고,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.backward()&lt;/code&gt; 로 현재 시점의 gradient를 계산하고&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizer.step()&lt;/code&gt; 으로 실제 optimization (여기선 SGD)를 수행합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면, 이 모델은 얼마나 정확할까요?&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view_as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'''[Test set]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Average loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, 
Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%)'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 코드는 테스트셋을 모두 한바퀴 돌리면서, test loss의 값과 결과의 정확도를 확인합니다.&lt;/p&gt;

&lt;p&gt;초기화 상황 등에 따라 조금 달라질수는 있을텐데, 저는 2번의 epoch로 92.11%의 정확도를 얻을 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;multi-layer-perceptron&quot;&gt;Multi-Layer Perceptron&lt;/h2&gt;
&lt;p&gt;Pytorch는 굉장히 쓰기 편한 모듈인데, 위 코드에서 정말 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model&lt;/code&gt;만 바꾸면 바로 MLP를 사용해볼수 있습니다. MLP를 수행하면서 점점 개수가 줄어들어야 하는데, 여기서는 크게 중요하지 않으므로 그냥 편의상 점점 줄어드는 이쁜 값을 몇개 적어넣겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MLP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 모델은 activation function으로 ReLU를 쓰는 depth 4짜리 MLP인데, 784 -&amp;gt; 256 -&amp;gt; 128 -&amp;gt; 64 -&amp;gt; 10으로 단계적으로 개수를 줄여나갑니다. 순서대로 Linear-&amp;gt;ReLU-&amp;gt;…-&amp;gt;Linear로 끝납니다.&lt;/p&gt;

&lt;p&gt;위 코드에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss_function&lt;/code&gt; 정의부터는 그대로 실행하면 됩니다. 저는 로컬에서 정확도가 96% 정도 나오고, 참을성을 갖고 Epoch를 10으로 바꿨을 때는 98%의 정확도를 얻을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;Q. 왜 4단계 layer를 (3단계, 5단계가 아니라…) 쓰나요?&lt;br /&gt;
-&amp;gt; 일반적으로 Layer가 깊어질수록 파라미터가 많아져서 training 시간이 오래 걸리고 capacity가 커집니다. 반대로, layer가 얕으면 non-linearity를 충분히 주지 못해서 underfitting할 우려가 있습니다. 
그렇다고 해서 문제로부터 바로 몇 Layer짜리 MLP를 쓸지 결정할 수 있는 것은 아닙니다. 해보니까 저는 4 Layer 정도가 가장 적당해 보였습니다.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Problem / Dataset Softmax Regression Multi-Layer Perceptron 심층 신경망의 수학적 기초 5강, 6강 (9월 16일, 23일) 에 기반합니다. 이번 내용은 대부분이 코드에 대한 내용이라서, $\LaTeX$ 노트를 변환하지 않고 여기에 바로 작성했습니다. 아직 읽지 않았다면, 최소한 Softmax(링크)와 MLP(링크)에 대한 포스팅 을, 되도록 링크 에 있는 포스팅 중 shallow-nn과 SVM, LR에 대한 내용을 읽으면 이론적 배경이 충분할 것으로 생각합니다 (제가 이 내용을 공부해서 이해한대로 정리했으니까요..?) Problem / Dataset 이번에 해결하고자 하는 문제는, MNIST라는 매우 유명한 데이터셋을 이용합니다. MNIST는 Hand-written 숫자로 구성된 데이터셋으로, 널리 알려진 CNN 모델을 처음 제시한 LeCun의 연구에 사용되었던 데이터셋이기도 합니다. 실제로 작동하는 딥 러닝을 만들기에는 너무 작은 데이터셋이지만 공부하는 목적으로 주로 사용됩니다. 각 이미지는 28 by 28 grayscale image로, 편의상 $\R^{28 \times 28}$ 으로 생각하면 됩니다. 가장 먼저 해야할 일은 pytorch module을 import하고, 데이터를 받아오고 정리하는 것입니다. Pytorch에서는 DataLoader라는 모듈을 이용하여, 편하게 데이터를 Batch로 먹인다거나 하는 작업을 할 수 있습니다. import torch import torch.nn as nn from torch.optim import Optimizer from torch.utils.data import DataLoader from torchvision import datasets from torchvision.transforms import transforms train_set = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True) test_set = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=True) train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True) test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False) device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) device = 부분은 가능하다면 cuda GPU를 사용하도록 하는 부분인데, 사실 이번 태스크는 너무 작기 때문에 GPU를 쓰면 이득이 없거나 오히려 더 느려질 수도 있습니다. Softmax Regression 먼저, 우리는 Softmax regression을 시도해 보겠습니다. Pytorch에서는 다음과 같은 과정으로 머신러닝 모델을 학습합니다. Model 정의 : 입력 $x$를 어떤 과정을 거쳐 출력값으로 만들지를 정의합니다. 이 모델에는 훈련가능한 parameter가 있습니다. Loss function 정의 : 모델이 어떤 방법으로 현재 정확도를 측정할지를 정의합니다. 학습 : Training data를 이용하여 모델의 파라미터를 조정합니다. 이제, Model을 정의해야 합니다. Model은 기본적으로 softmax regression에서 공부했던 모델로, $Ax + b$ 를 10개 만들어야 합니다. 여기서, __init__ 을 이용하여 이 모델에서 쓸 Layer들을 정의하고, 그 Layer들을 forward 메서드를 통해 사용해서 넘겨주면 됩니다. class SoftMax(nn.Module): def __init__(self): super().__init__() self.layer = nn.Linear(28*28, 10, bias=True) def forward(self, x): return self.layer(x.float().view(-1, 28 * 28)) model = SoftMax() Softmax Regression은 이렇게 정의된 model에 다음과 같은 최적화 문제를 푸는 방법입니다. \(\underset{a \in \R^{k \times n}, b \in \R^k}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \left(-(a_{Y_i}^T X_i + b_{Y_i} + \log\left(\sum_{j = 1}^{k} e^{a_j^TX_i + b}\right)\right)\) pytorch에는 $Ax + b$의 결과만 받아내면 이를 계산해주는 함수가 있으므로, 모델은 $Ax + b$만 해주면 됩니다. 대신 Loss function을 다음과 같이 사용합니다. 여기서 lr 은 learning rate, $\alpha$ 값을 의미합니다. 최적화 자체에는 Stochastic Gradient Descent를 사용하겠습니다. loss_function = torch.nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.03) 이제, 우리에게 필요한 모델의 훈련 과정은 이렇게 진행됩니다. Epoch를 많이 돌릴수록 정확해지긴 하지만, 투입하는 시간 대비 얼만큼의 효율이 있는지는 상황마다 다르므로 적당히 판단할 필요가 있습니다. 워낙 단순한 모델이라 학습할게 많지 않으므로 여기서는 epoch=2 (즉, 전체 데이터를 두바퀴 돌립니다) 만 돌리겠습니다. NUM_EPOCH = 2 for epoch in range(NUM_EPOCH) : for images, labels in train_loader : optimizer.zero_grad() train_loss = loss_function(model(images), labels) train_loss.backward() optimizer.step() 이를 뜯어보면, optimizer.zero_grad() 로 기존 MLP 모델에 남아있던 gradient 값들을 다 날리고 train_loss 는 현재 시점에 모델이 이미지를 받아서 추측을 해보고 그 loss function 값을 확인하고, .backward() 로 현재 시점의 gradient를 계산하고 optimizer.step() 으로 실제 optimization (여기선 SGD)를 수행합니다. 그렇다면, 이 모델은 얼마나 정확할까요? test_loss, correct = 0, 0 for ind, (image, label) in enumerate(test_loader) : image, label = image.to(device), label.to(device) output = model(image) test_loss += loss_function(output, label).item() pred = output.max(1, keepdim=True)[1] correct += pred.eq(label.view_as(pred)).sum().item() print(f'''[Test set]\nAverage loss: {test_loss /len(test_loader):.4f}, Accuracy: {correct}/{len(test_loader)} ({100. * correct / len(test_loader):.2f}%)''') 이 코드는 테스트셋을 모두 한바퀴 돌리면서, test loss의 값과 결과의 정확도를 확인합니다. 초기화 상황 등에 따라 조금 달라질수는 있을텐데, 저는 2번의 epoch로 92.11%의 정확도를 얻을 수 있었습니다. Multi-Layer Perceptron Pytorch는 굉장히 쓰기 편한 모듈인데, 위 코드에서 정말 model만 바꾸면 바로 MLP를 사용해볼수 있습니다. MLP를 수행하면서 점점 개수가 줄어들어야 하는데, 여기서는 크게 중요하지 않으므로 그냥 편의상 점점 줄어드는 이쁜 값을 몇개 적어넣겠습니다. class MLP(nn.Module) : def __init__(self,) : super().__init__() self.linear = nn.Linear(784, 256, bias=True) self.linear2 = nn.Linear(256, 128, bias=True) self.linear3 = nn.Linear(128, 64, bias=True) self.linear4 = nn.Linear(64, 10, bias=True) def forward(self, x) : x = x.float().view(-1, 784) x = nn.functional.relu(self.linear(x)) x = nn.functional.relu(self.linear2(x)) x = nn.functional.relu(self.linear3(x)) x = self.linear4(x) return x model = MLP().to(device) 이 모델은 activation function으로 ReLU를 쓰는 depth 4짜리 MLP인데, 784 -&amp;gt; 256 -&amp;gt; 128 -&amp;gt; 64 -&amp;gt; 10으로 단계적으로 개수를 줄여나갑니다. 순서대로 Linear-&amp;gt;ReLU-&amp;gt;…-&amp;gt;Linear로 끝납니다. 위 코드에서 loss_function 정의부터는 그대로 실행하면 됩니다. 저는 로컬에서 정확도가 96% 정도 나오고, 참을성을 갖고 Epoch를 10으로 바꿨을 때는 98%의 정확도를 얻을 수 있었습니다. Q. 왜 4단계 layer를 (3단계, 5단계가 아니라…) 쓰나요? -&amp;gt; 일반적으로 Layer가 깊어질수록 파라미터가 많아져서 training 시간이 오래 걸리고 capacity가 커집니다. 반대로, layer가 얕으면 non-linearity를 충분히 주지 못해서 underfitting할 우려가 있습니다. 그렇다고 해서 문제로부터 바로 몇 Layer짜리 MLP를 쓸지 결정할 수 있는 것은 아닙니다. 해보니까 저는 4 Layer 정도가 가장 적당해 보였습니다.</summary></entry><entry><title type="html">GCPC 2020 팀연습</title><link href="http://localhost:4000/cp-rounds/team-practice-gcpc-2020/" rel="alternate" type="text/html" title="GCPC 2020 팀연습" /><published>2021-09-28T00:00:00+09:00</published><updated>2021-09-28T00:00:00+09:00</updated><id>http://localhost:4000/cp-rounds/team-practice-gcpc-2020</id><content type="html" xml:base="http://localhost:4000/cp-rounds/team-practice-gcpc-2020/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#f--flip-flow-10분-ac&quot; id=&quot;markdown-toc-f--flip-flow-10분-ac&quot;&gt;F : Flip Flow (10분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#a--adolescent-architecture--k--knightly-knowledge-45--85분-ac-각-1wa&quot; id=&quot;markdown-toc-a--adolescent-architecture--k--knightly-knowledge-45--85분-ac-각-1wa&quot;&gt;A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#c--confined-catching-67분-ac&quot; id=&quot;markdown-toc-c--confined-catching-67분-ac&quot;&gt;C : Confined Catching (67분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#i--impressive-integers-103분-ac-4-wa&quot; id=&quot;markdown-toc-i--impressive-integers-103분-ac-4-wa&quot;&gt;I : Impressive Integers (103분 AC, 4 WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#d--decorative-dominoes-142분-ac&quot; id=&quot;markdown-toc-d--decorative-dominoes-142분-ac&quot;&gt;D : Decorative Dominoes (142분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#g--gravity-grid-160분-ac-3-wa&quot; id=&quot;markdown-toc-g--gravity-grid-160분-ac-3-wa&quot;&gt;G : Gravity Grid (160분 AC, 3 WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#b--bookshelf-building-175분-ac-3-wa&quot; id=&quot;markdown-toc-b--bookshelf-building-175분-ac-3-wa&quot;&gt;B : Bookshelf Building (175분 AC, 3 WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#m--mixtape-management-199분-ac&quot; id=&quot;markdown-toc-m--mixtape-management-199분-ac&quot;&gt;M : Mixtape Management (199분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#l--lexicographical-lecturing-209분-ac&quot; id=&quot;markdown-toc-l--lexicographical-lecturing-209분-ac&quot;&gt;L : Lexicographical Lecturing (209분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#review&quot; id=&quot;markdown-toc-review&quot;&gt;Review&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;멤버가 조금씩 바뀌면서 지난 3년간 UCPC, ICPC, HashCode 등을 함께해온 팀 Little Piplup으로 이번에는 다시 제가 참여하게 되었습니다.&lt;/p&gt;

&lt;p&gt;이 팀은 2019년 저와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coffeetea&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DHDroid&lt;/code&gt;로 시작해서 PS 공부도 같이 하고, 많은 대회를 뛰면서 나름 행복 PS 해온 팀입니다. 2020년에는 Hashcode를 기점으로 저랑 그전까지 같이 연습셋을 많이 돌았던 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dlwocks31&lt;/code&gt;이 들어와서 4명이 되었습니다.&lt;/p&gt;

&lt;p&gt;Hashcode는 4인팀이지만, UCPC와 ICPC는 3인 1팀입니다. 또한, ICPC의 경우 휴학생이 본선에 진출할수 없다는 규정이 있는데 이 팀은 저를 제외한 3명이 모두 휴학생 (병특 중)이라 2020 ICPC에서는 자연스럽게 제가 다른 팀을 찾아 나가고 3명이서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Army Piplup&lt;/code&gt; 을 구성해서 나갈 수 있었고, 2020 UCPC는 dlwocks31이 다른 팀원들이랑 출전했었습니다. 2021 UCPC는… 2명 2명을 가르고 한명씩을 더 영입했는데, 저랑 dlwocks31쪽은 어리석은 실수로 대회를 치르지 못했었습니다.&lt;/p&gt;

&lt;p&gt;이번에는 dlwocks31이 딱히 PS에 더이상 동기가 많이 떨어졌다는 식으로 기회를 양보하기도 했고, 저는 다른 팀원들을 모으더라도 서울대에서 본선을 진출하기는 쉽지 않겠다는 판단이 들어서 행복 PS를 위해 이 팀 그대로 나가기로 했습니다. 무엇보다 같이 문제를 풀고 팀연습하는 과정을 즐길 수 있는 팀이라서 그렇기도 합니다.&lt;/p&gt;

&lt;p&gt;ICPC는 순수하게 PS를 즐기러 나가지만 (본선 진출권도 없으므로) 그래도 이왕 모인거 팀연습이나 한두번 하자는 생각으로 GCPC 2020 셋을 돌았습니다.&lt;/p&gt;

&lt;p&gt;GCPC는 비교적 쉬운 리저널로, 원래 5시간 셋이지만 예선만 나갈거기도 하고 저희한테 시간이 많이 없어서 3.5시간으로 잡고 돌았습니다. 풀만한 문제는 다 푼듯 합니다.&lt;/p&gt;

&lt;p&gt;DHdroid가 ABCD, 제가 EFGHI, Coffeetea가 JKLM을 읽자고 생각했지만 커뮤니케이션 미스로 Coffeetea가 I부터 읽었고 M은 아무도 잡지 않았습니다. ㅋㅋㅋㅋ&lt;/p&gt;

&lt;h3 id=&quot;f--flip-flow-10분-ac&quot;&gt;F : Flip Flow (10분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Gratus907     Code : Gratus907&lt;/code&gt;&lt;br /&gt;
재밌게도 GCPC는 문제제목이 문제 번호를 따라갑니다.&lt;/p&gt;

&lt;p&gt;모래시계를 뒤집으면서 남은 모래의 양을 확인하는 문제인데, 전체 시간 $t$가 작아서 그대로 시뮬레이션 할 수 있습니다. 10분에 AC.&lt;/p&gt;

&lt;h3 id=&quot;a--adolescent-architecture--k--knightly-knowledge-45--85분-ac-각-1wa&quot;&gt;A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA)&lt;/h3&gt;
&lt;p&gt;각각 DHDroid / Coffeetea가 잡았습니다.&lt;/p&gt;

&lt;p&gt;E는 딱 보기에도 어려웠고, G는 귀찮은 구현이 필요해 보였습니다. H는 너무 문제가 길어서 걸러버렸고… ‘컴퓨터가 남으면’ G를 짜겠다고 말했는데, DHdroid와 Coffeetea가 A, K가 쉽다고 주장했으므로 컴퓨터를 제가 잡고있는건 좋은 전략이 아니라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;다만 둘다 구현을 그렇게 빠르게 쳐내지는 못했습니다. 저는 두 문제 다 읽지 않았지만 각각 2000, 2500바이트의 코딩이 필요했던 것으로 보아 뇌절도 있었지만 근본적으로 구현난이도가 좀 있었던것 같습니다.&lt;/p&gt;

&lt;p&gt;저는 양쪽 다 구현에 참여하지 않았고, 둘다 구상이 끝나고 구현만 남은 상태였기 때문에, DHDroid가 A번을 코딩할 때는 Coffeetea랑 같이 I번을, Coffeetea가 K번을 코딩하는 동안 DHDroid랑 같이 C, D를 풀 수 있었습니다. Coffeetea가 K번의 구현에서 상당히 많이 고전했기 때문에, 버그를 찾기 위해 코드를 따로 보면서 (실전에서는 코드 출력에 해당하는 선택입니다) 저한테 중간에 컴퓨터를 넘겨서 I번을 (몇번의 디버깅 끝에) 성공했습니다.&lt;/p&gt;

&lt;h3 id=&quot;c--confined-catching-67분-ac&quot;&gt;C : Confined Catching (67분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Gratus907, DHDroid&lt;/code&gt;&lt;br /&gt;
굉장히 재밌는 퍼즐틱한 문제였다고 생각합니다.&lt;br /&gt;
상하좌우로 움직일 수 있는 ‘말’ 이 나에게 2개, 상대에게 1개 주어집니다. $100 \times 100$ 그리드 안에서, 내가 두 말을 동시에 움직이면, 상대가 그걸 보고 도망칠 수 있습니다. 말 두 개를 잘 coordination해서, 상대 말을 ‘잡으면’ 이기는 게임입니다. 단, 600턴의 시간 제한이 있습니다.&lt;/p&gt;

&lt;p&gt;처음에는 두 말이 이루는 직사각형을 좁히는 등 몇가지 아이디어를 생각했지만, 적절한 아이디어가 없어 고민하던 중에 제가 말 하나는 $x$좌표를 먼저 따라붙고, 말 하나는 $y$좌표를 먼저 따라붙는 아이디어를 제시했습니다. 상대가 어느쪽으로 도망치든 두 말 중 적어도 하나는 거리를 줄일 수 있음을 보장받기 때문에 (직선상의 경우가 예외가 되지만, 다음 턴에는 다시 줄일 수 있습니다) 어떻게 될 것 같았고, 잘 코너로 몰면 이길 수 있다고 생각했습니다.&lt;/p&gt;

&lt;p&gt;DHDroid가 이걸 받고 잠깐 생각해보더니 ‘내 말 두 개와 벽이 이루는 직사각형이 줄어든다’ 는 논증으로 이 방법이 올바름을 증명했고, 제가 Coffeetea에게 잠깐 컴퓨터를 받아서 구현해서 맞았습니다.&lt;/p&gt;

&lt;h3 id=&quot;i--impressive-integers-103분-ac-4-wa&quot;&gt;I : Impressive Integers (103분 AC, 4 WA)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Coffeetea, Gratus907&lt;/code&gt;&lt;br /&gt;
요약하자면, 어떤 $n$이 주어졌을 때, 자연수 $a, b, c$를 골라서, 한 변의 길이가 $c$인 정삼각형을 한 변의 길이가 $a$ 와 $b$인 정삼각형들로 채우는데 정확히 $n$개를 쓰도록 할 수 있는지에 대한 문제입니다.&lt;/p&gt;

&lt;p&gt;Coffeetea가 먼저 맨 위에 1개 또는 4개만 쓰고, 나머지를 잘 채워넣으면 될것같다는 간단하지만 문제를 바로 해결하는 아이디어를 던졌고, 제가 빈 로직을 채워넣어서 문제를 해결했습니다. $n$이 큰 짝수일 때는, 맨 위에 큰 삼각형 1개를 놓고, 아래를 한 변의 길이가 1인 삼각형 $n-1$개로 채울 수 있습니다. ($n-1$이 홀수이기 때문에, 위아래로 채워넣으면 됩니다) 반대로 $n$이 큰 홀수일 때는 맨 위에 삼각형 4개를 놓고, 아래를 한 변의 길이가 짝수인 삼각형 $n-4$개로 채워넣으면 됩니다. 이 방법으로 $n = 2, 3, 5$ 외에는 모든 경우를 해결할 수 있음을 보이면 됩니다.&lt;/p&gt;

&lt;p&gt;구현에서 숫자를 off-by-one 에러 내서 무려 4번을 틀렸습니다. 흑흑…&lt;/p&gt;

&lt;h3 id=&quot;d--decorative-dominoes-142분-ac&quot;&gt;D : Decorative Dominoes (142분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : DHDroid, Gratus907     Code : Gratus907&lt;/code&gt;  &lt;br /&gt;
재밌게 풀었습니다. 도미노에 숫자를 써넣되, 숫자가 2번 이상 중복되어서는 안 되고, 도미노칸 하나는 적어도 주변에 같은 숫자가 써있는 도미노가 하나 있어야 합니다.&lt;/p&gt;

&lt;p&gt;문제를 이분 매칭으로 만들어 풀면 그렇게 어렵지는 않은데 구현이 상당히 귀찮습니다. DHDroid가 이분매칭의 대략적인 아이디어를 제시하고, 제가 정확히 어떻게 풀건지 좀 고민해보다가 풀었습니다. pair를 노드로 다시 인코딩한다던가 하는 구현의 잡다한 트릭들이 많이 들어간것 같습니다.&lt;/p&gt;

&lt;p&gt;이때, 제가 구현하는 동안 DHDroid는 계속 L에 대한 아이디어를 제시하고 Coffeetea와 B를 해결했습니다. D와 L을 오가면서 저랑 DHdroid가 풀이를 둘다 거의 완성했었기 때문에, L번도 사실 시간이 충분하다면 코딩할 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;g--gravity-grid-160분-ac-3-wa&quot;&gt;G : Gravity Grid (160분 AC, 3 WA)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Gratus907     Code : Gratus907&lt;/code&gt;&lt;br /&gt;
단순 시뮬레이션 문제입니다. 중력이 작용하는 칸에서 열만 고르면서 틱택토를 하는데, $k$개를 한줄로 (가로, 세로, 대각선) 모으면 승리합니다.&lt;/p&gt;

&lt;p&gt;가로 방향, 세로 방향, 대각선 방향의 DSU를 관리하면 어렵지 않습니다. 가로방향과 세로방향의 크기는 자명한데, 대각선방향은 대각선에 적절한 인덱스를 부여하여 $(h + w)$개의 DSU를 $\min(h, w)$개 칸을 갖도록 관리하면 잘 해볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;중간에 실수로, $h$와 $w$를 바꿔 썼는데 놀랍게도 WA가 아니라 MLE를 받았습니다. 어떤 원리로 MLE가 나는지는 파악하지 못한 채로, 벡터로 정수 900만 개를 allocate하는거 자체가 문제가 있는건가 하는 생각에 new int를 쓰는 등 삽질을 했지만 원인은 단순 실수였음을 한참 나중에 찾아냈습니다.&lt;/p&gt;

&lt;h3 id=&quot;b--bookshelf-building-175분-ac-3-wa&quot;&gt;B : Bookshelf Building (175분 AC, 3 WA)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : DHDroid, Coffeetea     Code : DHDroid&lt;/code&gt;  &lt;br /&gt;
읽어보지 않았지만 제가 G번 푸는 동안 둘이 잘 풀고 코딩했습니다.&lt;/p&gt;

&lt;h3 id=&quot;m--mixtape-management-199분-ac&quot;&gt;M : Mixtape Management (199분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Coffeetea, Gratus907&lt;/code&gt;
쉬운 문제이지만 팀원간의 커뮤니케이션 실수로 아무도 읽지 않아서 버려진 문제입니다. 문제가 매우 길고 지문이 혼란스러운데, 숫자의 크기 정렬과 문자열로써의 정렬 간에 발생하는 차이에 대한 문제입니다.&lt;/p&gt;

&lt;p&gt;이 숫자가 몇번째에 위치해야 하는지를 파악한 다음, 그 앞에는 모두 1들을, 자기 자신은 2를, 뒤에는 3들을 붙이면 됩니다. 이 말만으로는 전혀 무슨말인지 알 수가 없지만..&lt;/p&gt;

&lt;p&gt;예제 4 2 6 1 5 7 3 을 보면, 1이 4번째이므로 1 1 1 2 3 3 3 으로 만듭니다. 이후에는, 2가 두번째이므로 11, 12, 13, 2 (이미 끝난 숫자는 건드리지 않습니다), 33, 33, 33으로 만들고… 이런식으로 1, 2, 3을 붙여서 만들면 됩니다.&lt;/p&gt;

&lt;p&gt;예제에 대한 저희의 답은 1112 12 131312 2 33132 3313332 332 입니다. 20줄 내외의 코드로 해결가능합니다. ㅋㅋ! 199분 AC.&lt;/p&gt;

&lt;h3 id=&quot;l--lexicographical-lecturing-209분-ac&quot;&gt;L : Lexicographical Lecturing (209분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : DHDroid, Gratus907     Code : Gratus907&lt;/code&gt;
먼저 문제를 설명하자면, $n$ 개의 길이 $L$짜리 문자열이 주어지고, 이 문자열의 어떤 $[i, j]$ 구간들만을 이용하여 정렬한 결과가 원래의 정렬 결과와 같게 하는 최소 길이 $[i, j]$를 찾는 문제입니다.&lt;/p&gt;

&lt;p&gt;Prefix에 관한 배열을 관리하는데, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p[k][j]&lt;/code&gt; 는 현재 보는 $k$번 문자열과 그 앞 문자열의 $j$번째 문자를 비교한 결과를 저장합니다. 이때, 우리가 원하는 $[i, j]$는 이 $p$배열에서 다음과 같게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$p$배열의 sub-matrix $[2, n] \times [i, j]$를 뽑았을 때, 모든 행에 leading 1이 있어야 합니다. $p$배열의 정의를 생각해보면, sub-matrix의 row가 1로 시작한다면 (첫번째 non-zero element가 1이라는 뜻) 정렬 결과가 올바르고, -1이라면 정렬 결과가 틀리며, 모든 element가 0이라면 비교가 불가능해서 판단할 수 없기 때문에 역시 올바르지 않습니다.&lt;/li&gt;
  &lt;li&gt;그러면, 이를 어떻게 파악할 것인지가 문제인데…&lt;/li&gt;
  &lt;li&gt;각 i, j마다, “내 뒤로 보이는 첫번째 +1”과 “내 뒤로 보이는 첫번째 -1” 의 위치를 저장합니다. 이제, 어떤 $[i, -]$ 구간이 올바르기 위해서는 $i$번 뒤로 나타나는 첫번째 1의 위치가 첫번째 -1보다 앞이어야 합니다.&lt;/li&gt;
  &lt;li&gt;이제, $i$로 시작하는 구간들 중, 적어도 모든 행이 leading 1을 갖도록 구간 끝점을 뒤로 밀어줘야 합니다.&lt;/li&gt;
  &lt;li&gt;각 $i$로 시작하는 구간들을 $O(n)$에 판단가능해서, $O(nL)$ 시간에 작동합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이번 연습 하이라이트는, M번을 맞고 나서 시간이 11분 남아있었는데 제가 이걸 10분 만에 짜서 예제만 돌려보고 바로 내서 맞았다는 점입니다. ㅋㅋ!! 
제가 구현을 못하는것은 구현이 느려서가 아니라 말렸을때 답이 없어서 그런거고, 사실 구현 속도는 그럭저럭 느리지 않은 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;review&quot;&gt;Review&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;여전히 이 팀은 그냥 PS를 즐길 수 있게 해주는 원동력입니다. 세명의 장단점이 비교적 뚜렷하고 서로 보완적인 구성입니다.&lt;/li&gt;
  &lt;li&gt;GCPC 셋 자체는 괜찮은데, 5시간이었다면 아마 남은 1시간 반동안 하나 잡고 풀기 쉽지 않았을 것 같습니다. 실제로 남은 문제들은 충격적인 난이도 (다이아 또는 ?) 를 가지고 있었습니다.&lt;/li&gt;
  &lt;li&gt;제가 구현에 묶여있는동안 두명이 J도 좀 풀어놨던데, 무슨 각도정렬 + 미친기하 + 단절점 문제였습니다. 결과적으로 솔루션은 거의 다 맞았던 것으로 기억하는데, 저는 24시간 줘도 그걸 구현할 자신이 없으므로 아마 어차피 AC를 받지는 못했을 것입니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="cp-rounds" /><summary type="html">Contents F : Flip Flow (10분 AC) A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA) C : Confined Catching (67분 AC) I : Impressive Integers (103분 AC, 4 WA) D : Decorative Dominoes (142분 AC) G : Gravity Grid (160분 AC, 3 WA) B : Bookshelf Building (175분 AC, 3 WA) M : Mixtape Management (199분 AC) L : Lexicographical Lecturing (209분 AC) Review 멤버가 조금씩 바뀌면서 지난 3년간 UCPC, ICPC, HashCode 등을 함께해온 팀 Little Piplup으로 이번에는 다시 제가 참여하게 되었습니다. 이 팀은 2019년 저와 Coffeetea, DHDroid로 시작해서 PS 공부도 같이 하고, 많은 대회를 뛰면서 나름 행복 PS 해온 팀입니다. 2020년에는 Hashcode를 기점으로 저랑 그전까지 같이 연습셋을 많이 돌았던 Dlwocks31이 들어와서 4명이 되었습니다. Hashcode는 4인팀이지만, UCPC와 ICPC는 3인 1팀입니다. 또한, ICPC의 경우 휴학생이 본선에 진출할수 없다는 규정이 있는데 이 팀은 저를 제외한 3명이 모두 휴학생 (병특 중)이라 2020 ICPC에서는 자연스럽게 제가 다른 팀을 찾아 나가고 3명이서 Army Piplup 을 구성해서 나갈 수 있었고, 2020 UCPC는 dlwocks31이 다른 팀원들이랑 출전했었습니다. 2021 UCPC는… 2명 2명을 가르고 한명씩을 더 영입했는데, 저랑 dlwocks31쪽은 어리석은 실수로 대회를 치르지 못했었습니다. 이번에는 dlwocks31이 딱히 PS에 더이상 동기가 많이 떨어졌다는 식으로 기회를 양보하기도 했고, 저는 다른 팀원들을 모으더라도 서울대에서 본선을 진출하기는 쉽지 않겠다는 판단이 들어서 행복 PS를 위해 이 팀 그대로 나가기로 했습니다. 무엇보다 같이 문제를 풀고 팀연습하는 과정을 즐길 수 있는 팀이라서 그렇기도 합니다. ICPC는 순수하게 PS를 즐기러 나가지만 (본선 진출권도 없으므로) 그래도 이왕 모인거 팀연습이나 한두번 하자는 생각으로 GCPC 2020 셋을 돌았습니다. GCPC는 비교적 쉬운 리저널로, 원래 5시간 셋이지만 예선만 나갈거기도 하고 저희한테 시간이 많이 없어서 3.5시간으로 잡고 돌았습니다. 풀만한 문제는 다 푼듯 합니다. DHdroid가 ABCD, 제가 EFGHI, Coffeetea가 JKLM을 읽자고 생각했지만 커뮤니케이션 미스로 Coffeetea가 I부터 읽었고 M은 아무도 잡지 않았습니다. ㅋㅋㅋㅋ F : Flip Flow (10분 AC) Solve : Gratus907 Code : Gratus907 재밌게도 GCPC는 문제제목이 문제 번호를 따라갑니다. 모래시계를 뒤집으면서 남은 모래의 양을 확인하는 문제인데, 전체 시간 $t$가 작아서 그대로 시뮬레이션 할 수 있습니다. 10분에 AC. A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA) 각각 DHDroid / Coffeetea가 잡았습니다. E는 딱 보기에도 어려웠고, G는 귀찮은 구현이 필요해 보였습니다. H는 너무 문제가 길어서 걸러버렸고… ‘컴퓨터가 남으면’ G를 짜겠다고 말했는데, DHdroid와 Coffeetea가 A, K가 쉽다고 주장했으므로 컴퓨터를 제가 잡고있는건 좋은 전략이 아니라고 생각했습니다. 다만 둘다 구현을 그렇게 빠르게 쳐내지는 못했습니다. 저는 두 문제 다 읽지 않았지만 각각 2000, 2500바이트의 코딩이 필요했던 것으로 보아 뇌절도 있었지만 근본적으로 구현난이도가 좀 있었던것 같습니다. 저는 양쪽 다 구현에 참여하지 않았고, 둘다 구상이 끝나고 구현만 남은 상태였기 때문에, DHDroid가 A번을 코딩할 때는 Coffeetea랑 같이 I번을, Coffeetea가 K번을 코딩하는 동안 DHDroid랑 같이 C, D를 풀 수 있었습니다. Coffeetea가 K번의 구현에서 상당히 많이 고전했기 때문에, 버그를 찾기 위해 코드를 따로 보면서 (실전에서는 코드 출력에 해당하는 선택입니다) 저한테 중간에 컴퓨터를 넘겨서 I번을 (몇번의 디버깅 끝에) 성공했습니다. C : Confined Catching (67분 AC) Solve : Gratus907, DHDroid 굉장히 재밌는 퍼즐틱한 문제였다고 생각합니다. 상하좌우로 움직일 수 있는 ‘말’ 이 나에게 2개, 상대에게 1개 주어집니다. $100 \times 100$ 그리드 안에서, 내가 두 말을 동시에 움직이면, 상대가 그걸 보고 도망칠 수 있습니다. 말 두 개를 잘 coordination해서, 상대 말을 ‘잡으면’ 이기는 게임입니다. 단, 600턴의 시간 제한이 있습니다. 처음에는 두 말이 이루는 직사각형을 좁히는 등 몇가지 아이디어를 생각했지만, 적절한 아이디어가 없어 고민하던 중에 제가 말 하나는 $x$좌표를 먼저 따라붙고, 말 하나는 $y$좌표를 먼저 따라붙는 아이디어를 제시했습니다. 상대가 어느쪽으로 도망치든 두 말 중 적어도 하나는 거리를 줄일 수 있음을 보장받기 때문에 (직선상의 경우가 예외가 되지만, 다음 턴에는 다시 줄일 수 있습니다) 어떻게 될 것 같았고, 잘 코너로 몰면 이길 수 있다고 생각했습니다. DHDroid가 이걸 받고 잠깐 생각해보더니 ‘내 말 두 개와 벽이 이루는 직사각형이 줄어든다’ 는 논증으로 이 방법이 올바름을 증명했고, 제가 Coffeetea에게 잠깐 컴퓨터를 받아서 구현해서 맞았습니다. I : Impressive Integers (103분 AC, 4 WA) Solve : Coffeetea, Gratus907 요약하자면, 어떤 $n$이 주어졌을 때, 자연수 $a, b, c$를 골라서, 한 변의 길이가 $c$인 정삼각형을 한 변의 길이가 $a$ 와 $b$인 정삼각형들로 채우는데 정확히 $n$개를 쓰도록 할 수 있는지에 대한 문제입니다. Coffeetea가 먼저 맨 위에 1개 또는 4개만 쓰고, 나머지를 잘 채워넣으면 될것같다는 간단하지만 문제를 바로 해결하는 아이디어를 던졌고, 제가 빈 로직을 채워넣어서 문제를 해결했습니다. $n$이 큰 짝수일 때는, 맨 위에 큰 삼각형 1개를 놓고, 아래를 한 변의 길이가 1인 삼각형 $n-1$개로 채울 수 있습니다. ($n-1$이 홀수이기 때문에, 위아래로 채워넣으면 됩니다) 반대로 $n$이 큰 홀수일 때는 맨 위에 삼각형 4개를 놓고, 아래를 한 변의 길이가 짝수인 삼각형 $n-4$개로 채워넣으면 됩니다. 이 방법으로 $n = 2, 3, 5$ 외에는 모든 경우를 해결할 수 있음을 보이면 됩니다. 구현에서 숫자를 off-by-one 에러 내서 무려 4번을 틀렸습니다. 흑흑… D : Decorative Dominoes (142분 AC) Solve : DHDroid, Gratus907 Code : Gratus907 재밌게 풀었습니다. 도미노에 숫자를 써넣되, 숫자가 2번 이상 중복되어서는 안 되고, 도미노칸 하나는 적어도 주변에 같은 숫자가 써있는 도미노가 하나 있어야 합니다. 문제를 이분 매칭으로 만들어 풀면 그렇게 어렵지는 않은데 구현이 상당히 귀찮습니다. DHDroid가 이분매칭의 대략적인 아이디어를 제시하고, 제가 정확히 어떻게 풀건지 좀 고민해보다가 풀었습니다. pair를 노드로 다시 인코딩한다던가 하는 구현의 잡다한 트릭들이 많이 들어간것 같습니다. 이때, 제가 구현하는 동안 DHDroid는 계속 L에 대한 아이디어를 제시하고 Coffeetea와 B를 해결했습니다. D와 L을 오가면서 저랑 DHdroid가 풀이를 둘다 거의 완성했었기 때문에, L번도 사실 시간이 충분하다면 코딩할 수 있었습니다. G : Gravity Grid (160분 AC, 3 WA) Solve : Gratus907 Code : Gratus907 단순 시뮬레이션 문제입니다. 중력이 작용하는 칸에서 열만 고르면서 틱택토를 하는데, $k$개를 한줄로 (가로, 세로, 대각선) 모으면 승리합니다. 가로 방향, 세로 방향, 대각선 방향의 DSU를 관리하면 어렵지 않습니다. 가로방향과 세로방향의 크기는 자명한데, 대각선방향은 대각선에 적절한 인덱스를 부여하여 $(h + w)$개의 DSU를 $\min(h, w)$개 칸을 갖도록 관리하면 잘 해볼 수 있습니다. 중간에 실수로, $h$와 $w$를 바꿔 썼는데 놀랍게도 WA가 아니라 MLE를 받았습니다. 어떤 원리로 MLE가 나는지는 파악하지 못한 채로, 벡터로 정수 900만 개를 allocate하는거 자체가 문제가 있는건가 하는 생각에 new int를 쓰는 등 삽질을 했지만 원인은 단순 실수였음을 한참 나중에 찾아냈습니다. B : Bookshelf Building (175분 AC, 3 WA) Solve : DHDroid, Coffeetea Code : DHDroid 읽어보지 않았지만 제가 G번 푸는 동안 둘이 잘 풀고 코딩했습니다. M : Mixtape Management (199분 AC) Solve : Coffeetea, Gratus907 쉬운 문제이지만 팀원간의 커뮤니케이션 실수로 아무도 읽지 않아서 버려진 문제입니다. 문제가 매우 길고 지문이 혼란스러운데, 숫자의 크기 정렬과 문자열로써의 정렬 간에 발생하는 차이에 대한 문제입니다. 이 숫자가 몇번째에 위치해야 하는지를 파악한 다음, 그 앞에는 모두 1들을, 자기 자신은 2를, 뒤에는 3들을 붙이면 됩니다. 이 말만으로는 전혀 무슨말인지 알 수가 없지만.. 예제 4 2 6 1 5 7 3 을 보면, 1이 4번째이므로 1 1 1 2 3 3 3 으로 만듭니다. 이후에는, 2가 두번째이므로 11, 12, 13, 2 (이미 끝난 숫자는 건드리지 않습니다), 33, 33, 33으로 만들고… 이런식으로 1, 2, 3을 붙여서 만들면 됩니다. 예제에 대한 저희의 답은 1112 12 131312 2 33132 3313332 332 입니다. 20줄 내외의 코드로 해결가능합니다. ㅋㅋ! 199분 AC. L : Lexicographical Lecturing (209분 AC) Solve : DHDroid, Gratus907 Code : Gratus907 먼저 문제를 설명하자면, $n$ 개의 길이 $L$짜리 문자열이 주어지고, 이 문자열의 어떤 $[i, j]$ 구간들만을 이용하여 정렬한 결과가 원래의 정렬 결과와 같게 하는 최소 길이 $[i, j]$를 찾는 문제입니다. Prefix에 관한 배열을 관리하는데, p[k][j] 는 현재 보는 $k$번 문자열과 그 앞 문자열의 $j$번째 문자를 비교한 결과를 저장합니다. 이때, 우리가 원하는 $[i, j]$는 이 $p$배열에서 다음과 같게 됩니다. $p$배열의 sub-matrix $[2, n] \times [i, j]$를 뽑았을 때, 모든 행에 leading 1이 있어야 합니다. $p$배열의 정의를 생각해보면, sub-matrix의 row가 1로 시작한다면 (첫번째 non-zero element가 1이라는 뜻) 정렬 결과가 올바르고, -1이라면 정렬 결과가 틀리며, 모든 element가 0이라면 비교가 불가능해서 판단할 수 없기 때문에 역시 올바르지 않습니다. 그러면, 이를 어떻게 파악할 것인지가 문제인데… 각 i, j마다, “내 뒤로 보이는 첫번째 +1”과 “내 뒤로 보이는 첫번째 -1” 의 위치를 저장합니다. 이제, 어떤 $[i, -]$ 구간이 올바르기 위해서는 $i$번 뒤로 나타나는 첫번째 1의 위치가 첫번째 -1보다 앞이어야 합니다. 이제, $i$로 시작하는 구간들 중, 적어도 모든 행이 leading 1을 갖도록 구간 끝점을 뒤로 밀어줘야 합니다. 각 $i$로 시작하는 구간들을 $O(n)$에 판단가능해서, $O(nL)$ 시간에 작동합니다. 이번 연습 하이라이트는, M번을 맞고 나서 시간이 11분 남아있었는데 제가 이걸 10분 만에 짜서 예제만 돌려보고 바로 내서 맞았다는 점입니다. ㅋㅋ!! 제가 구현을 못하는것은 구현이 느려서가 아니라 말렸을때 답이 없어서 그런거고, 사실 구현 속도는 그럭저럭 느리지 않은 것 같습니다. Review 여전히 이 팀은 그냥 PS를 즐길 수 있게 해주는 원동력입니다. 세명의 장단점이 비교적 뚜렷하고 서로 보완적인 구성입니다. GCPC 셋 자체는 괜찮은데, 5시간이었다면 아마 남은 1시간 반동안 하나 잡고 풀기 쉽지 않았을 것 같습니다. 실제로 남은 문제들은 충격적인 난이도 (다이아 또는 ?) 를 가지고 있었습니다. 제가 구현에 묶여있는동안 두명이 J도 좀 풀어놨던데, 무슨 각도정렬 + 미친기하 + 단절점 문제였습니다. 결과적으로 솔루션은 거의 다 맞았던 것으로 기억하는데, 저는 24시간 줘도 그걸 구현할 자신이 없으므로 아마 어차피 AC를 받지는 못했을 것입니다.</summary></entry><entry><title type="html">Semantic Segmentation : Introduction</title><link href="http://localhost:4000/deep-learning-study/semantic-segmentation/" rel="alternate" type="text/html" title="Semantic Segmentation : Introduction" /><published>2021-09-26T00:00:00+09:00</published><updated>2021-09-26T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/semantic-segmentation</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/semantic-segmentation/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#문제-소개&quot; id=&quot;markdown-toc-문제-소개&quot;&gt;문제 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#활용&quot; id=&quot;markdown-toc-활용&quot;&gt;활용&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#개요&quot; id=&quot;markdown-toc-개요&quot;&gt;개요&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이 글의 상당 부분은, 서베이 논문인 Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtarnavaz, N., &amp;amp; Terzopoulos, D. (2020). Image Segmentation Using Deep Learning: A Survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–22. https://doi.org/10.1109/TPAMI.2021.3059968 을 정리한 내용입니다.&lt;/p&gt;

&lt;h2 id=&quot;문제-소개&quot;&gt;문제 소개&lt;/h2&gt;
&lt;p&gt;Semantic Segmentation이란, Computer Vision 분야의 대표적인 task중 하나로, 간단히 요약하자면&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이미지가 주어졌을 때&lt;/strong&gt;, 그 이미지를 픽셀단위로 &lt;strong&gt;어떤 대상인지&lt;/strong&gt; 를 분류해내는 문제입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/65248dcf9168b967e664f799c65014d13df38e1e7bff5db23b3db50ee05952ff.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;br /&gt;
출처 : Stanford cs231n slides&lt;/p&gt;

&lt;p&gt;이 사진은 대표적인 네 가지의 task를 비교한 것인데, 굉장히 직관적으로 무슨 의미인지 알 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;활용&quot;&gt;활용&lt;/h2&gt;
&lt;p&gt;Semantic segmentation은 딱 느낌에도 매우 유용할 것 같은데, 대표적인 활용처 몇개를 생각해보면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;자율 주행 : 자율주행에서 지금 눈앞에 보이는 것이 도로인지, 흙바닥인지, 물웅덩이인지를 판단하는 작업은 굉장히 중요합니다.&lt;/li&gt;
  &lt;li&gt;의료 이미지 : CT 사진에서, 각 고형장기를 분류한다거나, 정상조직과 비정상조직을 구분하는 작업도 결국은 segmentation에 기반합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;
&lt;p&gt;여기서는 정말 대략적인 아이디어를 한줄로 정리하고, 개별 네트워크 구조에 대한 포스팅을 통해 전체 내용을 붙여나가려고 합니다.&lt;/p&gt;

&lt;p&gt;이 이미지가 개인지, 고양이인지를 판단하는 Classification의 경우, 통상적으로 convolutional neural network (CNN) 에 기반한 방법들을 사용합니다. 사진 전체의 정보를 인코딩한 $3 \times W \times H$ 텐서를 가지고 시작해서, Convolution layer를 거치면서 정보들을 추출하고, 마지막에 fully connected layer를 붙여서 실제로 클래스를 구분해내는 식으로 진행하게 되는 것입니다.&lt;/p&gt;

&lt;p&gt;이 방법을 semantic segmentation같은 문제에서 적용하기 어려운 이유는, 마지막 fully connected layer가 기하적인 위치정보를 다 날려버리기 때문입니다. 즉, ‘고양이가’ 있다는 정보는 어떻게 분류해볼 수 있을지라도, 고양이가 ‘어디에’ 있는지에 대해서는 전혀 알 수가 없게 됩니다. 그렇기 때문에 fully connected layer를 쓸 수 없습니다.&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해 나온 아이디어로, 마지막 정보를 Fully connected로 처리하는 대신 $1 \times 1$ Convolution을 쓰는 방법을 생각해 볼 수 있습니다. Convolution은 위치정보를 어느정도 보존할 수 있다는 점에서 착안한 아이디어인데, 이는 2016년에 &lt;strong&gt;Fully Convolutional Network (FCN)&lt;/strong&gt; 이라는 이름으로 발표되었습니다. 여기에 추가로 Conditional Random Field, Markov Random Field 등의 모델들을 적용하면 더 높은 정확도를 얻을 수 있다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/d945a1658b049113080a2dbfb06afd68ae4b46cb6059c4a462159cf9fafa4159.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNN에서는 Convolution과 함께 Pooling을 반복하기 때문에, 갈수록 feature map의 크기가 줄어들게 됩니다. 그런데 우리는 각 픽셀단위로 어떤 클래스인지를 찾아내는 것이 목표이기 때문에, 다시 feature map의 크기를 원본 이미지 크기만큼 키워야 합니다. 이를 위해 다양한 방법들이 있는데, FCN에서는 skip connection / upsampling 이라고 해서, 네트워크를 타고 흐르는 중간의 정보를 뽑아다가 최종 정보와 함께 사용하는 방식을 사용합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/0ba5dd41655ed3613a70807a6580e8dfe8ee2a0bea10f9684f934e5eecd4b4d3.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNN에서 사용하는 개념 중, feature map의 크기를 거꾸로 늘리게 되는 deconvolution이라는 연산이 있습니다 (convolution의 계산적인 inverse이긴 한데, 정확한 inverse는 아닙니다. transposed convolution이 좀더 정확한 말인데, 이 부분도 나중에 다루겠습니다). CNN을 타고 feature map의 개수가 줄어들었다는 것이 문제가 된다면, 다시 deconvolution을 그만큼 거꾸로 돌려서 feature map을 돌이켜주면 되지 않을까요? 이를 &lt;strong&gt;Encoder-Decoder&lt;/strong&gt; 형태의 구조라고 부르며, &lt;strong&gt;U-Net&lt;/strong&gt; 을 필두로 (이 이름은, 말그대로 convolution과 deconvolution을 U자형으로 쌓아서 붙여진 이름입니다) 여러 모델들이 성공적인 결과를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/becc0a664a9a998e0f9d78b27411a3bb3fa0ac435f41b799ce11600416e38e7f.png&quot; alt=&quot;picture 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Convolution에서 pooling을 통해 정보를 잃다가 다시 이걸 만들어주는 것 대신, 처음부터 feature map의 크기를 줄이지 않으면 어떨까요? 그렇다고 pooling을 아예 하지 않을 수는 없는데, 필터의 크기가 크면 연산이 너무 많아지는 데다가 learning capacity가 너무 커지는 현상들이 발생하기 때문입니다. 이런 문제를 어느정도 해결하는 Dilated convolution은 Convolution을 할 때부터 적당히 필터에 제로 패딩을 붙여줌으로써, 공간적인 정보를 잃지 않고 feature map의 크기를 유지해 줍니다. 이 연산을 이용하여 (원래의 upsampling과 함께 쓰긴 합니다) Dilated Convolutional Model 들이 개발되었는데, 대표적으로 Google의 &lt;strong&gt;DeepLab&lt;/strong&gt; 를 예시로 들 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/2e524914bd271cef4334b42466615f08a209df30df675c74151349d76ca87345.png&quot; alt=&quot;picture 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우선은 FCN, U-Net, DeepLab을 필두로 정리를 시작해 보려고 합니다.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents 문제 소개 활용 개요 이 글의 상당 부분은, 서베이 논문인 Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtarnavaz, N., &amp;amp; Terzopoulos, D. (2020). Image Segmentation Using Deep Learning: A Survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–22. https://doi.org/10.1109/TPAMI.2021.3059968 을 정리한 내용입니다. 문제 소개 Semantic Segmentation이란, Computer Vision 분야의 대표적인 task중 하나로, 간단히 요약하자면 이미지가 주어졌을 때, 그 이미지를 픽셀단위로 어떤 대상인지 를 분류해내는 문제입니다. 출처 : Stanford cs231n slides 이 사진은 대표적인 네 가지의 task를 비교한 것인데, 굉장히 직관적으로 무슨 의미인지 알 수 있습니다. 활용 Semantic segmentation은 딱 느낌에도 매우 유용할 것 같은데, 대표적인 활용처 몇개를 생각해보면… 자율 주행 : 자율주행에서 지금 눈앞에 보이는 것이 도로인지, 흙바닥인지, 물웅덩이인지를 판단하는 작업은 굉장히 중요합니다. 의료 이미지 : CT 사진에서, 각 고형장기를 분류한다거나, 정상조직과 비정상조직을 구분하는 작업도 결국은 segmentation에 기반합니다. 개요 여기서는 정말 대략적인 아이디어를 한줄로 정리하고, 개별 네트워크 구조에 대한 포스팅을 통해 전체 내용을 붙여나가려고 합니다. 이 이미지가 개인지, 고양이인지를 판단하는 Classification의 경우, 통상적으로 convolutional neural network (CNN) 에 기반한 방법들을 사용합니다. 사진 전체의 정보를 인코딩한 $3 \times W \times H$ 텐서를 가지고 시작해서, Convolution layer를 거치면서 정보들을 추출하고, 마지막에 fully connected layer를 붙여서 실제로 클래스를 구분해내는 식으로 진행하게 되는 것입니다. 이 방법을 semantic segmentation같은 문제에서 적용하기 어려운 이유는, 마지막 fully connected layer가 기하적인 위치정보를 다 날려버리기 때문입니다. 즉, ‘고양이가’ 있다는 정보는 어떻게 분류해볼 수 있을지라도, 고양이가 ‘어디에’ 있는지에 대해서는 전혀 알 수가 없게 됩니다. 그렇기 때문에 fully connected layer를 쓸 수 없습니다. 이를 개선하기 위해 나온 아이디어로, 마지막 정보를 Fully connected로 처리하는 대신 $1 \times 1$ Convolution을 쓰는 방법을 생각해 볼 수 있습니다. Convolution은 위치정보를 어느정도 보존할 수 있다는 점에서 착안한 아이디어인데, 이는 2016년에 Fully Convolutional Network (FCN) 이라는 이름으로 발표되었습니다. 여기에 추가로 Conditional Random Field, Markov Random Field 등의 모델들을 적용하면 더 높은 정확도를 얻을 수 있다고 합니다. CNN에서는 Convolution과 함께 Pooling을 반복하기 때문에, 갈수록 feature map의 크기가 줄어들게 됩니다. 그런데 우리는 각 픽셀단위로 어떤 클래스인지를 찾아내는 것이 목표이기 때문에, 다시 feature map의 크기를 원본 이미지 크기만큼 키워야 합니다. 이를 위해 다양한 방법들이 있는데, FCN에서는 skip connection / upsampling 이라고 해서, 네트워크를 타고 흐르는 중간의 정보를 뽑아다가 최종 정보와 함께 사용하는 방식을 사용합니다. CNN에서 사용하는 개념 중, feature map의 크기를 거꾸로 늘리게 되는 deconvolution이라는 연산이 있습니다 (convolution의 계산적인 inverse이긴 한데, 정확한 inverse는 아닙니다. transposed convolution이 좀더 정확한 말인데, 이 부분도 나중에 다루겠습니다). CNN을 타고 feature map의 개수가 줄어들었다는 것이 문제가 된다면, 다시 deconvolution을 그만큼 거꾸로 돌려서 feature map을 돌이켜주면 되지 않을까요? 이를 Encoder-Decoder 형태의 구조라고 부르며, U-Net 을 필두로 (이 이름은, 말그대로 convolution과 deconvolution을 U자형으로 쌓아서 붙여진 이름입니다) 여러 모델들이 성공적인 결과를 보여주었습니다. Convolution에서 pooling을 통해 정보를 잃다가 다시 이걸 만들어주는 것 대신, 처음부터 feature map의 크기를 줄이지 않으면 어떨까요? 그렇다고 pooling을 아예 하지 않을 수는 없는데, 필터의 크기가 크면 연산이 너무 많아지는 데다가 learning capacity가 너무 커지는 현상들이 발생하기 때문입니다. 이런 문제를 어느정도 해결하는 Dilated convolution은 Convolution을 할 때부터 적당히 필터에 제로 패딩을 붙여줌으로써, 공간적인 정보를 잃지 않고 feature map의 크기를 유지해 줍니다. 이 연산을 이용하여 (원래의 upsampling과 함께 쓰긴 합니다) Dilated Convolutional Model 들이 개발되었는데, 대표적으로 Google의 DeepLab 를 예시로 들 수 있습니다. 우선은 FCN, U-Net, DeepLab을 필두로 정리를 시작해 보려고 합니다.</summary></entry><entry><title type="html">[P] Stochastic Gradient Descent</title><link href="http://localhost:4000/deep-learning-study/sgd/" rel="alternate" type="text/html" title="[P] Stochastic Gradient Descent" /><published>2021-09-24T00:00:00+09:00</published><updated>2021-09-24T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/sgd</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/sgd/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot; id=&quot;markdown-toc-stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#batch-sgd--cyclic-sgd&quot; id=&quot;markdown-toc-batch-sgd--cyclic-sgd&quot;&gt;Batch SGD / Cyclic SGD&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sgd-convergence-theorem&quot; id=&quot;markdown-toc-sgd-convergence-theorem&quot;&gt;SGD Convergence Theorem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 2강 (9월 7일), 3강 (9월 9일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h2&gt;

&lt;p&gt;ML에는 많은 Finite sum optimization이 있다. 우리는
$F(x) = \frac{1}{N} \sum_{i = 1}^{N} f_i(x)$ 를 최적화하고 싶다.
대표적으로, Gradient Descent를 쓸 수 있다. But, $N$이 매우 크면 이
함수를 한번 계산하는 시간이 매우 오래 걸린다.&lt;/p&gt;

&lt;p&gt;위 식을, 이 함수의 &lt;strong&gt;기댓값&lt;/strong&gt; 으로 이해할 수 있다.
\(\underset{x \in \R^p}{\minimize}\ \E_I[f_I(x)], \ I \sim \uniform{1}{N}\)&lt;/p&gt;

&lt;p&gt;이런 motivation을 통해, Stochastic (Random) Gradient Descent를 생각한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm (Stochastic Gradient Descent)&lt;/strong&gt; &lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha_k &amp;gt; 0$ 에 대해
다음을 반복한다.
\(i(k) \sim \uniform{1}{N},\quad x^{k+1} = x^k - \alpha_k \nabla{f_{i(k)}(x^k)}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;대략의 아이디어&lt;/strong&gt; :&lt;br /&gt;
GD처럼, Taylor expansion하고 Stochastic을 고려하여 Expectation을 씌운다.&lt;/p&gt;

&lt;p&gt;$x^k$ 근처에서 $F(x) = \frac{1}{N} \sum_{i = 1}^{N} f_i(x)$를 테일러
전개하고 $x^{k+1}$ 대입하면,
\(F(x^{k+1}) = F(x^k) - \alpha_k \nabla F(x^k)^T \nabla f_{i(k)}(x^k) + \order{\alpha_k^2}\)
이제, 양쪽에 $\E$ 를 씌운다.
\(\expect{F(x^{k+1})} = \expect{F(x^k)} - \alpha_k \expect{\nabla F(x^k)^T \nabla f_{i(k)}(x^k)} + \order{\alpha_k^2}\)
$\nabla F(x^k)^T$ 는 기댓값에 영향이 없고, $\nabla f_{i(k)}(x^k)$ 의
기댓값은 $\nabla F(x^k)$ 이므로,
\(\expect{F(x^{k+1})} = \expect{F(x^k)} - \alpha_k \norm{\nabla F(x^k)}^2 + \order{\alpha_k^2}\)
적당히 $\alpha_k$를 충분히 작게 잡으면, 기댓값이 감소할 수 있을 것 같다.&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Stochastic Gradient Descent도 수렴성에 관한 정리를 기술할 수
있으나, 증명이 매우 Tedious하고 ML 세팅에서는 그렇게 중요하지 않다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;직접 구현해서 테스트해 보면, 초반에 SGD가 GD보다 수렴속도가 빠르지만,
Eventually GD에게 따라잡힌다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;그러나, 우리는 ML을 공부하는데 있어 SGD를 Subroutine으로 쓸 것이고, 짧은 Training 시간의 환경에서 SGD가 in practice GD보다 잘 수렴한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Stochastic Gradient Descent에서, $i(k)$ 자체의 성질은 전혀 활용하지 않았다.&lt;/li&gt;
  &lt;li&gt;실제로, SGD의 수렴성 증명에서 중요한 것은, 다음과 같은 Framework면 충분하기 때문.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Algorithm (Stochastic Gradient Descent)&lt;/strong&gt; &lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha_k &amp;gt; 0$ 에 대해
다음을 반복한다.
\(i(k) \sim \uniform{1}{N},\quad x^{k+1} = x^k - \alpha_k g^k\) 이때,
$g^k$ 는 Stochastic gradient로, $\nabla F(x^k)$ 의 Unbiased Estimator
이면 - 즉, 기댓값이 $\nabla F(x^k)$ 이면 충분하다.&lt;/p&gt;

&lt;h2 id=&quot;batch-sgd--cyclic-sgd&quot;&gt;Batch SGD / Cyclic SGD&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;예를 들어, $g^k$를 고르는 방법으로 Batch sampling with/without
Replacement를 생각할 수 있다.&lt;/li&gt;
  &lt;li&gt;즉, $N$개 중 일부인 $B$개를 랜덤하게 계속
뽑아서, $\frac{1}{B}\sum_{b = 1}^{B} \nabla f_{i(k, b)}(x^k)$, 즉
$B$개의 batch에 대한 gradient의 평균을 쓰는 것.&lt;/li&gt;
  &lt;li&gt;이때, Batch를 뽑을 때
중복을 허용하는지 여부는 상관 없다 (둘 다 Unbiased estimator가 되기
때문). 중복을 허용하고 싶으면 random한 $B$개를 뽑고, 허용하고 싶지
않으면 random permutation의 첫 $B$개를 쓰면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;특히, Batch 방법의 경우, GPU를 이용한 Parallel 연산에 유리하다는
추가적인 장점이 있다. GPU와 병렬처리를 최대한 활용하기 위해, GPU
memory에 들어가는 최대 $B$를 이용하는 것이 가장 유리하다. Batch size는
noise 정도에 따라 성능이 달라지는데, noise가 클수록 large batch가
유리하다.&lt;/p&gt;

&lt;p&gt;그런데…이 알고리즘에서, 원래 랜덤하지 않은 것을 억지로 랜덤하게 만들어서 풀고 있는 것 아닌가? Stochastic하게 뽑는 대신, 그냥 순서대로 돌리면서 쓰면 안 되나?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm : Cyclic SGD&lt;/strong&gt;&lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha &amp;gt; 0$ 에 대해 다음을 반복한다.
\(x^{k+1} = x^k - \alpha_k \nabla{f_{(k \text{ mod } N + 1)}(x^k)}\)&lt;/p&gt;

&lt;p&gt;이 방법은 stochastic한 부분이 사실 없다. 장단점은...&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(+)&lt;/code&gt; 확실하게 $N$개의 데이터를 $N$번마다 한번씩 정확하게 사용한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-)&lt;/code&gt; SGD의 수렴성에 대한 정리를 쓸 수 없다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-)&lt;/code&gt; 일반 SGD에 비해 Theoretically / Empirically, some case에서는 잘 작동하지 않음.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-)&lt;/code&gt; Deep Learning으로 가면, Neural network가 이 순서(cyclic order)를 기억하는 경향 발생.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;특히 기억하는 경향에 의한 overfitting이 큰 이슈이기 때문에, 이를
방지해야 한다. 적당히 섞어주면 어떨까?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm : Shuffled Cyclic SGD&lt;/strong&gt;&lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha &amp;gt; 0$ 에 대해 다음을
반복한다.
\(x^{k+1} = x^k - \alpha \nabla{f_{\sigma^{(k/N)}(k \text{ mod } N + 1)}(x^k)}\)&lt;/p&gt;

&lt;p&gt;즉, $N$번에 한 번씩, 인덱스들을 랜덤하게 permutation해버린 다음, 그
순서로 다음 $N$번의 iteration을 Cyclic하게 돌린다. 이렇게 하면, 정확하게
$N$개의 데이터를 한번씩 쓴다는 장점을 챙기면서도, neural network가
학습하는 일을 막을 수 있다. 기존에는 강한 theory가 별로 없었지만, recent
breakthrough들이 이를 개선하고 있다.&lt;/p&gt;

&lt;p&gt;그냥 일반적인 세팅에서는, &lt;strong&gt;Shuffled cyclic minibatch SGD without
replacement&lt;/strong&gt; 를 쓰면 되고, &lt;strong&gt;GPU가 허락하는 최대한 큰 Batch size&lt;/strong&gt;를
잡으면 된다. Deep Learning의 많은 경우, 수학적인 분석이 실제
performance를 정확하게 예측하지 못하는 경향이 있는데, empirically this
is best.&lt;/p&gt;

&lt;p&gt;일반적인 expectation으로 표현된 최적화 문제, 예를 들어 확률변수
$\omega$에 대해 이런 문제들
\(\underset{x \in \R^p}{\minimize}\ \E_\omega[f_\omega(x)]\) 의 경우,
똑같이 SGD로 풀 수 있다. GD로도 할 수는 있지만,
일반적으로 ‘gradient의 기댓값’ 을 구하기가 어렵기 때문에...&lt;/p&gt;

&lt;p&gt;참고 : Optimization / ML에서, 대충 ‘한바퀴’ 를 &lt;strong&gt;Epoch&lt;/strong&gt; 라고 부른다. 대충
데이터들을 한바퀴 돌면 된다. Gradient descent면 한번 = 1 epoch, SGD면
$N$번, Batched SGD면 $N / B$ 번 정도.&lt;/p&gt;

&lt;h2 id=&quot;sgd-convergence-theorem&quot;&gt;SGD Convergence Theorem&lt;/h2&gt;

&lt;p&gt;상세하게 다루어야 할 내용은 아니지만, 앞서 공부한 Lipschitz Gradient Lemma 등을 이용해서 비슷한 증명을 쓸 수 있다.&lt;/p&gt;

&lt;p&gt;$F : \R^n \to \R$ 이 미분가능하고, $\nabla F$ 가 $L$-Lipschitz 연속이며,
$F$가 $-\infty$가 아닌 최소값을 가지며, $g^k$가 다음 조건
\(\E[g^k \di x^k] = \nabla F(x^k), \quad \quad \expect{\norm{g^k - \nabla F(x^k)}^2 \di x^k} \leq \sigma^2\)
을 만족할 때, 즉 $g^k$ 가 Gradient에 대한 Unbiased estimator이고 그
분산이 $\sigma^2$ 이하일 때, 다음이 성립한다.
\(\frac{1}{M}\sum_{k = 0}^{M-1} \expect{\norm{\nabla F(x^k)}^2} \leq \frac{1}{\sqrt{M}}\left(2L(F(x^0) - F^*) + \sigma^2\right)\)&lt;/p&gt;

&lt;p&gt;즉, Gradient의 크기의 평균이 $M$번의 iteration에 의해
$\order{\frac{1}{\sqrt{M}}}$로 감소한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Proof.&lt;/em&gt;&lt;/strong&gt; 먼저, Lipschitz Gradient Lemma를
$x = x^k, \delta = -\alpha g^k$에 대해 쓰면,
\(F(x^{k+1}) \leq F(x^k) -\alpha \nabla F(x^k)^T g^k + \frac{\alpha^2L}{2}\norm{g^k}^2\)
$x^k$ 가 이미 주어졌을 때의 Conditional expectation을 쓴다.
\(\expect{F(x^{k+1}) \di x^k} \leq F(x^k) - \alpha \norm{\nabla F(x^k)}^2 + \frac{\alpha^2 L}{2}\left(\norm{\nabla F(x^k)}^2 + \sigma^2\right)\)
이제 이를 다시 Total expectation을 취하면,
\(\expect{F(x^{k+1})} \leq \expect{F(x^k)} - \alpha\left(1 - \frac{\alpha L}{2}\right) \expect{\nabla F(x^k)} + \frac{\alpha^2 \sigma^2 L}{2}\)
이를 $k = 0 \dots M-1$에 대해 양변을 더하여
\(\alpha\left(1 - \frac{\alpha L}{2}\right) \sum_{k = 1}^{M-1}\expect{\nabla F(x^k)} \leq (F(x^0) - F^*) + \expect{F(x^k) - F^*} + \frac{\alpha^2 \sigma^2 L}{2}\)
마지막으로, $\alpha = \frac{1}{L \sqrt{K}}$ 를 취하여 주어진 식을
얻는다. ◻&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">[P] Shallow Neural Networks - Introduction</title><link href="http://localhost:4000/deep-learning-study/shallow-nn/" rel="alternate" type="text/html" title="[P] Shallow Neural Networks - Introduction" /><published>2021-09-24T00:00:00+09:00</published><updated>2021-09-24T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/shallow-nn</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/shallow-nn/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#shallow-neural-network--introduction&quot; id=&quot;markdown-toc-shallow-neural-network--introduction&quot;&gt;Shallow Neural Network : Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kl-divergence&quot; id=&quot;markdown-toc-kl-divergence&quot;&gt;KL-Divergence&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;shallow-neural-network--introduction&quot;&gt;Shallow Neural Network : Introduction&lt;/h2&gt;

&lt;p&gt;데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨
$Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤
&lt;strong&gt;True Unknown Function&lt;/strong&gt; $f_\star : \mathcal{X} \to \mathcal{Y}$ 가
있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다.&lt;/p&gt;

&lt;p&gt;우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는
작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기
때문에, 이를 &lt;strong&gt;Supervised Learning&lt;/strong&gt;이라고 부른다.&lt;/p&gt;

&lt;p&gt;뭔가를 시작하기 전에, 일단 $f_\star$과 가까운 $f$가 도대체 무슨 말인지를
명확히 해야 한다. 뭔가를 최소화하는 문제로 만들고 싶은데... 가장 자명한
방법으로 생각하면 어떤 손실함수 $\ell$을 도입해서, 이렇게 쓰고 싶다.
\(\underset{f \in \mathcal{F}}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f(x), f_\star(x))\)
이 문제는, (1) 모든 가능한 함수들의 공간 위에서 뭔가를 최적화한다는 것은
알고리즘적으로 말이 안 되고, (2) 이 최적화 문제의 해는 $f_\star$이니까,
사실 최적화 문제도 딱히 아니다. 모든 $x$에 대해 $f_\star$를 알고 있으면
최적화를 생각할 이유가 없다.&lt;/p&gt;

&lt;p&gt;대신에, 함수들의 공간을 제약하자. 어떤 파라미터 $\theta$를 이용하여,
우리는 다음과 같은 최적화 문제로 바꾸고 싶다.
\(\underset{\theta \in \Theta}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f_\theta(x), f_\star(x))\)&lt;/p&gt;

&lt;p&gt;여전히, 일단 우리는 모든 $x$에 대해 $f_\star$를 알고 있지 않다. 우리가
알고 있는 $x_1, x_2, \dots$ 에 대한 답 $y_1, y_2 \dots$ 들을 맞춰낼 수
있는 함수를 일단 만드는 정도가 최선이 아닐까? 그리고, 최악의 경우를
최소화하는 대신, 평균을 최적화하는게 뭔가 ‘일반적으로’ 좋은 솔루션을
제공할 것 같다. supremum을 최소화한다는 것은 너무 지나친 목표이다.
\(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\)
우리는 $f_\star(x_i) = y_i$ 임을 알고 있으므로, 이제 뭔가가 가능하다.&lt;/p&gt;

&lt;p&gt;이제, $\theta$를 이용하여 표현되는 $f_\theta$를 &lt;strong&gt;model&lt;/strong&gt; 또는 &lt;strong&gt;neural
network&lt;/strong&gt;라고 부를 것이다. 또한, 이 최적화 문제를 푸는 작업을
&lt;strong&gt;training&lt;/strong&gt; 이라고 부를 것이다. 즉, 파라미터를 이용해서 표현한 모델
$f_\theta$를 SGD와 같은 알고리즘을 이용하여 training한다는 표현이 된다.
현재 거의 모든 방법들이 SGD에 기반하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example : Least square regression&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$\mathcal{X} = \R^p, \mathcal{Y} = \R, \Theta = \R^p$이고, 모델
$f_\theta(x) = x^T \theta$, $L(y_1, y_2) = \frac{1}{2}(y_1 - y_2)^2$ 인
문제를 Least square라고 부른다. 즉, 주어진 데이터들을 비슷하게 맞춰내는
Linear한 함수를 찍는 것.&lt;/p&gt;

&lt;h2 id=&quot;kl-divergence&quot;&gt;KL-Divergence&lt;/h2&gt;

&lt;p&gt;As a mathematical tool, 어떤 $p, q \in \R^n$이 probability mass vector일
때, 즉 $p_i, q_i \geq 0$ 이고 $\sum p_i = \sum q_i = 1$일 때, 우리는 두
distribution의 차이를 생각하고 싶다.&lt;/p&gt;

&lt;p&gt;Kullback-Leibler Divergence (KL-Divergence)를 다음과 같이 정의한다.
\(\DKL{p}{q} = \sum_{i = 1}^{n} p_i \log\frac{p_i}{q_i} = -\sum_{i = 1}^{n} p_i \log q_i + \sum_{i = 1}^{n} p_i \log p_i\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이는 다시, 정보이론의 용어로는 Cross entropy $H(p, q)$ 와 Entropy
$H(p)$의 합으로 쓰여진다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;편의를 위해 (자연스럽게), $0 \log (0 / 0) = 0$ 으로, $0 \log 0 = 0$
으로, $x &amp;gt; 0$이면 $x \log (x / 0) = \infty$ 으로 둔다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;몇가지 성질들을 살펴보면...&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\DKL{p}{q}$ 는 일반적으로 $\DKL{q}{p}$ 와 같지 않다. (그래서
  metric은 아님)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\DKL{p}{q} \geq 0$ 이고, $p \neq q$ 이면 $\DKL{p}{q} &amp;gt; 0$ (과제)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;$\DKL{p}{q} = \infty$ 인 경우도 가능.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;KL-Divergence를 확률론의 notation으로 쓰면, random variable $I$가
$p_i$의 확률분포를 가질 때,
\(\DKL{p}{q} = \expectwith{I}{\log\left(\frac{p_i}{q_i}\right)}\) 이렇게
expectation으로 쓸 수도 있다.&lt;/p&gt;

&lt;p&gt;Symmetrized version $(\DKL{p}{q} + \DKL{q}{p}) / 2$ 같은 것을 생각하면?&lt;br /&gt;
$\Rightarrow$ Jensen-Shannon Divergence라고 부르는데, 그래도 여전히
infinity라는 문제가 남아서 메트릭이 되지는 않는다.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Shallow Neural Network : Introduction KL-Divergence 심층 신경망의 수학적 기초 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다. 이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다. Shallow Neural Network : Introduction 데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨 $Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤 True Unknown Function $f_\star : \mathcal{X} \to \mathcal{Y}$ 가 있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다. 우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는 작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기 때문에, 이를 Supervised Learning이라고 부른다. 뭔가를 시작하기 전에, 일단 $f_\star$과 가까운 $f$가 도대체 무슨 말인지를 명확히 해야 한다. 뭔가를 최소화하는 문제로 만들고 싶은데... 가장 자명한 방법으로 생각하면 어떤 손실함수 $\ell$을 도입해서, 이렇게 쓰고 싶다. \(\underset{f \in \mathcal{F}}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f(x), f_\star(x))\) 이 문제는, (1) 모든 가능한 함수들의 공간 위에서 뭔가를 최적화한다는 것은 알고리즘적으로 말이 안 되고, (2) 이 최적화 문제의 해는 $f_\star$이니까, 사실 최적화 문제도 딱히 아니다. 모든 $x$에 대해 $f_\star$를 알고 있으면 최적화를 생각할 이유가 없다. 대신에, 함수들의 공간을 제약하자. 어떤 파라미터 $\theta$를 이용하여, 우리는 다음과 같은 최적화 문제로 바꾸고 싶다. \(\underset{\theta \in \Theta}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f_\theta(x), f_\star(x))\) 여전히, 일단 우리는 모든 $x$에 대해 $f_\star$를 알고 있지 않다. 우리가 알고 있는 $x_1, x_2, \dots$ 에 대한 답 $y_1, y_2 \dots$ 들을 맞춰낼 수 있는 함수를 일단 만드는 정도가 최선이 아닐까? 그리고, 최악의 경우를 최소화하는 대신, 평균을 최적화하는게 뭔가 ‘일반적으로’ 좋은 솔루션을 제공할 것 같다. supremum을 최소화한다는 것은 너무 지나친 목표이다. \(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\) 우리는 $f_\star(x_i) = y_i$ 임을 알고 있으므로, 이제 뭔가가 가능하다. 이제, $\theta$를 이용하여 표현되는 $f_\theta$를 model 또는 neural network라고 부를 것이다. 또한, 이 최적화 문제를 푸는 작업을 training 이라고 부를 것이다. 즉, 파라미터를 이용해서 표현한 모델 $f_\theta$를 SGD와 같은 알고리즘을 이용하여 training한다는 표현이 된다. 현재 거의 모든 방법들이 SGD에 기반하고 있다. Example : Least square regression $\mathcal{X} = \R^p, \mathcal{Y} = \R, \Theta = \R^p$이고, 모델 $f_\theta(x) = x^T \theta$, $L(y_1, y_2) = \frac{1}{2}(y_1 - y_2)^2$ 인 문제를 Least square라고 부른다. 즉, 주어진 데이터들을 비슷하게 맞춰내는 Linear한 함수를 찍는 것. KL-Divergence As a mathematical tool, 어떤 $p, q \in \R^n$이 probability mass vector일 때, 즉 $p_i, q_i \geq 0$ 이고 $\sum p_i = \sum q_i = 1$일 때, 우리는 두 distribution의 차이를 생각하고 싶다. Kullback-Leibler Divergence (KL-Divergence)를 다음과 같이 정의한다. \(\DKL{p}{q} = \sum_{i = 1}^{n} p_i \log\frac{p_i}{q_i} = -\sum_{i = 1}^{n} p_i \log q_i + \sum_{i = 1}^{n} p_i \log p_i\) 이는 다시, 정보이론의 용어로는 Cross entropy $H(p, q)$ 와 Entropy $H(p)$의 합으로 쓰여진다. 편의를 위해 (자연스럽게), $0 \log (0 / 0) = 0$ 으로, $0 \log 0 = 0$ 으로, $x &amp;gt; 0$이면 $x \log (x / 0) = \infty$ 으로 둔다. 몇가지 성질들을 살펴보면... $\DKL{p}{q}$ 는 일반적으로 $\DKL{q}{p}$ 와 같지 않다. (그래서 metric은 아님) $\DKL{p}{q} \geq 0$ 이고, $p \neq q$ 이면 $\DKL{p}{q} &amp;gt; 0$ (과제) $\DKL{p}{q} = \infty$ 인 경우도 가능. KL-Divergence를 확률론의 notation으로 쓰면, random variable $I$가 $p_i$의 확률분포를 가질 때, \(\DKL{p}{q} = \expectwith{I}{\log\left(\frac{p_i}{q_i}\right)}\) 이렇게 expectation으로 쓸 수도 있다. Symmetrized version $(\DKL{p}{q} + \DKL{q}{p}) / 2$ 같은 것을 생각하면? $\Rightarrow$ Jensen-Shannon Divergence라고 부르는데, 그래도 여전히 infinity라는 문제가 남아서 메트릭이 되지는 않는다.</summary></entry><entry><title type="html">[P] Binary Classification : Support Vector Machine / Logistic Regression</title><link href="http://localhost:4000/deep-learning-study/svm-and-lr/" rel="alternate" type="text/html" title="[P] Binary Classification : Support Vector Machine / Logistic Regression" /><published>2021-09-24T00:00:00+09:00</published><updated>2021-09-24T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/svm-and-lr</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/svm-and-lr/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#binary-classification&quot; id=&quot;markdown-toc-binary-classification&quot;&gt;Binary Classification&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#linear-classification&quot; id=&quot;markdown-toc-linear-classification&quot;&gt;Linear Classification&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#support-vector-machine&quot; id=&quot;markdown-toc-support-vector-machine&quot;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#logistic-regression&quot; id=&quot;markdown-toc-logistic-regression&quot;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;binary-classification&quot;&gt;Binary Classification&lt;/h2&gt;

&lt;p&gt;잠시 앞서의 정의를 돌아보자.&lt;/p&gt;

&lt;p&gt;데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨
$Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤
&lt;strong&gt;True Unknown Function&lt;/strong&gt; $f_\star : \mathcal{X} \to \mathcal{Y}$ 가
있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다.&lt;/p&gt;

&lt;p&gt;우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는
작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기
때문에, 이를 &lt;strong&gt;Supervised Learning&lt;/strong&gt;이라고 부른다.&lt;/p&gt;

&lt;p&gt;Supervised Learning을 위해, 우리는 다음과 같은 최적화 문제를 생각할 것이다.
\(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\)&lt;/p&gt;

&lt;p&gt;특히, 이번에는 $\mathcal{X} = \R^p$, $\mathcal{Y} = \Set{-1, +1}$ 인 문제를 생각하자.
즉, 데이터를 두 클래스로 분리해내는 것이다. 이때, 특별히 이 데이터가
&lt;strong&gt;linearly seperable&lt;/strong&gt;한지를 생각한다. 어떤 초평면 $a^T x + b$ 가
존재하여, $y$값을 $a^T x + b$의 부호에 따라 찍어낼 수 있으면 linearly
seperable하다고 정의한다.&lt;/p&gt;

&lt;h2 id=&quot;linear-classification&quot;&gt;Linear Classification&lt;/h2&gt;

&lt;p&gt;Binary classifcation, 특히 linear classifcation 문제를 해결하기 위해
다음과 같은 affine model을 생각한다. \(f_{a, b}(x) = \sgn(a^T x + b)\)
여기에 loss function으로, 틀린 라벨의 개수를 세는 것이 매우 자연스럽다.
이렇게 컴팩트하게 쓸 수 있다.
\(\ell(y_1, y_2) = \frac{1}{2}\abs{1 - y_1 y_2}\)&lt;/p&gt;

&lt;p&gt;이제, 다음의 최적화 문제를 풀고 싶다.
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_{a, b}(x_i), y_i)\)
그러면 Linearly seperable한지는 이 최적화 문제의 최적해가 0인지와
동치이다. 그런데, 이 함수는 연속함수가 아니기 때문에 (정확히는 대충
미분가능하다는 조건을 요구한다) SGD같은 알고리즘을 돌릴수가 없다.&lt;/p&gt;

&lt;h2 id=&quot;support-vector-machine&quot;&gt;Support Vector Machine&lt;/h2&gt;

&lt;p&gt;따라서, 이 문제를 continuous하게 relaxation하고자 한다. 관점을 바꾸면,
이 라벨이 1일 / -1일 ‘Confidence’를 반환하도록 모델을 좀 잘 확장하고자
한다. 0.5이면 ‘아마도 1일 것으로 보인다’ 같은 느낌으로.&lt;/p&gt;

&lt;p&gt;이를 위해서는 $y_i f_{a, b}(x_i) &amp;gt; 0$ 을 만족해야 한다.&lt;/p&gt;

&lt;p&gt;그런데, 실제로는 이렇게 하면 $f$값이 0 근처에서만 왔다갔다하는 문제가 있고, 이는 numerical한 면에서나 neural network의 confidence라는 해석으로나 적절하지 않으므로 적당히
margin을 주는 것이 바람직하다.&lt;/p&gt;

&lt;p&gt;적당히 margin을 1만큼 줘서, $y_i f_{a, b}(x_i) \geq 1$ 을 만족하면
좋을 것 같다. 여기서 ‘좋을 것 같다’ 는 말은 반대로 저 성질을 만족하지
않으면 페널티를 부과하겠다는 발상으로도 해석될 수 있고… 이 페널티 함수를 최소화하는 문제로 쓰면,
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i f_{a, b}(x_i)) = \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b))\)&lt;/p&gt;

&lt;p&gt;데이터가 linearly seperable하면, 이 식도 optimal value가 0임을 알 수
있다. 이 방법을 &lt;strong&gt;Support Vector Machine&lt;/strong&gt; 이라고 부르며, 흔히
regularizer를 추가한 아래 식으로
쓴다.\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b)) + \frac{\lambda}{2}\norm{a}^2\)&lt;/p&gt;

&lt;p&gt;이 최적화 문제 (Relaxation 넣기 전!)가 원본 문제의 relaxation이라는
사실을 보이는 것은 어렵지 않다. 원래 문제의 최적해를 $p_1^\star$ 라 하고,
SVM의 최적해를 $p_2^\star$ 라 하면, $p_1^\star = 0 \iff p_2^\star = 0$ 임을 알 수
있다.&lt;/p&gt;

&lt;p&gt;결국, relaxed supervised learning은 point prediction을 relaxation 해서
label value 대신 그 label의 probability를 예측하는 방향으로 생각하는 것.
Single prediction보다 훨씬 realistic한 세팅으로 생각할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h2&gt;

&lt;p&gt;Linear binary classification에 대한 또다른 방법. 여전히 Decision
boundary $a^T x + b$ 를 알고자 한다. 먼저...&lt;/p&gt;

&lt;p&gt;Binary classification에서, 우리가 확인한 데이터의 Label을 확률벡터로
만들어서 (만약 완전히 label이 하나라면, (1, 0) 과 (0, 1) 처럼) 표현한
것을 empirical distribution $\mathcal{P}(y)$ 라고 정의하기로 한다.&lt;/p&gt;

&lt;p&gt;다음과 같은 모델을 이용하여 최적화하는 supervised learning을 Logistic
Regression이라 한다. \(f_{a, b}(x) = \begin{bmatrix}
    \frac{1}{1 + e^{a^T x + b}} \\
    \frac{1}{1 + e^{-(a^Tx + b)}}
\end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;이 모델을 이용하여, 다음과 같은 최적화 문제를 해결하고자 한다.
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \sum_{i = 1}^{N} \DKL{\mathcal{P}(Y_i)}{f_{a, b}(X_i)}\)
즉, 우리는 empirical distribution과의 KL-Divergence를 최소화하고 싶다.
이 식을 정리하면...
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \sum_{i = 1}^{N} H(\mathcal{P}(Y_i), f_{a, b}(X_i)) + \text{ Terms independent of } a, b\)
정확히 Cross entropy $H$를 전개하고, 오른쪽 term들을 다 버리면...
\(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \P(y_i = -1) \log\left(\frac{1}{1 + e^{a^Tx_i + b}}\right) + \P(y_i = 1)\log\left(\frac{1}{1 + e^{-a^Tx_i - b}}\right)\)
이는 다시, $\P(y_i = 1)$ 과 $\P(y_i = -1)$ 이 one-hot이므로, 둘중에
어느쪽이 1인지를 깔끔하게 정리하여,
\(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \log\left(\frac{1}{1 + e^{-y_i(a^Tx_i + b)}}\right)\)
단조감소함수인 Loss function $\ell(z) = \log(1 + e^{-z})$를 도입하여
부호를 떼고 깔끔하게 정리할 수 있다.
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N}\ell(y_i(a^T x_i + b))\)
이 문제를 해결한 후, $a^T x + b$ 의 부호에 따라 prediction한다.&lt;/p&gt;

&lt;p&gt;SVM과 비교하면, 출발점이 달랐지만 결국은 같은 문제가 되는데, $\ell(z)$
를 어떻게 정의하느냐의 문제가 된다. SVM은 $\max(0, 1-z)$이고, Logistic
regression은 $\log(1 + e^{-z})$ 를 쓰는 경우로 생각할 수 있다. 좌표에
그려보면 두 함수가 사실 굉장히 비슷하게 생겼다.&lt;/p&gt;

&lt;p&gt;SVM과 LR은 둘다 (Decision boundary가 hyperplane이라는 관점에서) Linear
classifier이지만, LR이 좀더 자연스럽게 multiclass classification으로
확장된다. (Softmax Regression)&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Binary Classification Linear Classification Support Vector Machine Logistic Regression 심층 신경망의 수학적 기초 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다. 이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다. Binary Classification 잠시 앞서의 정의를 돌아보자. 데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨 $Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤 True Unknown Function $f_\star : \mathcal{X} \to \mathcal{Y}$ 가 있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다. 우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는 작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기 때문에, 이를 Supervised Learning이라고 부른다. Supervised Learning을 위해, 우리는 다음과 같은 최적화 문제를 생각할 것이다. \(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\) 특히, 이번에는 $\mathcal{X} = \R^p$, $\mathcal{Y} = \Set{-1, +1}$ 인 문제를 생각하자. 즉, 데이터를 두 클래스로 분리해내는 것이다. 이때, 특별히 이 데이터가 linearly seperable한지를 생각한다. 어떤 초평면 $a^T x + b$ 가 존재하여, $y$값을 $a^T x + b$의 부호에 따라 찍어낼 수 있으면 linearly seperable하다고 정의한다. Linear Classification Binary classifcation, 특히 linear classifcation 문제를 해결하기 위해 다음과 같은 affine model을 생각한다. \(f_{a, b}(x) = \sgn(a^T x + b)\) 여기에 loss function으로, 틀린 라벨의 개수를 세는 것이 매우 자연스럽다. 이렇게 컴팩트하게 쓸 수 있다. \(\ell(y_1, y_2) = \frac{1}{2}\abs{1 - y_1 y_2}\) 이제, 다음의 최적화 문제를 풀고 싶다. \(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_{a, b}(x_i), y_i)\) 그러면 Linearly seperable한지는 이 최적화 문제의 최적해가 0인지와 동치이다. 그런데, 이 함수는 연속함수가 아니기 때문에 (정확히는 대충 미분가능하다는 조건을 요구한다) SGD같은 알고리즘을 돌릴수가 없다. Support Vector Machine 따라서, 이 문제를 continuous하게 relaxation하고자 한다. 관점을 바꾸면, 이 라벨이 1일 / -1일 ‘Confidence’를 반환하도록 모델을 좀 잘 확장하고자 한다. 0.5이면 ‘아마도 1일 것으로 보인다’ 같은 느낌으로. 이를 위해서는 $y_i f_{a, b}(x_i) &amp;gt; 0$ 을 만족해야 한다. 그런데, 실제로는 이렇게 하면 $f$값이 0 근처에서만 왔다갔다하는 문제가 있고, 이는 numerical한 면에서나 neural network의 confidence라는 해석으로나 적절하지 않으므로 적당히 margin을 주는 것이 바람직하다. 적당히 margin을 1만큼 줘서, $y_i f_{a, b}(x_i) \geq 1$ 을 만족하면 좋을 것 같다. 여기서 ‘좋을 것 같다’ 는 말은 반대로 저 성질을 만족하지 않으면 페널티를 부과하겠다는 발상으로도 해석될 수 있고… 이 페널티 함수를 최소화하는 문제로 쓰면, \(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i f_{a, b}(x_i)) = \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b))\) 데이터가 linearly seperable하면, 이 식도 optimal value가 0임을 알 수 있다. 이 방법을 Support Vector Machine 이라고 부르며, 흔히 regularizer를 추가한 아래 식으로 쓴다.\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b)) + \frac{\lambda}{2}\norm{a}^2\) 이 최적화 문제 (Relaxation 넣기 전!)가 원본 문제의 relaxation이라는 사실을 보이는 것은 어렵지 않다. 원래 문제의 최적해를 $p_1^\star$ 라 하고, SVM의 최적해를 $p_2^\star$ 라 하면, $p_1^\star = 0 \iff p_2^\star = 0$ 임을 알 수 있다. 결국, relaxed supervised learning은 point prediction을 relaxation 해서 label value 대신 그 label의 probability를 예측하는 방향으로 생각하는 것. Single prediction보다 훨씬 realistic한 세팅으로 생각할 수 있다. Logistic Regression Linear binary classification에 대한 또다른 방법. 여전히 Decision boundary $a^T x + b$ 를 알고자 한다. 먼저... Binary classification에서, 우리가 확인한 데이터의 Label을 확률벡터로 만들어서 (만약 완전히 label이 하나라면, (1, 0) 과 (0, 1) 처럼) 표현한 것을 empirical distribution $\mathcal{P}(y)$ 라고 정의하기로 한다. 다음과 같은 모델을 이용하여 최적화하는 supervised learning을 Logistic Regression이라 한다. \(f_{a, b}(x) = \begin{bmatrix} \frac{1}{1 + e^{a^T x + b}} \\ \frac{1}{1 + e^{-(a^Tx + b)}} \end{bmatrix}\) 이 모델을 이용하여, 다음과 같은 최적화 문제를 해결하고자 한다. \(\underset{a \in \R^p, b \in \R}{\minimize}\ \sum_{i = 1}^{N} \DKL{\mathcal{P}(Y_i)}{f_{a, b}(X_i)}\) 즉, 우리는 empirical distribution과의 KL-Divergence를 최소화하고 싶다. 이 식을 정리하면... \(\underset{a \in \R^p, b \in \R}{\minimize}\ \sum_{i = 1}^{N} H(\mathcal{P}(Y_i), f_{a, b}(X_i)) + \text{ Terms independent of } a, b\) 정확히 Cross entropy $H$를 전개하고, 오른쪽 term들을 다 버리면... \(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \P(y_i = -1) \log\left(\frac{1}{1 + e^{a^Tx_i + b}}\right) + \P(y_i = 1)\log\left(\frac{1}{1 + e^{-a^Tx_i - b}}\right)\) 이는 다시, $\P(y_i = 1)$ 과 $\P(y_i = -1)$ 이 one-hot이므로, 둘중에 어느쪽이 1인지를 깔끔하게 정리하여, \(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \log\left(\frac{1}{1 + e^{-y_i(a^Tx_i + b)}}\right)\) 단조감소함수인 Loss function $\ell(z) = \log(1 + e^{-z})$를 도입하여 부호를 떼고 깔끔하게 정리할 수 있다. \(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N}\ell(y_i(a^T x_i + b))\) 이 문제를 해결한 후, $a^T x + b$ 의 부호에 따라 prediction한다. SVM과 비교하면, 출발점이 달랐지만 결국은 같은 문제가 되는데, $\ell(z)$ 를 어떻게 정의하느냐의 문제가 된다. SVM은 $\max(0, 1-z)$이고, Logistic regression은 $\log(1 + e^{-z})$ 를 쓰는 경우로 생각할 수 있다. 좌표에 그려보면 두 함수가 사실 굉장히 비슷하게 생겼다. SVM과 LR은 둘다 (Decision boundary가 hyperplane이라는 관점에서) Linear classifier이지만, LR이 좀더 자연스럽게 multiclass classification으로 확장된다. (Softmax Regression)</summary></entry></feed>