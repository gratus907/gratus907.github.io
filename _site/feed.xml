<<<<<<< Updated upstream
<<<<<<< Updated upstream
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-17T14:30:09+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
=======
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-18T14:09:35+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
>>>>>>> Stashed changes
</subtitle><entry><title type="html">Autodiff/Backpropagation</title><link href="http://localhost:4000/deep-learning-study/backpropagation/" rel="alternate" type="text/html" title="Autodiff/Backpropagation" /><published>2021-11-16T00:00:00+09:00</published><updated>2021-11-16T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/backpropagation</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/backpropagation/">&lt;div id=&quot;toc&quot;&gt;
=======
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-19T18:53:13+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Portfolio / Study note by Wonseok Shin (Gratus907), SNU CSE
</subtitle><entry><title type="html">BOJ 17532, ICPC Brazil Subregional 2019D Denouncing Mafia</title><link href="http://localhost:4000/problem-solving/BOJ-17532/" rel="alternate" type="text/html" title="BOJ 17532, ICPC Brazil Subregional 2019D Denouncing Mafia" /><published>2021-11-19T00:00:00+09:00</published><updated>2021-11-19T00:00:00+09:00</updated><id>http://localhost:4000/problem-solving/BOJ-17532</id><content type="html" xml:base="http://localhost:4000/problem-solving/BOJ-17532/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#풀이&quot; id=&quot;markdown-toc-풀이&quot;&gt;풀이&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#구현&quot; id=&quot;markdown-toc-구현&quot;&gt;구현&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/17532&quot;&gt;문제 링크&lt;/a&gt;&lt;br /&gt;
난이도 : solved.ac 기준 Platinum 4.&lt;/p&gt;

&lt;h2 id=&quot;풀이&quot;&gt;풀이&lt;/h2&gt;
&lt;p&gt;결국 주어진 문제는, 어떤 트리가 주어질 때, 트리에서 최대 $K$개의 path를 택하여 그 path들의 union을 최대화하는 문제입니다.&lt;/p&gt;

&lt;p&gt;문제의 특성 상, 트리 DP를 먼저 생각해 볼 수 있습니다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dp[i][j]&lt;/code&gt; : $i$번째 노드를 루트로 하는 subtree에 대해, $j$개의 path를 택했을 때의 최댓값&lt;/p&gt;

&lt;p&gt;이 DP를 계산하는 방법을 생각해 봅시다. 만약 내 child node에 대해 모든 dp값을 알고 있다면, 내 child node 들에 대해 각 노드당 몇개의 chain을 사용할지를 정해야 합니다. 이는 굳이 열심히 복잡도를 계산해 보지 않더라도, 적어도 $O(NK)$ 칸의 DP를 모두 채워야 하기 때문에 전혀 답이 없습니다. 예를 들어 3개의 자식노드를 가진 노드에 대해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dp[i][5]&lt;/code&gt;를 계산하려면, 5를 3개로 분할하는 모든 경우에 대해 각각 dp값을 더해서 확인해야 하기 때문에 exponential한 시간이 걸릴 것입니다.&lt;/p&gt;

&lt;p&gt;대신해서, 이렇게 생각해 봅시다. 이하, 한줄로 쭉 연결된 path를 경로 또는 체인으로 표현하겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;만약 최종적인 답이, 트리에서 가장 긴 경로 (루트-리프 중 가장 긴 경로)를 포함하지 않는다면 적당한 경로 하나를 빼고 대신에 이 가장 긴 경로를 집어넣으면 더 좋은 답이 됩니다.&lt;/li&gt;
  &lt;li&gt;이를 귀납적으로 반복 적용하면, 무조건 현재 남아 있는 가장 긴 경로를 택해야 한다는 것입니다.&lt;/li&gt;
  &lt;li&gt;단, path의 길이의 합이 아니라 union에 포함된 노드 수를 세기 때문에, 이미 한번 방문된 노드는 더이상 path의 길이에 의미가 없습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;path의 개수는 너무 많고, 우리는 어차피 어떤 노드를 정하면 거기서부터 리프까지 달려가는게 최대한 이득이기 때문에, “어떤 노드를 골라서” 그 노드를 루트로 하는 서브트리에서 가장 깊이 들어가 있는 리프까지의 경로를 택한다고 생각해도 충분합니다. 즉, 트리를 서로 disjoint한 path로 잘라서 생각합니다.&lt;/p&gt;

&lt;p&gt;이제, 미리 모든 path를 priority queue에 넣어놓고, 이를 고르는 식으로 돌립니다. 단, 이미 방문한 노드는 다시 고르지 않도록 조정하면 됩니다. 아래 구현이 충분히 직관적으로 읽힌다고 생각해서, 더이상 설명은 생략하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;bits/stdc++.h&amp;gt;
#define usecppio ios::sync_with_stdio(0);cin.tie(0);cout.tie(0);
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;priority_queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int32_t&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;usecppio&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="problem-solving" /><summary type="html">Contents</summary></entry><entry><title type="html">Autodiff/Backpropagation</title><link href="http://localhost:4000/deep-learning-study/backpropagation/" rel="alternate" type="text/html" title="Autodiff/Backpropagation" /><published>2021-11-16T00:00:00+09:00</published><updated>2021-11-16T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/backpropagation</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/backpropagation/">&lt;div id=&quot;toc&quot;&gt;
>>>>>>> Stashed changes
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#backpropagation&quot; id=&quot;markdown-toc-backpropagation&quot;&gt;Backpropagation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#notes&quot; id=&quot;markdown-toc-notes&quot;&gt;Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이 글은 심층신경망 수업에서 공부한 내용에 기반하지만, 제가 나름대로 이해한 바를 덧붙여서 작성했습니다. 특히, 설명하는 방법이 조금 다릅니다.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Multi layer perceptron이 되었든, Convolutionary neural network가 되었든 기본적인 틀은 logistic regression과 다를 것이 없습니다.&lt;/p&gt;

&lt;p&gt;설명의 편의를 위해 이 글에서는 MLP에 대해 설명하겠지만, CNN도 사실은 별로 다르지 않습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MLP는 결국, 다음과 같은 형태의 함수로 나타나는 회귀 모형이라고 볼 수 있습니다.
\(\begin{align*}
  y_L &amp;amp;= W_L y_{L-1} + b_L \\
  y_{L - 1} &amp;amp;= \sigma(W_{L-1} y_{L - 2} + b_{L - 1}) \\
  \cdots &amp;amp; \cdots \\
  y_2 &amp;amp;= \sigma (W_2 y_1 + b_2) \\
  y_1 &amp;amp;= \sigma (W_1 x + b_1)
\end{align*}\)&lt;/li&gt;
  &lt;li&gt;여기서 $W_i, b_i$ 들은 모두 trainable weight 이고, $\sigma$는 어떤 activation function 입니다.&lt;/li&gt;
  &lt;li&gt;우리는, $y_L$의 참값 (이라고 말하면 좀 애매하지만…) 을 반환하는 함수 $\tilde{y_L} = f(x)$ 가 존재한다고 생각합니다. 이를 최대한 &lt;strong&gt;근사&lt;/strong&gt; 하는 것이 목표입니다. 즉, 저 위 형태의 함수 ($W_i, b_i$ 를 이용하여 표현되는 함수) 를 &lt;strong&gt;표현 가능하다&lt;/strong&gt; 라고 정의하면, &lt;strong&gt;Ground-truth 함수에 가장 가까운 표현가능한 함수&lt;/strong&gt; 를 찾고 싶습니다.&lt;/li&gt;
  &lt;li&gt;그러나 우리는 ground truth를 모두 아는게 아니라, 몇몇 데이터 $x^1, x^2, \dots$ 에 대해 알고 있습니다.&lt;br /&gt;
따라서, 어떤 Loss function을 정의하여
\(\sum_{i = 1}^{n} \mathcal{L}(y_L^{i}, \tilde{y_L}^{i})\)
을 정의한 다음, 이 $\mathcal{L}$ 이 어떤 실제 $\tilde{y_L}^i$ 과 $y_L^i$ 간의 거리를 제시하므로, 이를 가능한 최소화하는 방향으로 나아가려고 합니다.&lt;/li&gt;
  &lt;li&gt;그러므로, 우리는 여기서 SGD 또는 그 비슷한 알고리즘들을 사용합니다. 즉, $W_k, b_k$ 행렬 또는 벡터에 들어 있는 각 변수 $W_k(i, j)$ 나 $b_k(i)$ 를 이용해서 전체 공간에서의 Loss function을 그려놓고, 그 minimum을 (iterative하게) 찾을 수 있기를 바랍니다.&lt;/li&gt;
  &lt;li&gt;SGD나 다른 방법을 쓰려면, 결국은 이런 느낌의 편미분계수들을 꼭 알아야 합니다. 
\(\pdv{\mathcal{L}}{W_k(i, j)} \quad \quad \pdv{\mathcal{L}}{b_k(i)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모델이 간단하면 뭐 직접 미분한다고 치지만, 위에 있는 MLP 식 같이 생긴 복잡한 함수를 어떻게 미분할 수 있을까요?&lt;/p&gt;

&lt;h2 id=&quot;backpropagation&quot;&gt;Backpropagation&lt;/h2&gt;
&lt;p&gt;위 형태를 잘 보면, 합성함수 형태임을 알 수 있습니다. 합성함수의 미분은 Chain rule을 이용해서 수행할 수 있습니다.&lt;br /&gt;
$x \in \R^m, y \in \R^n$, $g : \R^m \to \R^n, f : \R^n \to \R$ 정도의 세팅을 생각해 봅시다. $\mathbf{y} = g(\mathbf{x}), z = \mathbf{y}$ 라 할 때, 다음이 성립합니다.
\(\pdv{z}{x_i} = \sum_{j} \pdv{z}{y_j} \pdv{y_j}{x_i}\)
이 방법을 이용해서, 우리는 전체 $P$개의 모든 파라미터에 대해 $\pdv{\mathcal{L}}{w_i}$ 를 구해야 합니다.&lt;/p&gt;

&lt;p&gt;이를 계산하기 위해, 먼저 Computational graph를 만듭니다. Computational graph란, 아래와 같이 각 값들을 노드로, 계산에 필요한 dependency들을 edge로 연결해서 그래프 형태로 만든 것입니다.
&lt;img src=&quot;../../images/40cd6084bc0a4674ff1e61d062fc8f8900db1c435a6b86e723fa32965d94d37f.png&quot; alt=&quot;picture 3&quot; /&gt;&lt;br /&gt;
(사진출처 : 서울대학교 심층신경망의 수학적 기초 강의자료)&lt;/p&gt;

&lt;p&gt;여기서, ‘변수를 다른 변수로 미분한 미분계수’ 들을 구하고, ‘최종 결과를 변수로 미분한 미분계수’ 를 그 결과로 얻을 것입니다. 구체적으로,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;각 edge에 대해, 변수를 변수로 미분한 중간 미분계수를 edge에 적어넣고,&lt;/li&gt;
  &lt;li&gt;마지막에, root 노드 (i.e, 계산의 최종값) 에서 출발해서, 임의의 노드까지 가는 경로를 모두 따라가면서 곱해서 더하면 ‘최종결과를 변수로 미분한’ 미분계수를 얻습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;즉, 알고리즘의 언어로 말하자면 DAG 위에서 depth가 낮은 노드부터 거꾸로 올라가면서 edge의 값을 계산하고 (DP), 돌아올때는 topological order로 계산하겠다는 의미입니다.&lt;/p&gt;

&lt;p&gt;이 사진에 있는 함수를 직접 계산하면서 과정을 따라가 보겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;step이 낮은 것부터 올라갑니다. 즉, 처음에는 step 1인 $a$-노드의 미분계수들을 계산하기 위해 $\pdv{a}{x}$ 를 구하며, 이 값은 $1/x$ 이므로 1/3입니다. 여기서 주목할 점은, 일반적인 symbolic differntiation을 수행할 때는 $1/x$를 들고 가지만, 우리는 어차피 최종적으로 수치연산을 할 것이므로 $1/3$ 이라는 사실만 기억하면 $1/x$ 라는 값은 잊어버려도 됩니다. 이 값은 edge에 적어 넣습니다. 또한 이후에 $a$값도 필요하기 때문에 $a = \log 3$ 이라는 결과를 노드에 적어넣습니다. 이제, step 1까지 왔습니다.&lt;/li&gt;
  &lt;li&gt;step 2에 해당하는 $b$를 구해야 합니다. $\pdv{b}{a} = y, \pdv{b}{y} = a$ 이며, 이는 각각 $a, y$의 &lt;strong&gt;이미 계산한 노드값&lt;/strong&gt; 을 참조해서 계산할 수 있습니다. 각각 $2, \log 3$ 이 될 것이며, 이를 edge에 적어 넣습니다. $b$ 는 $2 \log 3$ 이고. 이건 노드에 적어넣습니다.&lt;/li&gt;
  &lt;li&gt;step 3에 해당하는 $\pdv{c}{b}$ 는 $\frac{1}{2\sqrt{b}} = \frac{1}{2\sqrt{\log 3}}$ 입니다. $c = \sqrt{log 3}$ 입니다.&lt;/li&gt;
  &lt;li&gt;step 4는 마지막으로, $\pdv{f}{c} = 1$, $\pdv{f}{b} = 1$ 이며, $f$ 의 최종적인 값은 $\sqrt{2 \log 3} + 2 \log 3$ 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기까지가 지금 1 과정이 끝난 것입니다. 이를 “Forward pass” 등으로 부릅니다. 여기까지 계산한 결과는 아래와 같습니다.
&lt;img src=&quot;../../images/de99a2ba80e6f53a603bb8047d889a83d9d279550c8e053d5f4ad9f2479dd270.png&quot; alt=&quot;picture 4&quot; /&gt;&lt;br /&gt;
이제, 다시 거꾸로 돌아가면서 계산합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\pdv{f}{c} = 1$. 이번에는, $c$에 해당하는 노드에 이 값을 적어넣습니다.&lt;/li&gt;
  &lt;li&gt;$\pdv{c}{b} = \frac{1}{2 \sqrt{2 \log 3}}$ 이며, $\pdv{f}{b}$ 는 여기에 따로 $b$가 $f$에 영향을 미치는 1이 있으므로 (가장 아래 edge), $\pdv{f}{b} = \frac{1}{2 \sqrt{2 \log 3}} + 1$ 입니다. 마찬가지로 $b$ 노드에 적어 넣습니다.&lt;/li&gt;
  &lt;li&gt;같은 방법으로 뒤로 계속 달립니다. $\pdv{f}{a} = \frac{1}{\sqrt{2 \log 3}} + 2$.&lt;/li&gt;
  &lt;li&gt;결국 다 계산하면, $\pdv{f}{x} = \frac{1}{3\sqrt{2\log 3}} + \frac{2}{3}$ 과 $\pdv{f}{y} = \sqrt{\frac{\log 3}{8}} + \log 3$ 이 남을 것입니다. 
이 방법을 Backpropagation이라고 부릅니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Autodiff란, 사실은 forward autodiff 등 몇가지 방법이 더 있습니다. 그중 가장 대표적인 방법인 backpropagation을 소개했는데, 사실 생각해 보면 반대로 forward pass만으로 계산하는 방법이 있습니다. 
위 과정에서 위로 올라가는 DP를 할 때, $\pdv{b}{a}$ 같은 값들을 계산해서 edge에 적어놓고, 바로 $b$ 노드에는 $\pdv{b}{x}, \pdv{b}{y}$ 를 그자리에서 계산해서 (앞서 $\pdv{a}{x}$ 도 노드에 적어놨을 것이므로) 기억하는 방법이 있습니다.
이렇게 계산하면 한번 forward를 달릴 때 모든 계산이 끝납니다.&lt;/li&gt;
  &lt;li&gt;그럼에도 불구하고, 실제로 사용하는 deep learning에서의 gradient 계산은 대부분 backpropagation입니다. 그 이유는, 지금 위 예시에서는 알 수 없는 부분이긴 하지만 MLP를 다시 생각해 보면 대부분의 연산이 행렬곱이므로 위 예시와는 달리 각 edge에 스칼라값이 아니라 행렬이 쓰여지게 됩니다. 이게 왜 의미가 있냐면, 결국은 ‘행렬들을 순서대로 많이’ 곱해야 한다는 얘기고… 행렬 여러개를 곱할 때는 작은 행렬부터 곱하고 그 결과를 큰 행렬과 곱하는 것이 대체로 보다 효율적입니다. (이 표현은 완벽하게 정확하지는 않지만, 행렬의 크기가 단조증가한다면 참입니다. 사실은 이 자체가 &lt;strong&gt;행렬 곱셈 순서&lt;/strong&gt; 라는 (백준에도 있는..ㅋㅋ) 매우 유명한 DP 문제입니다.) 그런데 MLP든 CNN이든, 네트워크 끝쪽 (출력에 가까운 쪽) 으로 향하면서 점점 feature의 개수를 줄여나가는 것이 일반적이며, 따라서 backpropagation 방법으로 뒤에서부터 곱하면서 오는게 행렬 곱셈을 더 빨리 할 수 있기 때문입니다.&lt;/li&gt;
  &lt;li&gt;Torch 등 딥러닝 라이브러리들은 이 backpropagation을 자동으로 잘 따라가 주기 때문에 일반적으로는 걱정할 필요가 없지만, 새로운 loss function을 정의할 때는 항상 미분가능한지를 생각해야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;서울대학교 심층신경망의 수학적 기초 강의자료 (&lt;a href=&quot;http://www.math.snu.ac.kr/~ernestryu/courses/deep_learning.html&quot;&gt;링크&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Ian Goodfellow, Yoshua Bengio, &amp;amp; Aaron Courville (2016). Deep Learning. MIT Press.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">LeNet으로 MNIST 풀어보기</title><link href="http://localhost:4000/deep-learning-study/LeNet-MNIST/" rel="alternate" type="text/html" title="LeNet으로 MNIST 풀어보기" /><published>2021-11-07T00:00:00+09:00</published><updated>2021-11-07T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/LeNet-MNIST</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/LeNet-MNIST/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#lenet-모델&quot; id=&quot;markdown-toc-lenet-모델&quot;&gt;LeNet 모델&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#구현&quot; id=&quot;markdown-toc-구현&quot;&gt;구현&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 8강 (10월 5일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/deep-learning-study/mnist-mlp/&quot;&gt;MLP로 MNIST 풀어보기&lt;/a&gt;의 코드와 &lt;a href=&quot;/deep-learning-study/convolutionary-neural-networks/&quot;&gt;CNN 기초&lt;/a&gt; 내용에 이어지는 포스팅입니다.&lt;/p&gt;

&lt;h2 id=&quot;lenet-모델&quot;&gt;LeNet 모델&lt;/h2&gt;
&lt;p&gt;여기서는 LeNet-5 모델에 대해 간단히 살펴봅니다.&lt;/p&gt;

&lt;p&gt;LeNet은 거의 최초의 CNN을 이용한 image classification 모델이라고 할 수 있습니다. Turing award 수상자이며, 사실상 CNN의 아버지 격인 Yann Lecun의 연구팀이 1998년에 개발하였고 그 이름을 따서 LeNet이라는 이름을 갖게 되었습니다. “Gradient Based Learning Applied to Document Recognition” 라는 제목의 논문으로 발표되었는데, 제목에서 알 수 있듯 본래 손글씨로 쓰인 글자를 구분하는 task를 해결하기 위해 개발되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/cd97eccdcd206c69165bedbe52ab311cecf6e35e340166c1780794892fed550e.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 구조는 LeNet의 전체적인 모델입니다. &lt;a href=&quot;/deep-learning-study/convolutionary-neural-networks/&quot;&gt;CNN 기초&lt;/a&gt; 에 있는 각 레이어별 설명을 모두 이해했다는 가정하에, LeNet의 ‘선택’ 만 살펴보겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;첫 레이어는 $5 \times 5$ Convolution filter 6개를 사용합니다.&lt;/li&gt;
  &lt;li&gt;Subsampling은 average pooling을 사용하고&lt;/li&gt;
  &lt;li&gt;Activation function으로는 tanh의 약간 변형된 형태를 사용합니다.&lt;/li&gt;
  &lt;li&gt;재밌는 점은 C3 Layer가 일반적인 convolution이 아니라는 점입니다. 원본 논문에 의하면, symmetry를 깨기 위해서 S2-&amp;gt;C3 convolution을 할 때, 6개 채널 전부가 아닌 채널 일부만 사용해서 convolution을 수행합니다. 
&lt;img src=&quot;../../images/591aba20e38405a3f2c2fef76a765f3ac12b5b8abc6c3c9c8410ab22f8abc678.png&quot; alt=&quot;picture 2&quot; /&gt;  이와 같이, 0번째 컨볼루션은 0, 1, 2 채널만 쓰고… 하는 방법입니다.&lt;/li&gt;
  &lt;li&gt;Fully connected layer를 2번 탄 다음, 마지막에는 Gaussian connection이라는 조금 복잡한 방법을 사용합니다. 후술할 이유로 인해 자세히 설명하지는 않겠습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 이어진 후속연구에 의해, 꼭 이런 design choice를 지킬 필요가 없음이 알려졌습니다. 구현의 단순함과 성능을 위해 모델을 조금 수정해서 다음과 같이 구현하겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Subsampling에는 avg pooling이 아닌 max pooling을 사용합니다.&lt;/li&gt;
  &lt;li&gt;Activation으로 ReLU를 사용하겠습니다.&lt;/li&gt;
  &lt;li&gt;굳이 Symmetry를 이런 방법으로 깨지 않아도, initialization을 잘 하면 상관 없다고 합니다. Symmetry-breaking connection은 버리겠습니다.&lt;/li&gt;
  &lt;li&gt;Gaussian connection도 하지 않아도 됩니다. 그냥 Fully connected layer로 충분하다고 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;
&lt;p&gt;구현은 &lt;a href=&quot;/deep-learning-study/mnist-mlp/&quot;&gt;MLP로 MNIST 풀어보기&lt;/a&gt; 와 크게 다르지 않습니다.&lt;/p&gt;

&lt;p&gt;MNIST 데이터 로딩하는 부분의 코드를 그대로 가져옵니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optimizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist_data/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./mnist_data/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cuda&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제, LeNet 모델을 정의합니다. Convolution 연산을 쓴다는것 외에는 여전히 다른점이 없습니다.&lt;/p&gt;

&lt;p&gt;모델의 정의가 위 그림과 다른점이 하나 더 있는데, 그림에서는 첫 layer에 패딩을 쓰지 않는 대신 이미지 크기가 32 by 32였지만, 우리가 가진 MNIST 데이터는 28 by 28이기 때문에 첫 레이어에서 패딩 2를 넣어 줍니다. 이후에는 위 설명과 똑같습니다. Optimizer로는 여기서도 SGD를 쓰겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C5_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C5_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeNetModern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchsummary&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이렇게 얻은 model의 summary는 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 28, 28]             156
              ReLU-2            [-1, 6, 28, 28]               0
         MaxPool2d-3            [-1, 6, 14, 14]               0
            Conv2d-4           [-1, 16, 10, 10]           2,416
              ReLU-5           [-1, 16, 10, 10]               0
         MaxPool2d-6             [-1, 16, 5, 5]               0
            Linear-7                  [-1, 120]          48,120
              ReLU-8                  [-1, 120]               0
            Linear-9                   [-1, 84]          10,164
             ReLU-10                   [-1, 84]               0
           Linear-11                   [-1, 10]             850
================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 0.24
Estimated Total Size (MB): 0.35
----------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;6만 개의 parameter를 갖는 매우 작은 모델입니다.&lt;/p&gt;

&lt;p&gt;이제 데이터를 이용해서 이 모델을 실제로 훈련합니다. Train 방법도 MLP에서와 똑같습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; : loss &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt; 로 기존 MLP 모델에 남아있던 gradient 값들을 다 날리고&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_loss&lt;/code&gt; 는 현재 시점에 모델이 이미지를 받아서 추측을 해보고 그 loss function 값을 확인하고,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.backward()&lt;/code&gt; 로 현재 시점의 gradient를 계산하고&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizer.step()&lt;/code&gt; 으로 실제 optimization (여기선 SGD)를 수행합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;거의 같은 방법으로, Test set에 대해서 실제 정확도를 확인합니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view_as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'''[Test set]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Average loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, 
Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%)'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;저는 20번의 epoch (대략 1분 정도의 training) 후에 98.25%의 정확도를 얻을 수 있었습니다.&lt;/p&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">Image Segmentation - Single Layer Model</title><link href="http://localhost:4000/image-segmentation-2021/single-layer-convolution/" rel="alternate" type="text/html" title="Image Segmentation - Single Layer Model" /><published>2021-11-06T00:00:00+09:00</published><updated>2021-11-06T00:00:00+09:00</updated><id>http://localhost:4000/image-segmentation-2021/single-layer-convolution</id><content type="html" xml:base="http://localhost:4000/image-segmentation-2021/single-layer-convolution/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#model-만들기&quot; id=&quot;markdown-toc-model-만들기&quot;&gt;Model 만들기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#training&quot; id=&quot;markdown-toc-training&quot;&gt;Training&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#results&quot; id=&quot;markdown-toc-results&quot;&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이번 포스팅에서는 구현이 &lt;strong&gt;어떤 식으로&lt;/strong&gt; 동작해야 하는지를 대충 알아보기 위해, 생각할 수 있는 가장 단순한 모델인 &lt;strong&gt;1-layer convolution&lt;/strong&gt;을 이용해 semantic segmentation을 시도합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/image-segmentation-2021/preparation&quot;&gt;Preparation post&lt;/a&gt; 에서 이어집니다.&lt;/p&gt;

&lt;h2 id=&quot;model-만들기&quot;&gt;Model 만들기&lt;/h2&gt;
&lt;p&gt;Pytorch에서 model은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torch.nn.Module&lt;/code&gt; 형태의 클래스로 만들 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# models/single_conv.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SingleConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SingleConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;우리는 RGB 3개 채널을 갖는 이미지를 받아서, 23개 클래스 중 하나를 구분할 것입니다. 즉, 입력은 $3 \times W \times H$ 형태일 것이며, 출력은 각 $(i, j)$ 마다 23개의 클래스에 대한 probability를 출력해야 합니다. ($23 \times W \times H$)&lt;/p&gt;

&lt;p&gt;우리가 생각할 수 있는 가장 간단한 형태의 모델은 단 한 번의 convolution layer로 구성된 모델일 것입니다. 이 모델은 $3 \times f \times f$ 크기의 convolution filter 23개가 각 클래스에 대응하며, 각 filter는 trainable weight과 bias를 갖습니다. 즉 파라미터는 여기서 $27 \times 23$개의 weight과 23개의 bias로 총 644개가 됩니다. 각 클래스의 확률값은 convolution연산과 ReLU 한번으로 바로 결과값이 도출됩니다.&lt;/p&gt;

&lt;p&gt;이 모델을 정의하는 것까지를 코드로 옮기면 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# main.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datautils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;evaluate&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 

&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import_drone_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SingleConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;여기서 batch size는 GPU 메모리에 들어가는 한 많이 욱여넣는 것이 일반적입니다. 저는 1070Ti를 쓰기 때문에 6정도는 괜찮은것 같습니다. 다른 함수들은 앞서 Prep에서 준비한 함수들입니다. summary가 반환하는 결과가 아래와 같이 나타납니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 23, 600, 400]             644
              ReLU-2         [-1, 23, 600, 400]               0
================================================================
Total params: 644
Trainable params: 644
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 2.75
Forward/backward pass size (MB): 84.23
Params size (MB): 0.00
Estimated Total Size (MB): 86.98
----------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;우리가 예상했던 대로 644개의 trainable param을 갖는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;
&lt;p&gt;이제 모델을 정의했다면, 이 모델의 633개의 parameter를 실제로 train해 줘야 합니다. Train은 크게 두 과정으로 이루어집니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Forward pass로 훈련용 데이터를 먹여서, 최종 결과를 도출한 다음, 이 결과를 ground truth와 비교해서 얼마나 다른지 (loss function)의 값을 측정&lt;/li&gt;
  &lt;li&gt;그 값을 최소화하는 방향으로 뭔가 optimization 알고리즘을 적용.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;전체적인 CNN 모델 훈련의 이론에 대해서 다룬 포스팅들과, LeNet을 이용해서 pytorch에서 classification 하는 포스팅 (&lt;a href=&quot;/deep-learning-study/LeNet-MNIST&quot;&gt;LeNet으로 MNIST 풀어보기&lt;/a&gt;)가 있으므로 이쪽을 참고해 주세요.&lt;/p&gt;

&lt;p&gt;여기서의 훈련과정은 LeNet MNIST훈련과 크게 다르지 않습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# train.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;acc_metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel_accuracy&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;EPOCH &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; training begins...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc_metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Train epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; / &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Loss &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Accr &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Time &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; min&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train_loss'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'train_acc'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Total training time &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; minutes taken&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;LeNet으로 MNIST 풀어보는 포스팅에서 다뤘던 것과 거의 같습니다. 여러 모델에 대해 실험하기 위해 함수로 만들었다는 정도만 차이가 있습니다. 달라지는 부분이 거의 없으므로, LeNet 포스팅을 참조해 주세요.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;train data를 로딩할 data loader를 받고&lt;/li&gt;
  &lt;li&gt;몇 epoch 돌릴지를 파라미터로 받고&lt;/li&gt;
  &lt;li&gt;어떤 loss function을 어떤 optimizer로 훈련하고&lt;/li&gt;
  &lt;li&gt;어떤 방법으로 accuracy를 측정할지 (사실 훈련 자체에는 상관이 없는데, 눈으로 보기 위해서입니다) 정합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제, 마지막으로 이 모두를 합쳐서 최종 로직을 작성합니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# main.py
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.003&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;evaluator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ModelEvaluation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;evaluator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 모델에 뭔가 노력을 기울이는 것은 의미가 없으므로, 아무렇게나 5 epoch를 돌립니다. loss function과 optimizer도 일반적인 Cross Entropy Loss 와 Adam을 그대로 집어넣습니다. 이렇게 좀 기다려 보면…&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;../../images/5016c106c073b550e189e3d0242abd0ba532280a4eed9c4c27025aed43c46510.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;br /&gt;
이 결과는 8번 이미지에 대한 결과입니다. 모델이 대부분을 void로 잡아내긴 했는데, 뭔가 이미지의 큰 청크들에 대해 분명 trivial하지 않게 뭔가를 잡아낸 것 같아 보입니다.&lt;/p&gt;

&lt;p&gt;이는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;show_qualitative&lt;/code&gt;로 뽑은 결과인데, evaluate한 결과는 평균 pixel accuracy 47%정도가 나왔습니다. 이 프로젝트는 앞으로 다양한 방법을 이용해 이를 85% 내지는 그 이상으로 올릴 계획입니다.&lt;/p&gt;</content><author><name></name></author><category term="image-segmentation-2021" /><summary type="html">Contents</summary></entry><entry><title type="html">Image Segmentation - Preparation</title><link href="http://localhost:4000/image-segmentation-2021/preparation/" rel="alternate" type="text/html" title="Image Segmentation - Preparation" /><published>2021-11-01T00:00:00+09:00</published><updated>2021-11-01T00:00:00+09:00</updated><id>http://localhost:4000/image-segmentation-2021/preparation</id><content type="html" xml:base="http://localhost:4000/image-segmentation-2021/preparation/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#data-preparation&quot; id=&quot;markdown-toc-data-preparation&quot;&gt;Data preparation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dataset&quot; id=&quot;markdown-toc-dataset&quot;&gt;Dataset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#evaluation-of-model&quot; id=&quot;markdown-toc-evaluation-of-model&quot;&gt;Evaluation of Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;앞으로 이 프로젝트에서 사용하는 코드는 모두 &lt;a href=&quot;https://github.com/gratus907/Image-Segmentation-Study&quot;&gt;Github Repo&lt;/a&gt; 에 올라갈 예정입니다. 오늘은 먼저, 데이터 등을 준비하는 과정을 진행합니다.&lt;/p&gt;

&lt;h2 id=&quot;data-preparation&quot;&gt;Data preparation&lt;/h2&gt;
&lt;p&gt;TU Graz에서 제공하는 &lt;strong&gt;Drone aerial image&lt;/strong&gt; 데이터를 이용하려고 합니다. &lt;a href=&quot;https://www.tugraz.at/index.php?id=22387&quot;&gt;링크&lt;/a&gt; 에서 다운로드받을 수 있습니다. 사진 400장의 데이터셋이지만 굉장히 용량이 크고 (4.1GB, 각 이미지가 무려 &lt;strong&gt;6000 by 4000&lt;/strong&gt; 입니다) pixel-accurate한 라벨이 달려있는데다 클래스는 23개로 많지 않아서 적당하다고 생각했습니다. 여기서는 360개를 training에, 40개를 test에 쓰겠습니다.&lt;/p&gt;

&lt;p&gt;먼저, 필요한 모듈들을 import해서 때려넣습니다. 별로 좋은 practice는 아니지만, 다양한 모델들을 테스트해보는 의미가 있으므로 코드의 아름다움은 잠시 접어두기로 합시다. Jupyter Notebook이나 Colab을 사용한다면 훨씬 편하게 테스트할 수 있겠지만, 전체를 깃헙에 올려서 바로 볼 수 있게 하기 위해 그냥 일반 파이썬 코딩할때처럼 하겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# basics.py 
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PIL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchsummary&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cuda&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.485&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.456&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.406&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;device 등은 사실 모든 딥러닝에서 공통적으로 쓰는 GPU 코드이므로 별로 특별한 의미가 있지는 않고, 특이한 점은 mean과 std입니다. 이 값은 RGB 각 채널을 normalize하기 위한 값인데요. 0.5가 아닌 이유는 이 값들이 사실 ImageNet에서 훈련된 결과 값인데, 원칙적으로는 새로운 mean과 std를 train하는 것이 의미가 있겠지만 100만장의 ImageNet 데이터를 믿고 그냥 써도 큰 문제가 없습니다.&lt;/p&gt;

&lt;h2 id=&quot;dataset&quot;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;pytorch에서 custom dataset을 사용할 때는, torch.utils.data.Dataset 클래스를 만들면 됩니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# datautils.py 
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DroneDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cvtColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COLOR_BGR2RGB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interpolation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTER_NEAREST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMREAD_GRAYSCALE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interpolation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTER_NEAREST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;일단은 data augmentation 등은 아무것도 생각하지 말고, 정말 순수한 bare minimum만 생각합니다.&lt;/p&gt;

&lt;p&gt;간단히 해석해보면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__&lt;/code&gt; 는 img_path, mask_path 등을 받아서 이 데이터셋의 위치와, 어떤 transform을 적용할지 (transform이란, 이미지를 텐서로 바꾸는 연산) 기억합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__getitem__&lt;/code&gt;은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data[3]&lt;/code&gt; 과 같이 쓰기 위해서 override하는 method로, 이미지를 잘 읽고 적절하게 변환해서 뱉어줍니다.&lt;/li&gt;
  &lt;li&gt;6000 * 4000은 진짜 좀 너무 크기 때문에, 이미지 크기는 600 * 400으로 줄였습니다. 줄일때는 NEAREST를 써야 mask의 라벨이 이상해지지 않습니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test&lt;/code&gt; 데이터에 대해서는 Image를 그대로 저장하고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;training&lt;/code&gt; 데이터에 대해서는 이를 torch tensor로 바꿔서 저장합니다. 이렇게 하는 이유는, 나중에 정성적으로 segmentation의 퀄리티를 확인하고 싶을 때 이미지를 같이 display하려면 test에 대해서는 이미지를 갖고있는게 편하기 때문이&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 이 파일을 실제 모델에 적용하기 위해, training / test 데이터셋으로 잘라줘야 합니다. 이를 편하게 잘라주는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sklearn.model_selection.train_test_split&lt;/code&gt;이 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# datautils.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;import_drone_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;../dataset/semantic_drone_dataset/original_images/&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;MASK_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;../dataset/semantic_drone_dataset/label_images_semantic/&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dirname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;walk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DroneDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MASK_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DroneDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMAGE_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MASK_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;evaluation-of-model&quot;&gt;Evaluation of Model&lt;/h2&gt;
&lt;p&gt;모델을 만들기 전에 일단 모델이 있다면 어떻게 동작해야 할지를 먼저 생각해 봅니다. 좀 오래된 말이긴 하지만, 머신러닝을 정의하는 방법 중 한가지는 T, P, E 라고 해서…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;T&lt;/strong&gt;ask : 어떤 명확하게 정의되는 작업을 수행하고 싶고,&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;P&lt;/strong&gt;erformance Measure : 현재 가지고 있는 프로그램의 성능을 측정하는 방법이 있으며,&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;E&lt;/strong&gt;xperience : 데이터로부터 프로그램이 &lt;strong&gt;P&lt;/strong&gt;를 발전시키기 위해 노력한다는 것입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우리는 아직 프로그램을 작성하지 않았지만, semantic segmentation이라는 &lt;strong&gt;T&lt;/strong&gt;에 집중할 것입니다. &lt;strong&gt;P&lt;/strong&gt;를 어떻게 할지는 이 자체로도 독립된 포스팅이 필요한데, mIoU, Hausdorff distance등 재밌는게 많습니다. 이중 가장 생각하기 쉬운 것은 그냥 pixel단위로 맞은 픽셀수 / 전체 픽셀수를 세는 것입니다.&lt;/p&gt;

&lt;p&gt;Pytorch에서는 모델이 어떤 input image를 받아서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model(x)&lt;/code&gt; 과 같은 식으로 call해서 inference를 진행합니다. 그 결과를 실제 mask와 비교해서 정확도를 측정해야 합니다.&lt;/p&gt;

&lt;p&gt;Bare minimum의 철학에 따라 일단 pixel accuracy만을 구현합니다. 다만 나중에 여러 다른 metric을 구현할 수 있음을 염두에 두고, metrics.py로 따로 파일을 빼겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# metrics.py 
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pixel_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Pixel accuracy를 계산할때는 backpropagation용 gradient가 필요하지 않으므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with torch.no_grad():&lt;/code&gt; 로 감싸서 제낍니다.&lt;/p&gt;

&lt;p&gt;이제, 편하게 테스트를 여러번 시도하기 위해 테스트를 돌리는 클래스를 따로 만들겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# evaluate.py 
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;basics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ModelEvaluation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Mean accruacy = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;show_qualitative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pred_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inv_normalize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.485&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.456&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.406&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inv_normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapaxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapaxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Picture'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Ground truth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_axis_off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Model | score &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_axis_off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__&lt;/code&gt;에서는 어떤 모델을 테스트하는지, 어떤 데이터에 대해 테스트하는지, 그리고 어떤 metric을 사용할 것인지를 정합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;evaluate_single()&lt;/code&gt; 은 이미지 한 개를 받아서 이를 normalize한다음 실제로 inference해 봅니다. 결과로 predicted mask와 그 정확도를 반환합니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unsqueeze&lt;/code&gt;는 간단히 그냥 텐서를 쭉 잡아펴주는 연산으로 생각하면 됩니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;evaluate_all()&lt;/code&gt; 은 평균 정확도를 측정합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;show_qualitative()&lt;/code&gt; 는 결과의 정성적 평가를 위한 것으로, 특정 이미지에 대한 image, ground truth, prediction을 동시에 띄워줍니다. 실제로 이미지를 띄워야 하기 때문에, Dataset을 만들때 ToTensor와 Normalize했던 것을 다시 거꾸로 돌려줘야 합니다. Normalize의 정의를 이용하여 이부분은 적당히 처리해줄 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음 포스팅에서는 train을 어떻게 실제로 실행할지와, 이를 이용해서 아주 간단한 모델을 한번 확인해보는 정도를 진행할 예정입니다.&lt;/p&gt;</content><author><name></name></author><category term="image-segmentation-2021" /><summary type="html">Contents 앞으로 이 프로젝트에서 사용하는 코드는 모두 Github Repo 에 올라갈 예정입니다. 오늘은 먼저, 데이터 등을 준비하는 과정을 진행합니다.</summary></entry><entry><title type="html">Aho-Corasick Multiple Pattern Matching</title><link href="http://localhost:4000/advanced-algorithms/aho-corasick-algorithm/" rel="alternate" type="text/html" title="Aho-Corasick Multiple Pattern Matching" /><published>2021-10-27T00:00:00+09:00</published><updated>2021-10-27T00:00:00+09:00</updated><id>http://localhost:4000/advanced-algorithms/aho-corasick-algorithm</id><content type="html" xml:base="http://localhost:4000/advanced-algorithms/aho-corasick-algorithm/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#motivation&quot; id=&quot;markdown-toc-motivation&quot;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#algorithm&quot; id=&quot;markdown-toc-algorithm&quot;&gt;Algorithm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#complexity&quot; id=&quot;markdown-toc-complexity&quot;&gt;Complexity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#구현&quot; id=&quot;markdown-toc-구현&quot;&gt;구현&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;(아직 작성 중인 글입니다)&lt;/p&gt;

&lt;p&gt;이 글은 KMP 알고리즘과 Trie 자료구조에 대한 이해를 선행으로 요구합니다.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;어떤 $n$글자의 긴 텍스트 $T$에 대해, 짧은 $m$글자의 패턴 $P$를 매칭하는 문제를 생각해 보겠습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;가장 Naive하게 $T$의 모든 위치에 대해 $m$글자를 매칭해보는 알고리즘은 $O(nm)$ 입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm&quot;&gt;KMP 알고리즘&lt;/a&gt; 은 (언젠가 작성할 계획은 있지만 우선순위는 낮습니다) 이를 $O(n + m)$ 으로 줄인 엄청난 성과를 보입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;KMP가 이를 가능하게 하는 방법은, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T[i..i+L-1]&lt;/code&gt; 과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P&lt;/code&gt;를 매칭하다가 중간에 실패했다고 할 때, Naive 매칭은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T[i+1..i+L]&lt;/code&gt; 을 시도하면서 앞서의 정보를 전혀 이용하지 못합니다. 그러나, 패턴이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abababa&lt;/code&gt;인데, ababa까지 맞고 여섯번째 b가 틀렸다면, 앞 다섯글자까지 맞았다는 정보를 최대한 이용하고 싶습니다. 이를 정말 가능한 최대로 이용하는 것이 KMP 알고리즘이며, 위 위키피디아의 링크와 함께 &lt;a href=&quot;https://bowbowbow.tistory.com/6&quot;&gt;BowBowBow님의 블로그&lt;/a&gt; 글을 참고하면 그렇게 어렵지 않게 배울 수 있습니다. 요점은, 앞 몇글자가 맞았음을 이용해서 절대 맞을리가 없는 위치들을 스킵하는 것입니다. 이를 &lt;strong&gt;실패함수&lt;/strong&gt; 라고 부릅니다.&lt;/p&gt;

&lt;p&gt;이제, 이를 패턴이 여러 개인 경우로 확장하고자 합니다. 패턴이 $m_1, m_2, \dots m_k$ 글자의 $P_1, \dots P_k$ 라고 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;실패함수는 결국 어떤 prefix까지는 맞았다는 것을 알고 있는 데서 오는데, 우리는 여러 개의 패턴에 대해 비슷한 정보를 관리하고 싶습니다.&lt;/p&gt;

&lt;p&gt;Prefix 여러개를 동시에 관리하는 것은 Trie를 이용할 수 있습니다. 
&lt;img src=&quot;../../images/a9c2c1743cbd0e6d4b5a6ec257e0bd5864552d77867f1eadf2eb9747fb4a87c5.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 그림을 보면, 파란 간선과 함께 빨간 간선이 그려져 있습니다. 파란 간선은 우리가 일반적으로 알고 있는 Trie의 간선이고, 빨간 간선은 Failure function을 의미합니다. 우리는 다음과 같이 Failure function을 정의합니다.&lt;/p&gt;

&lt;p&gt;“패턴 $P$에 대해, 그 prefix $P’$ 까지를 현재 매칭했다고 하자. 이때, $P’$에 해당하는 노드의 실패-노드 $f(P’)$ 을 찾는데, 이는 $P’$의 &lt;strong&gt;proper suffix&lt;/strong&gt;이면서, &lt;strong&gt;다른 패턴의 prefix&lt;/strong&gt; 인 가장 깊은 노드여야 한다”&lt;/p&gt;

&lt;p&gt;이 조건이 무슨 뜻인지 생각해보면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$P’$을 매칭하다가 실패했다고 하겠습니다. 이제 더이상 이 패턴은 진행할 수 없습니다.&lt;/li&gt;
  &lt;li&gt;그러면 이제, 무슨 패턴을 노릴지 결정해야 합니다. 그림에서 cacba를 텍스트 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T[i..]&lt;/code&gt;에다가 대고 매칭하다가 실패했다면 현재 위치에서 당장 노릴 수 있는 패턴은 acba, cba, ba, a 등으로 시작하는 패턴을 노릴 수 있습니다.&lt;/li&gt;
  &lt;li&gt;이들 중 어떤 다른 패턴의 prefix여야 노리는 것이 의미가 있을 것입니다.&lt;/li&gt;
  &lt;li&gt;이러한 노드들이 여러 개 있다면, acba 노드와 cba 노드 중에는 acba 노드를 먼저 확인해야 합니다. 이유는, acba… 를 매칭하다가 실패하면 cba… 패턴은 그 다음에 노려도 되기 때문입니다.&lt;/li&gt;
  &lt;li&gt;즉, 텍스트를 스캔하면서 트라이를 따라서 움직이다가, 트라이에서 더이상 갈곳이 없으면 최대한 다른 끝점을 노릴 수 있는 곳으로 이동해서 계속 시도한다는 의미가 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;트라이는 빠르게 construct할 수 있으므로, 이러한 실패함수를 어떻게 계산할지만 따로 생각하면 됩니다. 실패함수는 BFS를 이용하여, depth가 얕은 노드부터 깊은 노드로 건설합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;지금 노드 $x$를 보고 있다면, 이 $x$보다 깊이가 얕은 노드 중 반드시 $f(x)$ 가 존재합니다. (proper suffix의 길이는 자기자신보다 짧으므로)&lt;/li&gt;
  &lt;li&gt;$x$의 바로 위 부모노드 $p(x)$ 와, $p(x)$에서 $x$로 오는 edge의 알파벳 (즉 $x$의 마지막 글자에 해당하는 알파벳)을 알고 있습니다. 이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c&lt;/code&gt; 라고 하겠습니다.&lt;/li&gt;
  &lt;li&gt;또한, 실패함수는 depth가 얕은 노드부터 계산했으므로 $f(p(x))$ 도 알고 있습니다. 만약 $f(p(x))$ 에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c&lt;/code&gt;를 이용하여 전진하는 edge가 있다면, 이를 따라 전진합니다.&lt;/li&gt;
  &lt;li&gt;그렇지 않다면, $f(f(p(x)))$ 에다 대고 시도하고… 를 반복하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;만약 트라이를 따라가다가 어떤 패턴의 끝을 만나면, 그 패턴을 찾았다고 report하면 됩니다. 즉 각 노드는 혹시 내가 어떤 패턴의 끝은 아닌지를 미리 기억하고 있어야 합니다. 이 정보는 사실 Trie에 문자열들을 집어넣을때 미리 잡아줄 수 있으므로 크게 문제될 것이 없습니다.&lt;/p&gt;

&lt;p&gt;스캔의 과정을 pseudocode로 표현해 보면 다음과 같습니다.
&lt;img src=&quot;../../images/6027d1807c7529d3d303be17844021b919f73bbb3ead7fdfbafc7590b459126b.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;complexity&quot;&gt;Complexity&lt;/h2&gt;
&lt;p&gt;알파벳 크기를 $q$, 패턴 전체의 글자수의 총합을 $M$, 텍스트의 글자수를 $n$이라고 하겠습니다. 이때,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pseudocode를 보면 자명하게 스캔은 $O(n)$ 인것 같지만, 실제로는 $n$에 next 함수가 소모하는 시간만큼이 걸립니다.&lt;/li&gt;
  &lt;li&gt;트라이를 구성하는 방법은 구현에 따라 다른데, 가장 일반적인 구현인 child pointer array 방식을 쓰는 경우 $O(qM)$ 시간에 트라이를 구성할 수 있으며 (BFS를 돌려야 해서 이만큼이 소모됩니다) $O(qM)$ 메모리를 소비합니다.&lt;/li&gt;
  &lt;li&gt;$q$가 크면 이것이 비효율적일 수 있는데, 트라이의 각 노드에 BBST같은걸 쓴다거나 링크드 리스트를 쓰면 복잡도가 달라집니다. 대표적으로 BBST를 쓰면 $O(M \log q)$ 시간에 트라이를 구성할 수 있고, $O(M \log q)$ 메모리를 소비하는 대신, next가 $O(\log q)$ 시간이 들게 되므로 스캔이 $O(n \log q)$ 걸립니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서, 종합하면 간단하게는 $O(qM + n)$ 시간과 $O(qM)$ 공간을 이용하여 multiple pattern matching을 할 수 있게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;
&lt;p&gt;추가 예정.&lt;/p&gt;</content><author><name></name></author><category term="advanced-algorithms" /><summary type="html">Contents</summary></entry><entry><title type="html">Boyer-Moore Heuristic Pattern Matching</title><link href="http://localhost:4000/advanced-algorithms/boyer-moore-algorithm/" rel="alternate" type="text/html" title="Boyer-Moore Heuristic Pattern Matching" /><published>2021-10-27T00:00:00+09:00</published><updated>2021-10-27T00:00:00+09:00</updated><id>http://localhost:4000/advanced-algorithms/boyer-moore-algorithm</id><content type="html" xml:base="http://localhost:4000/advanced-algorithms/boyer-moore-algorithm/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#motivation&quot; id=&quot;markdown-toc-motivation&quot;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#algorithm--bad-character-heuristic&quot; id=&quot;markdown-toc-algorithm--bad-character-heuristic&quot;&gt;Algorithm : Bad Character Heuristic&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#algorithm--good-suffix-heuristic&quot; id=&quot;markdown-toc-algorithm--good-suffix-heuristic&quot;&gt;Algorithm : Good Suffix Heuristic&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#boyer-moore-horspool-algorithm&quot; id=&quot;markdown-toc-boyer-moore-horspool-algorithm&quot;&gt;Boyer-Moore-Horspool Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;(아직 작성 중인 글입니다)&lt;/p&gt;

&lt;p&gt;이 글은 KMP 알고리즘과 Trie 자료구조에 대한 이해를 선행으로 요구합니다.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Boyer-Moore 알고리즘이 해결하는 문제는 KMP와 똑같이, 어떤 $n$글자의 긴 텍스트 $T$에 대해, 짧은 $m$글자의 패턴 $P$를 매칭하는 것입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;가장 Naive하게 $T$의 모든 위치에 대해 $m$글자를 매칭해보는 알고리즘은 $O(nm)$ 입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm&quot;&gt;KMP 알고리즘&lt;/a&gt; 은 (언젠가 작성할 계획은 있지만 우선순위는 낮습니다) 이를 $O(n + m)$ 으로 줄인 엄청난 성과를 보입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Boyer-Moore 알고리즘은 worst case에서는 $O(nm)$이지만, string이 랜덤하게 주어진다면 평균 $O(n / m)$ 복잡도를 보입니다.&lt;/p&gt;

&lt;p&gt;기본적으로, 이 알고리즘은 패턴을 &lt;strong&gt;오른쪽부터 왼쪽으로&lt;/strong&gt; 매칭하고, 문자열 자체는 (즉 매칭하는 위치 자체는) &lt;strong&gt;왼쪽에서 오른쪽으로&lt;/strong&gt; 봅니다. 이 방향의 차이에 주목할 필요가 있습니다. KMP의 경우는 패턴과 텍스트 모두 좌 -&amp;gt; 우 로 매칭합니다. 가능한한 ‘첫’, ‘두번째’ 와 같은 말은 오른쪽에서 왼쪽으로 매칭하는 실제 세팅에, ‘1번’, ‘2번’ 등의 말은 진짜 인덱스를 의미하도록 작성했습니다.&lt;/p&gt;

&lt;h2 id=&quot;algorithm--bad-character-heuristic&quot;&gt;Algorithm : Bad Character Heuristic&lt;/h2&gt;
&lt;p&gt;텍스트 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abcacbcadc&lt;/code&gt; 에서 패턴 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;acbcda&lt;/code&gt;를 매칭한다고 생각해 봅시다. 이때, 뒤에서부터 앞으로 매칭을 시도하는 것은 텍스트 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abcacb&lt;/code&gt; 와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;acbcda&lt;/code&gt;를 매칭하는 것입니다. 여기서 첫 글자 (패턴을 &lt;strong&gt;오른쪽부터&lt;/strong&gt; 읽으므로 텍스트와 패턴의 첫 글자는 각각 6번 위치인 b와 a입니다!) 를 매칭하려고 시도했을 때, a를 찾아야 하는데 b를 찾았으므로 실패했습니다.&lt;/p&gt;

&lt;p&gt;Naive matching은 여기서 포기하고 다음 위치인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bcacbc&lt;/code&gt;와의 매칭을 시도하겠지만, Boyer-Moore의 알고리즘은 여기서 “그럼 만약, 이 6번위치의 b를 꼭 써야 한다면, 어디까지 내가 패턴을 밀어야 b를 쓸 수 있느냐?” 라는 질문을 던집니다. 생각해보면 텍스트를 기준으로 패턴을 한칸 밀어봤자, 패턴의 5번 글자인 d와 b를 매칭하게 될 것이고 이는 어차피 실패할 것이기 때문입니다. 패턴의 맨 뒤를 기준으로 3글자를 밀어야 b를 텍스트 6번 b에 맞출 수 있으므로, 이만큼을 push해 버릴 수 있습니다. 여기서 이 ‘b’ 를 &lt;strong&gt;Bad Character&lt;/strong&gt; 라고 부를 것입니다.&lt;/p&gt;

&lt;p&gt;이를 좀더 정리하면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bad character가 패턴에 아예 등장하지 않으면, 패턴을 확 밀어서 아예 넘어가도 됩니다.&lt;/li&gt;
  &lt;li&gt;Bad character가 패턴에서 &lt;strong&gt;가장 오른쪽에&lt;/strong&gt; 등장하는 위치가 현재 보고있는 bad character의 패턴에서의 위치보다 왼쪽이면, 그만큼을 밀어도 됩니다.&lt;/li&gt;
  &lt;li&gt;Bad character가 패턴에서 &lt;strong&gt;가장 오른쪽에&lt;/strong&gt; 등장하는 위치가 현재 보고있는 bad character의 패턴에서의 위치보다 오른쪽이면 얻을 수 있는 정보가 없습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;algorithm--good-suffix-heuristic&quot;&gt;Algorithm : Good Suffix Heuristic&lt;/h2&gt;
&lt;p&gt;이 방법은 자세히 설명하지 않을 것입니다. (이유는 후술합니다) Good suffix란, 어떻게 보면 위 Bad character의 3번 경우에 얻는 정보가 없음을 거꾸로 이용하는 방법인데요. 3번 경우는 아마도 꽤 많은 글자들이 맞은 다음 처음으로 bad character를 만난 상황일 것입니다. 즉 pattern의 꽤 긴 suffix가 이미 맞고 있는 상황이라는 의미가 됩니다. 이 Good suffix를 패턴에서 다시 맞추려면 얼만큼 이동해야 하는지를 미리 모두 precomputation해 두면, 그만큼을 점프할 수 있습니다. 당연히 맞는 suffix가 길수록 이 suffix를 다시 맞추기가 어려울 것이므로, 꽤 멀리 점프할 수 있을 것 같습니다. 이 precomputation은 “Pattern의 길이 k인 suffix가 다시 suffix로 등장하는 pattern의 prefix 위치” 를 마킹하면 되고, KMP의 실패함수와 매우 유사한 방법으로 구할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;boyer-moore-horspool-algorithm&quot;&gt;Boyer-Moore-Horspool Algorithm&lt;/h2&gt;
&lt;p&gt;Horspool의 알고리즘은 위 Boyer-Moore에서 Good suffix heuristic을 아예 포기하고, Bad character는 항상 현재 매칭 위치의 마지막 글자만 고려합니다. 이렇게 해도 평균 시간 복잡도 $O(n / m)$ 비슷한 시간을 유지할 수 있음이 알려져 있지만, 그 증명 과정은 엄청난 수식과 고통스러운 증명 (부등식 줄이기)을 요구합니다. 다만, 충분히 랜덤한 텍스트에 대해서는 B-M-H가 굉장히 빠름이 잘 알려져 있습니다.&lt;/p&gt;

&lt;p&gt;Horspool은 굉장히 쉽게 구현할 수 있습니다. 먼저 각 character에 대해 패턴의 오른쪽 끝에서 가장 가까운 (하지만 오른쪽 끝은 아닌) 등장 위치를 계산해 두고, bad character에 걸리면 그만큼 push하면 됩니다.&lt;/p&gt;

&lt;p&gt;여기서는 정말 러프한 증명…도 아니고 argument를 하나 소개하고 마치겠습니다. 알파벳 $q$글자 중 랜덤하게 생성된 string $P, T$에서의 Horspool 알고리즘을 가정하겠습니다. 이중 한 글자가 패턴의 오른쪽 끝에서 얼마나 멀리 있을지 그 기댓값을 생각해 봅시다. 알파벳 $x$를 이용하여 $k$길이 이상의 jump를 허용하기 위해서는 뒤에서 $k-1$개의 글자는 $x$가 아닌 다른 글자여야 하므로, 점프 길이가 $k$ 이상일 확률은 $\left(1-\frac{1}{q}\right)^{k-1}$ 입니다. $r = \left(1-\frac{1}{q}\right)$ 로 쓰면 편하게 이를 $r^{k-1}$ 로 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;$\expect{X} = \sum_{k = 1}^{\infty} \P(X \geq k)$ 의 공식을 이용합니다. $k \geq m+1$의 확률은 0이므로, 
\(\expect{\text{jump length}} = \sum_{j = 1}^{m} r^{j-1} = \frac{r^m - 1}{r - 1}= q(1 - r^m)\)&lt;/p&gt;

&lt;p&gt;따라서, $m$이 충분히 크면 대충 $q$ 정도의 shift는 기대할 수 있으므로, $O(n / q)$ 정도의 퍼포먼스는 기대해 볼 수 있습니다. 당연히 이는 각 글자가 iid random이라는 이루어지지 않는 가정이 들어갔을 뿐만 아니라, 각 위치에서 bad character를 만나는 데 걸리는 매칭개수도 무시하고 있지만, 간단한 argument로는 그럭저럭 기능합니다.&lt;/p&gt;</content><author><name></name></author><category term="advanced-algorithms" /><summary type="html">Contents</summary></entry><entry><title type="html">Amortized Analysis</title><link href="http://localhost:4000/advanced-algorithms/amortized-analysis/" rel="alternate" type="text/html" title="Amortized Analysis" /><published>2021-10-24T00:00:00+09:00</published><updated>2021-10-24T00:00:00+09:00</updated><id>http://localhost:4000/advanced-algorithms/amortized-analysis</id><content type="html" xml:base="http://localhost:4000/advanced-algorithms/amortized-analysis/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#amortized-analysis&quot; id=&quot;markdown-toc-amortized-analysis&quot;&gt;Amortized Analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#three-frameworks&quot; id=&quot;markdown-toc-three-frameworks&quot;&gt;Three frameworks&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#aggregate-method&quot; id=&quot;markdown-toc-aggregate-method&quot;&gt;Aggregate Method&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#accounting-method&quot; id=&quot;markdown-toc-accounting-method&quot;&gt;Accounting Method&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#potential-method&quot; id=&quot;markdown-toc-potential-method&quot;&gt;Potential Method&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamic-table&quot; id=&quot;markdown-toc-dynamic-table&quot;&gt;Dynamic table&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#application&quot; id=&quot;markdown-toc-application&quot;&gt;Application&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;계산이론&lt;/strong&gt; 수업에서 배운 내용 정리. CLRS CH 17.&lt;/p&gt;

&lt;h2 id=&quot;amortized-analysis&quot;&gt;Amortized Analysis&lt;/h2&gt;
&lt;p&gt;우리는 일반적으로 어떤 알고리즘을 분석할 때, $O$, $\Theta$ 같은 asymptotic을 사용해서 분석합니다. 예를 들어, 연산 한번에 $O(n)$ 시간이 들고 그 연산을 $m$번 해야 한다면 전체 시간 복잡도는 $O(nm)$이 될 것입니다.&lt;/p&gt;

&lt;p&gt;이 방법은 유용하지만 어떤 알고리즘들은 이렇게 단순하게 분석할 수 없습니다. 대표적인 예시가 C++의 vector (dynamic array)입니다.&lt;/p&gt;

&lt;p&gt;vector의 모든 연산을 분석하지는 않더라도, 우리는 일단 이 연산을 원합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;맨 뒤에 push하는 연산이 $O(1)$ 비슷한 시간에 작동하기를 원합니다.&lt;/li&gt;
  &lt;li&gt;맨 뒤에서 pop하는 연산이 $O(1)$ 비슷한 시간에 작동하기를 원합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉 우리는 일단은 stack 형태로 생각할 것입니다. 그러나…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;연속한 메모리만 사용하여, 바로 index를 확인할 수 있어야 합니다. stack을 링크드 리스트로 구현하면 위 두가지를 지키기 쉽지만, 대신에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vec[17]&lt;/code&gt; 같은 것을 바로 확인할 수가 없습니다. 동적 배열은 이것이 가능해야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그런데, 이 두 조건은 뭔가 이상합니다. 배열의 원소들이 연속한 메모리를 점유해야 한다면 계속 push를 하다가 언젠가는 더이상 그 위치의 메모리를 쓸 수 없게 되고, 그러면 모든 원소들을 어딘가로 옮겨야 하므로 그때 들어있는 원소의 개수만큼의 시간이 소요될 것입니다. 그러므로, 연속한 메모리를 점유하기 위해선 반드시 $O(n)$ 시간이 걸리는 push가 존재합니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해, vector는 대략 다음과 같은 방법을 씁니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;size와 capacity를 분리합니다. size는 진짜 현재 들어 있는 원소의 개수를, capacity는 할당된 메모리를 말합니다.&lt;/li&gt;
  &lt;li&gt;만약 capacity가 다 차지 않았다면 push가 $O(1)$에 기능하게 하는 것은 쉽습니다.&lt;/li&gt;
  &lt;li&gt;capacity가 다 찼다면, 현재 모든 원소들을 새로운 곳으로 옮기되, capacity가 현재 크기 +1이 아니라 현재의 두 배가 되게 잡습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 하면, move 하는 연산이 가끔씩만 일어나기 때문에, &lt;strong&gt;평균적&lt;/strong&gt;으로는 빠릅니다. 이와 같이, 매 operation의 cost를 생각하는 대신, 여러 operation의 cost를 묶어서 그 평균을 계산하는 방법을 amortized analysis라고 부릅니다.&lt;/p&gt;

&lt;p&gt;주의할 점은, amortized analysis는 average case와는 다르다는 점입니다. 알고리즘 분석은 대부분 worst case를 기준으로 하는데 (최근에는 average case도 많이 나오긴 합니다), amortized worst case 도 생각할 수 있습니다. 한국어로 이를 자연스럽게 바꾸자면, “최악의 경우에도 각 연산은 평균 $O(1)$ 에 작동한다” 입니다. “평균적인 경우에 평균 $O(1)$” 이나, “평균적인 경우에 한번당 $O(1)$” 과는 다른 말입니다.&lt;/p&gt;

&lt;h2 id=&quot;three-frameworks&quot;&gt;Three frameworks&lt;/h2&gt;
&lt;p&gt;Amortized analysis를 하는 방법에는 크게 3가지가 있습니다.&lt;/p&gt;
&lt;h3 id=&quot;aggregate-method&quot;&gt;Aggregate Method&lt;/h3&gt;
&lt;p&gt;$n$번의 연산에 걸리는 시간을 모두 더한 다음, $n$으로 나눕니다. 가장 단순한 방법입니다. 이를 앞서 제시한 vector에 적용해 보겠습니다.&lt;/p&gt;

&lt;p&gt;벡터에 $n$개의 원소를 집어넣는다고 하겠습니다. $n = 2^k$ 일 때는 $2^k$ 의 시간이 들고, 그 외에는 1의 시간이 든다고 가정하면, 전체 시간은 
\(T(n) = n + \sum_{k = 1}^{\log_2 n} 2^k\)
이렇게 될 것입니다. 뒷부분의 $2^k$들의 합을 전부 취하면 $2n$ 이하임을 바로 알 수 있고, 이는 즉 $n$번의 연산이 총합 $3n$ 이상 걸리지 않는다는 것입니다. 따라서 개별 연산은 평균 $O(1)$입니다.&lt;/p&gt;

&lt;h3 id=&quot;accounting-method&quot;&gt;Accounting Method&lt;/h3&gt;
&lt;p&gt;어떤 연산의 실제 cost와는 별개로, 이 연산의 가격을 조금 넉넉하게 할당한 다음, 비싼 연산을 할 때 앞에 쟁여놓은 (?) 여분을 가져다 쓴다고 생각하는 방법입니다.&lt;/p&gt;

&lt;p&gt;역시 vector에 적용해 보겠습니다. $n$개의 원소를 집어넣는데, 개당 보통은 1이 들지만 일단 3이 든다고 생각하겠습니다. Expansion 직후에 남은 credit은 고려하지 않고, 지금 $2^k$개의 원소가 들어있는 테이블에 추가로 $n$개를 집어넣는다고 생각합니다. 이때, 개별 연산을 넉넉하게 3의 시간이 든다고 하면, $2n$어치가 남습니다. 예외적으로, $n$개를 집어넣다가 원소가 $2^{k+1}$ 개가 되면 연산이 실제로는 $2^{k+1}$ 시간이 들게 되는데, 이는 우리가 가정한 cost 3보다 큽니다.&lt;/p&gt;

&lt;p&gt;그러나, 여기까지 오는 길에 우리는 실제로는 1만큼이 걸리는 연산을 3이라고 넉넉하게 잡으면서 $2^k$ 개를 넣어 왔습니다. 즉 $2^{k+1}$ 만큼 여분의 credit이 남았을 것입니다. 이를 이용하여 테이블 확장에 필요한 시간을 지불한다고 생각할 수 있습니다. 이와 같이 적당한 여분을 둔 다음 이를 나중에 사용하는 방법을 Accounting method라 합니다.&lt;/p&gt;

&lt;p&gt;이 방법은 약간 애매한데, 처음에 3이라는 애매한 숫자를 어떻게 잡을지를 알려면 대충 평균적인 연산의 가격을 찍을 수 있어야 합니다. 그래서 증명하기는 어렵지 않지만, 처음 수치를 제시하는 조금…뭐랄까요, 비정형적입니다.&lt;/p&gt;

&lt;h3 id=&quot;potential-method&quot;&gt;Potential Method&lt;/h3&gt;
&lt;p&gt;이 글을 쓰게 된 이유이자, amortized analysis의 핵심입니다.&lt;/p&gt;

&lt;p&gt;이 자료구조의 상태를 나타내는 어떤 potential function $\phi(T)$ 를 생각합니다. 즉, 현재 벡터의 상태를 수치로 환산한다는 것입니다. 이때, 다음과 같은 조건을 만족하고자 합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;초기 상태에 0. 즉, $\phi(T_0) = 0$&lt;/li&gt;
  &lt;li&gt;언제나 $\phi(T_i) \geq 0$. 
(사실 2번 조건은 조금 relax할 수 있지만, 아무튼…)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제, 각 연산은 cost가 들 뿐만 아니라, potential function을 변화시킬 것입니다. $i$번째 연산이 potential function을 변화시키는 양을 $\Delta \phi _i $라 쓰면, 다음이 성립합니다. 
\(\phi_n = \phi_0 + \Delta \phi_1 + \cdots \Delta \phi_{n}\)
어떤 연산의 amortized cost $c_i$를, 실제 cost $r_i$에 potential function 변화량 $\Delta \phi_i$를 더한 값으로 생각합니다. 즉, $c_i = r_i + \Delta \phi_i$.&lt;/p&gt;

&lt;p&gt;$c_i$의 총합과 $r_i$의 총합을 비교하면…
\(\sum c_i = \sum r_i + \sum \Delta \phi_i = \sum r_i + \phi_n - \phi_0 \geq \sum r_i\)
($\phi_n \geq \phi_0 = 0$ 이므로) 따라서, $c_i$의 합을 어느 이하로 바운드를 잡아주면 이 바운드가 실제 cost의 합의 bound가 됩니다.&lt;/p&gt;

&lt;p&gt;vector에 적용해 보겠습니다. vector의 potential은 현재 들어있는 원소의 개수 $n_i$ 와 vector의 크기 $s_i$에 대해, $2n_i - s_i$ 로 정의하기로 하겠습니다. 초기에 벡터에 들어있는 원소가 없을때 약간 정의가 애매한데, 초기의 size를 0으로 잡으면 이 potential function이 위 조건 두개를 만족함을 알 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$r_i$가 size를 변화시키지 않는 연산이라면, 실제 cost가 1이고 potential의 변화는 $s$가 그대로인 채 $n$이 1만큼 증가하여 $\Delta \phi = 2$ 입니다.&lt;/li&gt;
  &lt;li&gt;$r_i$가 size를 변화시킨다면, $n$은 1만큼 증가하는데 $s$가 2배로 증가합니다. 이전에 $s_{i-1} = n_{i-1}$ 이었을 것이므로, 
\((2n_i - s_i) - (2n_{i-1} - s_{i-1}) = (2n_{i-1} + 2 - 2s_{i-1}) - s_{i-1} = 2 - s_{i-1}\)
따라서 $\Delta \phi$ 는 $2 - s_{i-1}$ 입니다. 그런데, 옮겨야 하는 원소는 $s_{i-1}$ 개이고, 새로 추가하는 1개를 고려하면 실제 cost는 $1 + s_{i-1}$ 입니다. 따라서 $c_i = 3$입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두 경우 모두 amortized cost가 $O(1)$ 이므로 전체도 amortized $O(1)$ 입니다.&lt;/p&gt;

&lt;p&gt;일반적으로 $c_i$의 합에 대해 뭔가를 논의하는 것이 쉽도록 $\phi$를 잘 잡는 것을 목표로 합니다. 이 경우는 worst case에도 연산이 한가지밖에 없어서 aggregate로 쉽게 풀 수 있지만, 여기에 delete만 추가하더라도 aggregate로는 분석하기가 굉장히 어렵습니다.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-table&quot;&gt;Dynamic table&lt;/h2&gt;
&lt;p&gt;만약 위 vector에 pop도 지원해야 한다면 어떨까요? 사실 pop은 많이 하더라도 메모리를 침범하지 않아서 그대로 하더라도 시간 복잡도는 유지됩니다. 그런데, 100만개를 넣었다가 다시 100만개를 뺐는데 vector가 그대로 100만칸을 먹고 있는 것은 뭔가 모양새가 나쁩니다. 이 경우에는 table의 크기에 비해 실제 원소의 개수 - 이를 &lt;strong&gt;load factor&lt;/strong&gt; 라고 부릅니다 - 가 너무 나빠서, 메모리 효율이 떨어지는 경우입니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해서는, 원소의 개수가 1/2 이하가 되면 테이블 크기를 반으로 줄이는 방법을 가장 먼저 생각할 수 있습니다. 그러나 이렇게 하면, 원소의 개수를 1/2개 근처로 유지하면서 push와 pop을 반복하면 테이블의 축소와 확대가 여러번 일어나게 만들 수 있고, 축소/확대는 $O(n)$ 연산이므로 &lt;strong&gt;비싼 연산을 가끔씩만 한다는 사실을 이용한다&lt;/strong&gt; 는 amortized 의 개념이 적용되지 않습니다. 실제로 이러면 &lt;strong&gt;worst case amortized&lt;/strong&gt; $O(n)$ 이 됩니다. (Amortized는 average를 내기는 하지만, average case (축소/확대가 랜덤하게 발생) 를 분석하는 것이 아니라 worst case의 average도 분석할 수 있음을 잘 보여주는 사례입니다)&lt;/p&gt;

&lt;p&gt;Load factor를 적절히 유지하면서 amortized $O(1)$을 적용하는 방법은, load factor를 최하 1/4까지 허용하여, 1/4 이하가 되면 테이블 크기를 반으로 줄이는 것입니다.&lt;/p&gt;

&lt;p&gt;이 방법이 amortized complexity $O(1)$ 을 유지한다는 것을 aggregate 같은 방법으로 보이려고 하면 매우 어렵습니다. 어떤 sequence로 연산이 주어지더라도 - 라는 개념을 적용하기가 어렵기 때문입니다. 대신에 potential function으로 다음과 같은 함수를 생각하면
\(\phi = \max(2n_i - s_i, s_i/2 - n_i)\)
이를 잘 이용하여 amortized cost를 바운드할 수 있습니다. 위 함수는 load factor가 1/2 이상일 때와 미만일 때 구간에 따라 정의된 함수이므로, 총 8가지 경우를 분석해야 합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;load factor 1/2 (이상, 이하) 일 때 이를 유지하면서 삽입/삭제하는 경우 4가지&lt;/li&gt;
  &lt;li&gt;load factor 1/2 이하에서 이상으로, 이상에서 이하로 넘어가는 삽입과 삭제 2가지&lt;/li&gt;
  &lt;li&gt;load factor 1/4 이상에서 이하로 떨어져서 축소를 시행하는 삭제&lt;/li&gt;
  &lt;li&gt;load factor 1에서 추가 삽입으로 인해 확대를 시행하는 삽입
정말 하나씩 다 분석하는 것이므로 자세한 과정은 생략합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;application&quot;&gt;Application&lt;/h2&gt;
&lt;p&gt;복잡한 연산을 다양하게 수행하는 자료구조에서 매우 유용합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;피보나치 힙 (예전에 제가 쓴 글도 &lt;a href=&quot;/advanced-algorithms/Fibonacci-heaps&quot;&gt;여기&lt;/a&gt; 있습니다.) 을 이용하여 다익스트라 알고리즘의 시간 복잡도를 $O(V \log V)$ 로 내리기&lt;/li&gt;
  &lt;li&gt;Splay Tree 와 같은 자료구조의 복잡도 분석.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name></name></author><category term="advanced-algorithms" /><summary type="html">Contents</summary></entry><entry><title type="html">Convolutionary Neural Networks : Introduction</title><link href="http://localhost:4000/deep-learning-study/convolutionary-neural-networks/" rel="alternate" type="text/html" title="Convolutionary Neural Networks : Introduction" /><published>2021-10-17T00:00:00+09:00</published><updated>2021-10-17T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/convolutionary-neural-networks</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/convolutionary-neural-networks/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#convolution&quot; id=&quot;markdown-toc-convolution&quot;&gt;Convolution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pooling&quot; id=&quot;markdown-toc-pooling&quot;&gt;Pooling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#convolutionary-neural-network&quot; id=&quot;markdown-toc-convolutionary-neural-network&quot;&gt;Convolutionary Neural Network&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-cnn&quot; id=&quot;markdown-toc-why-cnn&quot;&gt;Why CNN?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#next-posts&quot; id=&quot;markdown-toc-next-posts&quot;&gt;Next posts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 7강 (9월 28일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;매우 유명한 &lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;Standford CS231n 자료&lt;/a&gt; 도 참고하면 좋습니다.&lt;/p&gt;

&lt;h2 id=&quot;convolution&quot;&gt;Convolution&lt;/h2&gt;
&lt;p&gt;Convolution은 수학적으로 굉장히 다양한 대상들에 대해서 잘 정의된 연산인데, 우리는 $n$차원 텐서 (배열) 에 대해서만 생각하겠습니다.&lt;/p&gt;

&lt;p&gt;다음 그림과 같이, Convolution은 Filter 또는 Kernel 이라는 (그림의 노란색 행렬) 을 “밀면서” 내적을 반복해서 새로운 행렬을 얻는 연산입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/86b0e614b1f1445063f784261b4925e98524f0af7c7c3ec0692c3662bb9e631d.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;br /&gt;
&lt;a href=&quot;https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&quot;&gt;이미지 출처 : towardsdatascience.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;일반적으로, 이미지 처리에서 CNN을 가장 많이 쓰기 때문에 CNN의 입력은 3차원 텐서 (배열) 로 가정하고, filter도 3차원 텐서 (배열) 로 가정합니다. 이미지가 2차원임에도 3차원 텐서를 쓰는 이유는 이 텐서의 정체를 보면 알 수 있습니다. 보통은 세 차원을 Channel * Width * Height 으로 부르는데, Channel은 초기 입력 단계에서는 &lt;strong&gt;R G B&lt;/strong&gt; 의 색 정보를 나타냅니다.&lt;/p&gt;

&lt;p&gt;그래서, 3차원 텐서지만 실재로는 여러 채널이 있는 W * H 크기의 행렬의 묶음으로 생각하면 됩니다. $C * W * H$ 입력 이미지에 대해 $C * 3 * 3$ 필터를 쓰게 되면 실제로 공간적으로 필터를 밀어 볼 수 있는 방향은 (가로, 세로) 방향으로만 밀면 되므로, $(W - 2) * (H - 2)$ 크기의 결과를 얻습니다. 그러나 우리는 여러 정보를 동시에 인코딩해서 가져가고 싶기 때문에, 실제로는 동시에 $D$개의 $C * 3 * 3$ 필터를 사용합니다.&lt;/p&gt;

&lt;p&gt;이렇게 해서 얻어진 각 행렬들을 모두 연결하면, $D * (W - 2) * (H - 2)$ 크기의 output을 얻습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Padding :&lt;/strong&gt; 우리가 $W * H$ 크기의 이미지를 가지고 있고, 이 이미지에 $3 * 3$ filter를 convolution하면, $(W - 2) * (H - 2)$ 크기가 된다는 것은 쉽게 알 수 있습니다. 이는 맨 외곽 칸까지 밀게 되면 필터가 이미지 바깥으로 일부가 나가버리기 때문인데, 이를 보정하기 위해 이미지의 맨 외곽선을 0으로 쭉 한칸 더 만들어 주는 방법이 있습니다. 이를 Padding이라고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stride :&lt;/strong&gt; Filter를 평면상에서 “민다” 고 표현했는데, 위 설명은 매번 “한 칸 씩” 미는 경우를 생각하고 있습니다. 꼭 그럴 필요는 없고, $s$칸씩 한번에 밀 수도 있습니다. 그렇게 하면 당연히 출력의 크기는 더 줄어들게 됩니다. 이 $s$를 Stride라 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bias :&lt;/strong&gt; Convolution한 결과물 전체에 어떤 특정한 상수값을 더해줄 수도 있고, 이를 bias라고 부릅니다.&lt;/p&gt;

&lt;p&gt;여기까지 내용의 요약이 다음 image에 잘 드러나 있습니다. &lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;이미지 출처인 Standford CS231n 자료&lt;/a&gt; 에서는 저 필터가 진짜 움직이는걸 볼 수 있으니 한번쯤 보면 이해하기 좋은 것 같습니다. 그림에는 3개 채널의 5 by 5 이미지에, padding 1을 주었고, 3채널 by 3 by 3 크기의 필터를 쓰며, stride = 2 인 케이스를 보여주고 있습니다. 아래에는 bias도 포함되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/67486f42036dc6a5e62931ee5ca802f2c420dc43111f872087eacb39a9417a1c.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;입력이 $C_i * W_i * H_i$ 이고, padding이 $p$, stride가 $s$이며, 크기가 $C_i * F * F$ 인 필터 $K$개를 쓴다고 하면, convolution을 한번 하고 나면 다음과 같이 계산되는 $C_o * W_o * H_o$ 출력을 얻습니다. 
\(C_o = K \quad \quad W_o = \floor{\frac{W_i - F + 2P}{S} + 1} \quad \quad H_o = \floor{\frac{H_i - F + 2P}{S} + 1}\)&lt;/p&gt;

&lt;h2 id=&quot;pooling&quot;&gt;Pooling&lt;/h2&gt;
&lt;p&gt;CNN은 보통 큰 이미지 데이터를 대상으로 하며, 최초에는 이미지를 분류하는 목적으로 개발되었습니다. 그렇다 보니, 이미지 전체의 수만 픽셀의 데이터를 전부 보기보다는 그 특징을 잡아내는 것이 필요합니다. 또한 만약 신경망에서 잡아낼 수 있는 특징을 크게 훼손하지 않으면서 돌아다니는 데이터의 양을 줄일 수 있다면, training 및 inference 시간을 크게 개선할 수 있을 것입니다.&lt;/p&gt;

&lt;p&gt;이를 위해 pooling이라는 연산을 수행합니다. pooling은 단순히 지금 보고 있는 부분의 max나 avg를 택하는 연산인데, 다음 그림을 보면 쉽게 이해할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/f0d16cb834ed161fb9bc6d2930499da42a45d639ef36dcdd8cc51ea8b2f9a0d6.png&quot; alt=&quot;picture 3&quot; /&gt;&lt;br /&gt;
[이미지 출처 : Stanford CS231n]&lt;/p&gt;

&lt;p&gt;위 그림에서 볼 수 있듯, pooling도 convolution처럼 filter라는 표현을 자주 쓰며, stride와 padding을 줄 수 있습니다. 다만 convolution처럼 뭔가를 train할 필요는 없고, 그냥 그 연산을 수행한다고 생각하면 됩니다. 가장 일반적인 형태의 pooling은 2 by 2 필터에 stride 2로 연산하는 것으로, 2 * 2 정사각형에서 max 또는 avg 하나씩을 남김으로서 데이터의 양을 1/4로 줄입니다.&lt;/p&gt;

&lt;p&gt;Pooling은 각 채널별로 독립적으로 실행할 수 있으므로, 2D 에서만 생각해도 충분합니다. 3D pooling도 똑같이 정의하면 생각할 수는 있겠지만요.&lt;/p&gt;

&lt;h2 id=&quot;convolutionary-neural-network&quot;&gt;Convolutionary Neural Network&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;/deep-learning-study/multilayer-perceptron&quot;&gt;Multi Layer Perceptron&lt;/a&gt; 에서는, Linear Layer - Activation - Linear Layer - Activation - … 의 형태로 깊게 이어진 신경망을 구축했고 이를 Multi-Layer Perceptron이라고 불렀습니다.&lt;/p&gt;

&lt;p&gt;Convolutinary Neural Network, CNN도 큰 틀에서는 비슷합니다. 다만, 좀더 복잡한 아이디어들이 들어가 있습니다.&lt;/p&gt;

&lt;p&gt;가장 기본적인 CNN은 크게 Convolution, Pooling, Activation의 세가지 Layer를 잘 반복해서 구성됩니다.&lt;/p&gt;

&lt;p&gt;Convolution은 앞서 설명한 convolution 연산을 적당한 필터에 대해서 수행하는 것으로, MLP에서 weight 행렬이 train의 대상인 것처럼 여기서는 필터 전체가 training의 대상입니다.&lt;/p&gt;

&lt;p&gt;Activation은 MLP에서처럼 모든 항에 적당한 activation function을 씌워서 신경망에 non-linearity를 제공하는 것입니다. 역시 MLP에서와 마찬가지로 ReLU, sigmoid, tanh 같은 함수들을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;Pooling은 앞서 설명한 pooling을 수행하는 layer입니다.&lt;/p&gt;

&lt;h2 id=&quot;why-cnn&quot;&gt;Why CNN?&lt;/h2&gt;
&lt;p&gt;CNN의 효용에 대해 얘기하려면 기존의 MLP의 특징을 먼저 이야기할 필요가 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;장점 : 간단하고, 이론적으로 굉장히 general합니다. 모든 연속함수를 어떤 정해진 구간에서는 충분히 큰 MLP로 approximate 가능하다는 굉장한 정리가 있는데 (Universal Approximation Theorem) 제가 찾아본 증명은 실해석학 수준의 해석학 지식을 (Hahn-Banach, Riesz Repr thm) 요구하기 때문에 다룰 수가 없습니다.&lt;/li&gt;
  &lt;li&gt;단점 : Parameter가 매우 많아서, overfitting의 문제와 training speed 문제가 발생합니다.&lt;/li&gt;
  &lt;li&gt;단점 : Computer vision에 쓰기에는 shift invariance 같은 것을 잘 처리하지 못한다는 심각한 문제가 있습니다. 특히 image classification 같은 경우, 이미지의 일부를 shift해도 그대로 같은 이미지인데 MLP는 이를 처리하기 어렵습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Convolution은 그 자체로 shift invaraince를 가지기 때문에, 단점 2번을 잘 해결합니다. 또한, 단점 1번의 경우, Convolution의 파라미터가 꽤 많아 보이지만 $W * H$ 이미지를 던져주고 $W * H$ 출력을 만들기 위해서 Linear layer는 파라미터 $W^2H^2$ 개가 필요합니다. 입출력이 200 by 200이면 이 값이 16억인데, convolution은 파라미터가 훨씬 적습니다.&lt;/p&gt;

&lt;p&gt;자연스러운 질문은, 파라미터가 그렇게 적으면 충분히 general하게 학습하지 못하는게 아니냐는 의문이 들 수 있습니다. &lt;a href=&quot;https://arxiv.org/abs/1804.10306&quot;&gt;2018년 논문&lt;/a&gt; 에 따르면 수학적으로는 CNN도 universal approximation theorem이 있다고 하는데, 굳이 이런 놀라운 수학적 결과를 들이밀지 않더라도 이미지 처리에서 CNN이 그동안 보여준 놀라운 성과를 보면 이정도 파라미터로도 Convolution 자체가 어떤 이미지를 ‘대략적으로’ 보는 느낌이 굉장히 직관적으로 좋아서, 잘 작동하는 것으로 보입니다.&lt;/p&gt;

&lt;p&gt;또한, CNN은 MLP보다 같은 크기에서 훨씬 깊은 네트워크를 만들 수 있습니다 (레이어당 파라미터가 적으므로) 이 점도 장점이 될 수 있겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;next-posts&quot;&gt;Next posts&lt;/h2&gt;
&lt;p&gt;CNN의 여러 Model들에 대해 살펴볼 계획입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;LeNet&lt;/li&gt;
  &lt;li&gt;AlexNet&lt;/li&gt;
  &lt;li&gt;VGGNet&lt;/li&gt;
  &lt;li&gt;GoogLeNet&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/deep-learning-study/semantic-segmentation&quot;&gt;Semantic Segmentation&lt;/a&gt; 에서 다룰 모델들.
    &lt;ul&gt;
      &lt;li&gt;U-Net&lt;/li&gt;
      &lt;li&gt;FCN&lt;/li&gt;
      &lt;li&gt;DeepLab&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="deep-learning-study" /><summary type="html">Contents Convolution Pooling Convolutionary Neural Network Why CNN? Next posts 심층 신경망의 수학적 기초 7강 (9월 28일) 에 기반합니다. 매우 유명한 Standford CS231n 자료 도 참고하면 좋습니다. Convolution Convolution은 수학적으로 굉장히 다양한 대상들에 대해서 잘 정의된 연산인데, 우리는 $n$차원 텐서 (배열) 에 대해서만 생각하겠습니다. 다음 그림과 같이, Convolution은 Filter 또는 Kernel 이라는 (그림의 노란색 행렬) 을 “밀면서” 내적을 반복해서 새로운 행렬을 얻는 연산입니다. 이미지 출처 : towardsdatascience.com 일반적으로, 이미지 처리에서 CNN을 가장 많이 쓰기 때문에 CNN의 입력은 3차원 텐서 (배열) 로 가정하고, filter도 3차원 텐서 (배열) 로 가정합니다. 이미지가 2차원임에도 3차원 텐서를 쓰는 이유는 이 텐서의 정체를 보면 알 수 있습니다. 보통은 세 차원을 Channel * Width * Height 으로 부르는데, Channel은 초기 입력 단계에서는 R G B 의 색 정보를 나타냅니다. 그래서, 3차원 텐서지만 실재로는 여러 채널이 있는 W * H 크기의 행렬의 묶음으로 생각하면 됩니다. $C * W * H$ 입력 이미지에 대해 $C * 3 * 3$ 필터를 쓰게 되면 실제로 공간적으로 필터를 밀어 볼 수 있는 방향은 (가로, 세로) 방향으로만 밀면 되므로, $(W - 2) * (H - 2)$ 크기의 결과를 얻습니다. 그러나 우리는 여러 정보를 동시에 인코딩해서 가져가고 싶기 때문에, 실제로는 동시에 $D$개의 $C * 3 * 3$ 필터를 사용합니다. 이렇게 해서 얻어진 각 행렬들을 모두 연결하면, $D * (W - 2) * (H - 2)$ 크기의 output을 얻습니다. Padding : 우리가 $W * H$ 크기의 이미지를 가지고 있고, 이 이미지에 $3 * 3$ filter를 convolution하면, $(W - 2) * (H - 2)$ 크기가 된다는 것은 쉽게 알 수 있습니다. 이는 맨 외곽 칸까지 밀게 되면 필터가 이미지 바깥으로 일부가 나가버리기 때문인데, 이를 보정하기 위해 이미지의 맨 외곽선을 0으로 쭉 한칸 더 만들어 주는 방법이 있습니다. 이를 Padding이라고 합니다. Stride : Filter를 평면상에서 “민다” 고 표현했는데, 위 설명은 매번 “한 칸 씩” 미는 경우를 생각하고 있습니다. 꼭 그럴 필요는 없고, $s$칸씩 한번에 밀 수도 있습니다. 그렇게 하면 당연히 출력의 크기는 더 줄어들게 됩니다. 이 $s$를 Stride라 합니다. Bias : Convolution한 결과물 전체에 어떤 특정한 상수값을 더해줄 수도 있고, 이를 bias라고 부릅니다. 여기까지 내용의 요약이 다음 image에 잘 드러나 있습니다. 이미지 출처인 Standford CS231n 자료 에서는 저 필터가 진짜 움직이는걸 볼 수 있으니 한번쯤 보면 이해하기 좋은 것 같습니다. 그림에는 3개 채널의 5 by 5 이미지에, padding 1을 주었고, 3채널 by 3 by 3 크기의 필터를 쓰며, stride = 2 인 케이스를 보여주고 있습니다. 아래에는 bias도 포함되어 있습니다. 입력이 $C_i * W_i * H_i$ 이고, padding이 $p$, stride가 $s$이며, 크기가 $C_i * F * F$ 인 필터 $K$개를 쓴다고 하면, convolution을 한번 하고 나면 다음과 같이 계산되는 $C_o * W_o * H_o$ 출력을 얻습니다. \(C_o = K \quad \quad W_o = \floor{\frac{W_i - F + 2P}{S} + 1} \quad \quad H_o = \floor{\frac{H_i - F + 2P}{S} + 1}\) Pooling CNN은 보통 큰 이미지 데이터를 대상으로 하며, 최초에는 이미지를 분류하는 목적으로 개발되었습니다. 그렇다 보니, 이미지 전체의 수만 픽셀의 데이터를 전부 보기보다는 그 특징을 잡아내는 것이 필요합니다. 또한 만약 신경망에서 잡아낼 수 있는 특징을 크게 훼손하지 않으면서 돌아다니는 데이터의 양을 줄일 수 있다면, training 및 inference 시간을 크게 개선할 수 있을 것입니다. 이를 위해 pooling이라는 연산을 수행합니다. pooling은 단순히 지금 보고 있는 부분의 max나 avg를 택하는 연산인데, 다음 그림을 보면 쉽게 이해할 수 있습니다. [이미지 출처 : Stanford CS231n] 위 그림에서 볼 수 있듯, pooling도 convolution처럼 filter라는 표현을 자주 쓰며, stride와 padding을 줄 수 있습니다. 다만 convolution처럼 뭔가를 train할 필요는 없고, 그냥 그 연산을 수행한다고 생각하면 됩니다. 가장 일반적인 형태의 pooling은 2 by 2 필터에 stride 2로 연산하는 것으로, 2 * 2 정사각형에서 max 또는 avg 하나씩을 남김으로서 데이터의 양을 1/4로 줄입니다. Pooling은 각 채널별로 독립적으로 실행할 수 있으므로, 2D 에서만 생각해도 충분합니다. 3D pooling도 똑같이 정의하면 생각할 수는 있겠지만요. Convolutionary Neural Network Multi Layer Perceptron 에서는, Linear Layer - Activation - Linear Layer - Activation - … 의 형태로 깊게 이어진 신경망을 구축했고 이를 Multi-Layer Perceptron이라고 불렀습니다. Convolutinary Neural Network, CNN도 큰 틀에서는 비슷합니다. 다만, 좀더 복잡한 아이디어들이 들어가 있습니다. 가장 기본적인 CNN은 크게 Convolution, Pooling, Activation의 세가지 Layer를 잘 반복해서 구성됩니다. Convolution은 앞서 설명한 convolution 연산을 적당한 필터에 대해서 수행하는 것으로, MLP에서 weight 행렬이 train의 대상인 것처럼 여기서는 필터 전체가 training의 대상입니다. Activation은 MLP에서처럼 모든 항에 적당한 activation function을 씌워서 신경망에 non-linearity를 제공하는 것입니다. 역시 MLP에서와 마찬가지로 ReLU, sigmoid, tanh 같은 함수들을 쓸 수 있습니다. Pooling은 앞서 설명한 pooling을 수행하는 layer입니다. Why CNN? CNN의 효용에 대해 얘기하려면 기존의 MLP의 특징을 먼저 이야기할 필요가 있습니다. 장점 : 간단하고, 이론적으로 굉장히 general합니다. 모든 연속함수를 어떤 정해진 구간에서는 충분히 큰 MLP로 approximate 가능하다는 굉장한 정리가 있는데 (Universal Approximation Theorem) 제가 찾아본 증명은 실해석학 수준의 해석학 지식을 (Hahn-Banach, Riesz Repr thm) 요구하기 때문에 다룰 수가 없습니다. 단점 : Parameter가 매우 많아서, overfitting의 문제와 training speed 문제가 발생합니다. 단점 : Computer vision에 쓰기에는 shift invariance 같은 것을 잘 처리하지 못한다는 심각한 문제가 있습니다. 특히 image classification 같은 경우, 이미지의 일부를 shift해도 그대로 같은 이미지인데 MLP는 이를 처리하기 어렵습니다. Convolution은 그 자체로 shift invaraince를 가지기 때문에, 단점 2번을 잘 해결합니다. 또한, 단점 1번의 경우, Convolution의 파라미터가 꽤 많아 보이지만 $W * H$ 이미지를 던져주고 $W * H$ 출력을 만들기 위해서 Linear layer는 파라미터 $W^2H^2$ 개가 필요합니다. 입출력이 200 by 200이면 이 값이 16억인데, convolution은 파라미터가 훨씬 적습니다. 자연스러운 질문은, 파라미터가 그렇게 적으면 충분히 general하게 학습하지 못하는게 아니냐는 의문이 들 수 있습니다. 2018년 논문 에 따르면 수학적으로는 CNN도 universal approximation theorem이 있다고 하는데, 굳이 이런 놀라운 수학적 결과를 들이밀지 않더라도 이미지 처리에서 CNN이 그동안 보여준 놀라운 성과를 보면 이정도 파라미터로도 Convolution 자체가 어떤 이미지를 ‘대략적으로’ 보는 느낌이 굉장히 직관적으로 좋아서, 잘 작동하는 것으로 보입니다. 또한, CNN은 MLP보다 같은 크기에서 훨씬 깊은 네트워크를 만들 수 있습니다 (레이어당 파라미터가 적으므로) 이 점도 장점이 될 수 있겠습니다. Next posts CNN의 여러 Model들에 대해 살펴볼 계획입니다. LeNet AlexNet VGGNet GoogLeNet Semantic Segmentation 에서 다룰 모델들. U-Net FCN DeepLab</summary></entry><entry><title type="html">ICPC Korea First Round 2021 후기 / 풀이</title><link href="http://localhost:4000/cp-rounds/icpc-2021-prelim/" rel="alternate" type="text/html" title="ICPC Korea First Round 2021 후기 / 풀이" /><published>2021-10-14T00:00:00+09:00</published><updated>2021-10-14T00:00:00+09:00</updated><id>http://localhost:4000/cp-rounds/icpc-2021-prelim</id><content type="html" xml:base="http://localhost:4000/cp-rounds/icpc-2021-prelim/">&lt;div id=&quot;toc&quot;&gt;
Contents
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#preperation--our-team&quot; id=&quot;markdown-toc-preperation--our-team&quot;&gt;Preperation / Our Team&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#본-대회&quot; id=&quot;markdown-toc-본-대회&quot;&gt;본 대회&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-i--sport-climbing-combined&quot; id=&quot;markdown-toc-problem-i--sport-climbing-combined&quot;&gt;Problem I : Sport Climbing Combined&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-e--histogram&quot; id=&quot;markdown-toc-problem-e--histogram&quot;&gt;Problem E : Histogram&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-j--ten&quot; id=&quot;markdown-toc-problem-j--ten&quot;&gt;Problem J : Ten&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-h--similarity&quot; id=&quot;markdown-toc-problem-h--similarity&quot;&gt;Problem H : Similarity&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-b--carrot-field&quot; id=&quot;markdown-toc-problem-b--carrot-field&quot;&gt;Problem B : Carrot Field&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-k--treasure-hunter&quot; id=&quot;markdown-toc-problem-k--treasure-hunter&quot;&gt;Problem K : Treasure Hunter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-c--colorful-tower-of-hanoi&quot; id=&quot;markdown-toc-problem-c--colorful-tower-of-hanoi&quot;&gt;Problem C : Colorful Tower of Hanoi&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#retrospect&quot; id=&quot;markdown-toc-retrospect&quot;&gt;Retrospect&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#about-problemset--our-result&quot; id=&quot;markdown-toc-about-problemset--our-result&quot;&gt;About Problemset / Our result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#about-my-icpc&quot; id=&quot;markdown-toc-about-my-icpc&quot;&gt;About my ICPC&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#대회를-마치며&quot; id=&quot;markdown-toc-대회를-마치며&quot;&gt;대회를 마치며&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;Little Piplup 팀으로 복귀해서 ICPC 2021을 재밌게 치고 왔습니다.&lt;/p&gt;

&lt;p&gt;늘 대회가 끝나고 나면 Whining을 해왔지만, 이번 대회는 솔직히 말하면 Whining할게 별로 없습니다. 18등의 성적을 거두었는데, &lt;strong&gt;풀었어야 할 문제&lt;/strong&gt; 는 다 풀지 않았나 싶습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/ffc1cbe195617fa7de716c8086404b340a6b3419bdc0e214ec7e660b077149b5.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Prep - 대회과정 타임라인에 따른 의식의 흐름 - Retrospect의 순서로 작성합니다.&lt;/p&gt;

&lt;p&gt;평소보다 앞뒤 글이 많이 길고 장황하기 때문에, 왼쪽 아래 Table of Content를 보면 문제에 대한 이야기만 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;preperation--our-team&quot;&gt;Preperation / Our Team&lt;/h2&gt;
&lt;p&gt;팀연습 두번을 했습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;GCPC 2020 : &lt;a href=&quot;/cp-rounds/team-practice-gcpc-2020/&quot;&gt;팀연습 기록 링크&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;BAPC 2020 (기록 미작성)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 팀의 객관적인 전력을 저는 개인적으로 적어도 2100 3명 정도 수준, 내지는 문제셋을 조금 잘 타면 1레드가 섞인 팀과도 비벼볼 수 있다고 생각합니다. 가장 최근의 팀 대회는 Hashcode 2021이었는데, 그때와 지금 팀을 비교하면 (dlwocks31의 부재를 제외하고 세명만) 크게 달라진 것은 없으므로 그때 썼던 기록에 더하여 팀원들에 대한 얘기를 조금 해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Gratus907&lt;/code&gt; : 수학적인 문제에 비교적 강하고, 말리지 않을때까지는 구현이 빠르지만 말리면 한없이 말리는 경향이 있습니다.
    &lt;ul&gt;
      &lt;li&gt;그래도 제 코딩 경험이 쌓이면서 예전만큼 코딩이 말리지 않습니다.&lt;/li&gt;
      &lt;li&gt;반면에, 한번 어떤 방면으로 빠지면 무한한 뇌절을 이어가는 경향이 있습니다. 이는 &lt;a href=&quot;/cp-rounds/SCPC-2021-Round2&quot;&gt;FFT에 패배한 SCPC 2021&lt;/a&gt; 같은 상황에서 정말 끔찍했습니다.&lt;/li&gt;
      &lt;li&gt;수학 복수전공을 통해 얻은 지식은 딱히 PS에 도움이 되지 않지만, 씹덕같은 정수론 문제 한두개를 가끔 쳐낼 수 있는것 같습니다.&lt;/li&gt;
      &lt;li&gt;아카데믹한 알고리즘 공부를 그래도 이중에 가장 많이 했었습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DHDroid&lt;/code&gt; : Constructive한 문제에 매우 강하고, 관찰을 정당화 (증명) 하는 능력이 뛰어납니다.
    &lt;ul&gt;
      &lt;li&gt;이 능력을 실제로 보여준 대회가 역시 SCPC 2021입니다. Round 2 하노이탑에서 일부 레드들도 달성을 어려워했던 250점을 달성하고, 저보다 훨씬 높은 성적으로 2라운드를 마친후 본선에서 5등상을 받는 쾌거를 보여줬습니다.&lt;/li&gt;
      &lt;li&gt;본인의 표현을 빌리자면 정말 어려운 문제에 도전해서 몇 시간 고민을 이어가는 본인의 연습방식이 도움이 된다고 합니다.&lt;/li&gt;
      &lt;li&gt;학과 동기이고 친구지만 이렇게 어려운 문제를 대하는 자세를 보면서 항상 많은 것을 배웁니다.&lt;/li&gt;
      &lt;li&gt;반대로 제한시간이 짧은 대회에 살짝 약합니다. 2시간짜리 코드포스가 가장 대표적이죠.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coffeetea&lt;/code&gt; : 그리디하거나 휴리스틱한 관찰, 대략적인 경향성의 파악에 강합니다. 뭔가 문제에 빙의하는 특성이 있어서 글쓸때 Coffeetea의 표현을 많이 빌리게 됩니다 :)
    &lt;ul&gt;
      &lt;li&gt;저는 그때 이 팀에 없었지만, &lt;a href=&quot;https://www.acmicpc.net/problem/20041&quot;&gt;작년 ICPC F번&lt;/a&gt; 같은 문제에서 가장 잘 느낄 수 있습니다. (이 문제는 그렇게 어렵지 않지만요)&lt;/li&gt;
      &lt;li&gt;Hashcode 스타일의 대회에서 초기 아이디어를 정말 잘 던져주고, 데이터를 슥 보고 특성을 빠르게 캐치합니다.&lt;/li&gt;
      &lt;li&gt;많이 복잡한 구현은 저보다 잘 합니다. 저보다 좀더 구현에 대해 체계적으로 고민하고, 놓치는 케이스가 비교적 적으며, 디버깅할때의 끈기와 자세가 뛰어납니다. 역시 항상 많은 것을 배우게 되는 친구입니다.&lt;/li&gt;
      &lt;li&gt;개발 공부에 많은 시간과 노력을 투자했기 때문에 이런 구현 실력을 갖춘 것 같은데, 반대로 소위 ‘고인물 알고리즘’ 에 대한 공부를 많이 하지는 않았습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;대회 시작 전날까지 팀노트를 작년 제 팀노트에 얹어서 나름대로 열심히 준비했습니다. 후술하지만, 약간의 부족함은 있었습니다.&lt;/p&gt;

&lt;p&gt;팀노트를 준비할 때 생각해야 하는 기준은, (보편 타당한 생각을 제가 나름대로 표현해 보자면) “어 이거 그건데” 와 AC를 받는 시점 사이의 시간의 expectation을 minimize하는 것입니다. 이 말의 의미는, 구현 실수가 날만한 부분들이나 구현이 복잡한 자료구조, 알지만 구글링 없이는 코딩이 불가능한 알고리즘 등을 적어 가야 한다는 것입니다. 저희 팀을 예로 들자면&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;수많은 기하 구현을 준비했습니다. 대회 시간 중에 선분 - 선분 교차를 구현해 보셨나요? ㅋㅋ!&lt;/li&gt;
  &lt;li&gt;segment tree에서 lazy propagation의 개념은 잘 알고 있으나 구현시 실수할 것을 대비하여 적어 갔습니다.&lt;/li&gt;
  &lt;li&gt;Dinic과 HeavyLight Decomposition 등을 적어 갔습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;25페이지는 효율적으로 잘 꾹꾹 눌러 쓰면 생각보다 꽤 많습니다. 저희 팀노트는 [링크] 에서 볼 수 있는데, ICPC 전날 급하게 많은 것을 추가하느라 외관의 아름다움을 많이 잃어버렸습니다만 앞으로 계속 업데이트될 것입니다 (제 개인적으로는 archive의 의미가 있어서요.)&lt;/p&gt;

&lt;p&gt;팀노트 맨 끝장에는 Checkpoint를 붙여 갔습니다. 이 체크포인트는 제가 계속 관리하고 있는 노트인데, 제가 나가는 팀대회에서는 팀노트 맨 끝장에 붙여 나갑니다. 
&lt;img src=&quot;../../images/3767c2dd32cfce8f0d2abd4a81f13d248d4a154766ffde8e9929c218b5ebfe59.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;br /&gt;
(이미지를 우클릭-새 탭으로 열기해서 큰 화면으로 볼 수 있습니다)&lt;/p&gt;

&lt;p&gt;모든 포인트들은 제가 문제를 풀면서 경험해본 것들입니다. PS 오답노트라고나 할까요.&lt;/p&gt;

&lt;h2 id=&quot;본-대회&quot;&gt;본 대회&lt;/h2&gt;

&lt;p&gt;저희는 스터디카페에서 대회를 치렀기 때문에, 문제지가 뜨는걸 확인하는 즉시 제가 인쇄를 하러 나가면서 팀원들이 화면을 반으로 나눠서 A, B를 읽었습니다. 문제지 인쇄까지는 프린터가 느린데다 문제지 합본 pdf 파일이 바로 넘어오지 않아서, 거의 7분 가까운 시간이 소요되었습니다. 그러나 문제지를 인쇄하는 프린터 앞에 서서 저도 문제를 볼 수 있었기 때문에 실질적인 시간상의 로스는 거의 없습니다. 대회 규정상 팀원 1인 이상이 오랜 시간 자리를 비워서는 안되고 (아마도 이 규정이 strictly enforce되는 것은 어차피 기술적으로 불가능했을 것입니다만), 팀원들의 효율을 위해 문제지가 1/3정도 인쇄될 때마다 제가 계속 팀원들에게 배달했습니다.&lt;/p&gt;

&lt;p&gt;그 사이에, I번의 첫 Solve들이 등장하기 시작했습니다. 처음에 어떻게 다른 팀들이 12문제 중 9번째에 있는 문제를 찾아내서 풀었는지 의아했지만, 생각해보니 4/4/4로 분배하면 팀원중 한명에게는 가장 먼저 읽는 문제니까 그런것 같습니다. (그럼에도 약간의 의문이 있습니다. 찾아보니 작년에도 I번이 가장 쉬운 문제였고, 그 전까지는 등록이 있는 자리였는데 혹시 그 사실을 인지하고 있는 팀들이 있을까요?)&lt;/p&gt;

&lt;p&gt;인쇄 중에 저는 팀원들이 A, B 부터 읽고 있음을 감안하여 적당히 몇개 떼고 E를 읽었습니다. 한국어길래 슬쩍 B, C도 한번씩 읽었는데 B는 딱봐도 구현이 노답이고 C는 엄청나게 어려워 보였기 때문에… 제가 인쇄를 마치면서 2시 8분쯤 방에 복귀했는데, 이미 팀원들이 I번을 읽고 솔루션을 제시했으며 B가 구현 노답이라는 사실도 인지하고 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-i--sport-climbing-combined&quot;&gt;Problem I : Sport Climbing Combined&lt;/h3&gt;
&lt;p&gt;Solve : DHdroid&lt;br /&gt;
Code : DHDroid&lt;/p&gt;

&lt;p&gt;무슨 문제인지 방금 처음 읽었는데, 딱히 할말이 없습니다. $p_i \times q_i \times r_i$를 기준으로 정렬해서 그 $b_i$를 출력하면 됩니다. 13분에 AC를 받았습니다.&lt;/p&gt;

&lt;p&gt;이때 저는 E번의 풀이가 간단한 $O(B N^2)$ DP로 가능하다는 것을 이미 인지했기 때문에 ($30 * 4000^2$ 이면 4.8억이지만 실제로는 그 절반만 써서 괜찮습니다), 바로 제가 E를 잡겠다고 주장했습니다. 아무도 E를 풀지 않았다는 사실이 좀 마음에 걸리지만…&lt;/p&gt;

&lt;h3 id=&quot;problem-e--histogram&quot;&gt;Problem E : Histogram&lt;/h3&gt;
&lt;p&gt;Solve : Gratus907&lt;br /&gt;
Code : Gratus907&lt;/p&gt;

&lt;p&gt;배열을 최대 B개의 구간으로 나누어, 각 구간에서의 분산의 합을 최소화하는 문제입니다. $n$이 더 커지면 DP 최적화 기법 등을 생각해 볼 수 있겠지만, 이정도는 $B \times N$ 테이블을 칸당 $O(N)$ 에 구해도 충분합니다.&lt;/p&gt;

&lt;p&gt;먼저, 어떤 구간 $[j, i]$ 의 분산 $V(j, i)$ 을 $O(1)$에 구할 수 있다면, 이 문제는 간단히 다음과 같이 환원됩니다.
\(D(b, i) = \min_{j &amp;lt; i} V(j, i) + D(b-1, j-1)\)
그런데, 분산은 원소의 합과 제곱의 합을 안다면 $O(1)$에 구할 수 있고 (제평-평제 공식), 이는 prefix sum으로 최적화 가능한 문제입니다.&lt;/p&gt;

&lt;p&gt;이 문제의 구현은 금방 했지만, 실수로 n을 써야 할 자리에 MAXN 인 4000을 써넣어서 한번 틀렸습니다. 이후 이를 바로 캐치하고, 고쳤으나 맥북에 연결한 외장 키보드의 단축키가 익숙하지 않아서(변명같겠지만 진짜입니다….) 제출과 동시에 어 저장 안된거 아닌가? 라는 비명을 지르며 1번 더 틀리고 2틀 후 23분에 AC를 받았습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;저희 팀이 이 문제 First Solve를 받았습니다. 개인적으로 ICPC같은 큰 대회에서 퍼솔은 처음이라 굉장히 기분이 좋았습니다. ㅋㅋ!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이제, Coffeetea가 ‘B번은 미친듯이 케이스를 나눠야 한다. 일단 구현을 시작하겠지만 누군가 짤게있으면 바로 인터셉트해서 다른거 구현 하는게 좋겠다’ 는 말을 했고, 곧 DHDroid가 J를 바로 짤수있다고 선언해서 컴퓨터를 내줬습니다.&lt;/p&gt;

&lt;p&gt;추가로, 저는 A번을 읽고 바로 ‘수쿼 어딘가에 있을 법한 문제다’, ‘Mo’s Algorithm으로 풀 수 있을 것 같은데, 내가 그거 구현을 못한다. 정확히 이해한게 아니라서 팀노트에도 못적어왔다’ 고 말했습니다. 이때 또 웰노운 당했다는 생각에 굉장히 화가 났습니다. ㅋㅋ…&lt;/p&gt;

&lt;h3 id=&quot;problem-j--ten&quot;&gt;Problem J : Ten&lt;/h3&gt;
&lt;p&gt;Solve : DHDroid &lt;br /&gt;
Code : DHDroid&lt;/p&gt;

&lt;p&gt;숫자가 가득 주어지고 합이 10이 되는 직사각형의 개수를 세는 문제입니다. 일반적으로는 모든 직사각형을 볼 수 없으나, 이 문제에서는 각 숫자가 1 이상이다보니 크기가 10을 넘는 직사각형들을 볼 필요가 없어서 bruteforce할 수 있습니다. DHDroid가 2차원 부분합 잘 짜냐고 물어봐서 못한다고 대답하니까 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;아니;;;&lt;/code&gt; 이러면서 알아서 잘 짜더군요…ㅋㅋㅋ 40분 AC.&lt;/p&gt;

&lt;p&gt;이시점 저희의 순위는 최상위권이었기 때문에 (정확히 40분 시점에 저희는 E, I, J를 풀었고, 3솔 팀 다섯 팀이 각각 E, E, B, H, K를 풀었으며 4솔 이상 팀이 없어서 &lt;strong&gt;저희는 5등이었습니다&lt;/strong&gt;) 스코어보드를 보고 다음 풀 문제를 바로 알 수 없었고, B번의 케이스를 열심히 나누던 coffeetea와 제가 좀 얘기를 해보니까 H번을 금방 풀 수 있을 것 같았습니다. 제가 풀이의 확실함을 잠깐 고민하는 동안 Coffeetea가 한 7~8분? 정도 코딩을 좀 하다가, 제가 H번 풀 수 있다고 말해서 바로 바꿨습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-h--similarity&quot;&gt;Problem H : Similarity&lt;/h3&gt;
&lt;p&gt;Solve : Gratus907, Coffeetea (B번에 대해 생각하느라 많은 참여는 못했습니다)&lt;br /&gt;
Code : Gratus907&lt;/p&gt;

&lt;p&gt;두 배열 $P, Q$가 주어졌을 때, $p_i &amp;lt; p_j &amp;lt; p_k$ 이면서 $q_i &amp;lt; q_j &amp;lt; q_k$ 인 인덱스 $(i, j, k)$ 의 개수를 세는 문제입니다.&lt;/p&gt;

&lt;p&gt;$i$번째 인덱스를 점 $(p_i, q_i)$로 표현해 보겠습니다. 그렇다면, 2차원 배열 위에서, 우리가 원하는 인덱스들은 나의 ‘왼쪽 아래’ 직사각형에 있는 점들과, ‘오른쪽 위’ 직사각형에 있는 점들입니다. 즉 2차원 평면에서 어떤 직사각형 안에 점이 몇 개 있는지를 빠르게 셀 수 있다면 - 구체적으로, 내 ‘왼쪽 아래’ 와 ‘오른쪽 위’ 직사각형 - 이 문제를 풀 수 있습니다.&lt;/p&gt;

&lt;p&gt;언뜻 생각하면 2D segment tree 같은게 필요할 것 같지만, 잘 알려진 테크닉으로 이를 1D 세그만으로 할 수 있습니다. 세그먼트 트리는 업데이트 순서에 영향을 받기 때문에, 축 하나의 정보를 ‘업데이트 순서’ 를 이용해서 표현하는 것입니다. $x$좌표를 이용한 세그먼트 트리를 구현하되, $y$좌표가 큰 원소부터 업데이트한다고 하겠습니다. 이때, 어떤 점을 업데이트하기 직전에 $[x+1, \infty]$ 의 쿼리를 날려서 점의 개수를 세면, 아직 나보다 아래 있는 점은 업데이트를 안 했기 때문에 실제로 보이는 공간은 내 오른쪽 반평면이 아니라 내 오른쪽 위 사분면입니다. 이를 두개 이용해서 우상단과 좌하단을 각각 세면 됩니다. 같은 $y$좌표인 경우 누가 누구를 볼 수 있어야 하는지를 고려하면 되는데 여기서는 $x$좌표가 작은쪽부터 업데이트해주면 됩니다. 왼쪽에 있는 원소가 오른쪽 원소를 보게되면 ‘오른쪽 위’ 가 아니라 ‘오른쪽’ 인데도 포함하는 경우가 있어서, 왼쪽 원소는 자기랑 $y$좌표가 같고 $x$좌표가 큰 원소를 볼 수 없어야 합니다.&lt;/p&gt;

&lt;p&gt;여름에 다른학교 컴공과에 다니는 여자친구랑 세그먼트 트리, DP, 그래프 같은 주제 몇개로 플레 문제 일주일에 5-10개씩 밀었는데 &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, 그때 비슷한 문제를 풀어 봤습니다. &lt;a href=&quot;/ps-weekly/ps-weekly-21Jul1/&quot;&gt;링크&lt;/a&gt; 에 있는 ‘북서풍’, ‘여우가 정보섬에 올라온 이유’ 등 문제들에서 똑같이 쓰입니다. 72분에 AC를 받았습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;대회시간의 대략 40%가 지난 지금, 잠시 전체 상황을 조망해보자면&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;4 Solve. 1등은 6솔브, 2/3등은 5솔브로 최상위팀인 서울대 팀은 저희 + B, C를 풀었고, KAIST 팀과 다른 서울대 팀 하나가 각각 저희보다 K를 추가 / (B, C) 를 풀고 H 미해결인 상태였습니다. 많이 틀려서 페널티를 쌓기는 했지만, 대회 시간 40% 시점까지 상위권 솔브수를 따라붙을 수 있었습니다.&lt;/li&gt;
  &lt;li&gt;B번은 Coffeetea가 ‘충분한 시간이 주어지면 풀 수 있다’ 는 식으로 말했는데, 이게 참 어려운 말입니다. 반대로 ‘충분한 시간이 주어지지 않는’ 경우도 고려해야 합니다.&lt;/li&gt;
  &lt;li&gt;K번은 DHDroid가 고민을 좀 해보고 있었는데, ‘그리디일텐데… 복잡도가…’ 정도 상황이었습니다.&lt;/li&gt;
  &lt;li&gt;다른 문제에 대해서는 솔직하게 No clue. 저는 C번을 읽어봤기에, 최상위권 팀들이 C를 풀었다는 점 + 일부 4솔팀들이 H, 심지어 E보다도 C를 먼저 풀었다는 점이 좀 신기했습니다.&lt;/li&gt;
  &lt;li&gt;객관적으로 이때의 4솔팀들중에는 2400급 강팀들도 있지만, 2019-2020 시즌 Cafe mountain처럼 말도안되는 팀은 없는 것으로 알기 때문에 이들의 액션은 유의미합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이것들을 고려해서, 다시 Coffeetea가 키보드를 잡은채로 저희는 K를 풀고자 했습니다. 대회가 끝날 때까지 아마도 B, K는 풀 수 있을것 같았고, 하나 더 풀면 괜찮은 등수가 나오지 않겠느냐는 말을 했습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-b--carrot-field&quot;&gt;Problem B : Carrot Field&lt;/h3&gt;
&lt;p&gt;Solve : Coffeetea&lt;br /&gt;
Code : Coffeetea&lt;/p&gt;

&lt;p&gt;중학교 1학년 수학 교재를 보면, 말 같은걸 직사각형 한 점에 길이가 $L$인 줄로 묶어놓고 그 말이 움직일 수 있는 부분의 넓이를 구하는 문제가 많이 나옵니다. 그거랑 똑같은데, 대신에 격자점의 개수를 구하는 문제입니다. 
&lt;img src=&quot;../../images/9f32a25e45ffeac8ca959f5feb433785802b04c6cdd47724d613900ee6c924c7.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;br /&gt;
언뜻 보면 충격적으로 쉬워 보이지만, 이 문제가 끔찍한 점은 경우를 나눠야 한다는 것입니다. 편의상 $w \geq h$ 를 가정한다고 할 때, 크게 $L &amp;lt; h$ 인 경우 (원의 3/4 만큼), $h &amp;lt; L &amp;lt; w$ 인 경우 (이때는 가로쪽으로는 딱 사분원만큼을 먹을 수 있지만, 그려보면 위쪽으로는 작은 부채꼴을 더 생각해야 합니다), $w &amp;lt; L$ 인 경우가 있으며, $w &amp;lt; L$ 인 경우에는 두 점에서의 부채꼴이 겹치는 부분을 따로 세서 빼야 합니다.&lt;/p&gt;

&lt;p&gt;Coffeetea는 이 문제를 꽤 오랜 시간 붙잡았고 (구현이 체계적이려면 어쩔 수 없습니다), 구현해보았으나 틀렸습니다. 아마도 sqrt의 수치에러일 것으로 보고 다른 두 사람이 epsilon을 더하거나 이분탐색으로 직접 integer sqrt를 짤 것을 제안했고, 결국 이것 외에도 여러 자잘한 버그들을 고친 끝에 4번째만에 맞을 수 있었습니다. 119분 AC.&lt;/p&gt;

&lt;h3 id=&quot;problem-k--treasure-hunter&quot;&gt;Problem K : Treasure Hunter&lt;/h3&gt;
&lt;p&gt;Solve : Gratus907, DHDroid (Coffeetea도 잠깐 얘기를 듣는것 같던데, 여전히 B에 빠져 있던 것으로 기억합니다)&lt;br /&gt;
Code : Gratus907&lt;/p&gt;

&lt;p&gt;2차원 그리드에서 오른쪽 또는 아래로 내려가면서 보물을 먹을 수 있습니다. 그런데 왼쪽 또는 위로 돌아갈 수 없으므로 첫 경로에는 먹지 못하는 보물이 있을 수 있습니다. 모든 보물을 먹기 위해 필요한 경로의 개수 구하기.&lt;/p&gt;

&lt;p&gt;제가 이 문제를 잡았을때는 이미 DHDroid가 ‘그리디하게’ 라는 대략적인 각은 재 놨습니다. 즉, 한쪽의 convex hull을 따라 가면서 하나 먹고, 다 지운 다음 다시 먹고.. 하는 아이디어입니다. 이 방식이 답이 된다는 것은 약간의 논증을 통해 증명할 수 있었지만, 이 ‘외곽선 따는 경로’ 의 개수를 빠르게 구하는 방법에 대해서는 좀 어려움이 있었습니다.&lt;/p&gt;

&lt;p&gt;한참 동안을 생각하다가, 제가 ‘이 보물을 먹으면, 이 보물보다 오른쪽 위에 있는 보물은 같은 경로에서는 먹을 수 없다’ 는 사실을 관찰했습니다. 이제 이를 이용하면, ‘매번 upper convex hull을 따면서 먹는다고 할 때, 이 보물을 먹기 위해 필요한 최소 횟수’ 를 구할 수 있습니다. 구체적으로는, ‘나보다 오른쪽 위에 있는 보물들을 먹는 데 필요한 개수 + 1’ 만큼이 필요합니다.&lt;/p&gt;

&lt;p&gt;이는 다시 뭔가 오른쪽 위에 대한 max-2D query를 하는 연산인데, &lt;strong&gt;좀아까 푼 H번에서처럼&lt;/strong&gt; 1D 세그에다가 업데이트 순서를 잘 줘서 해결할 수 있습니다! 한 대회에 같은 아이디어를 두개 낸다는 점이 좀 의심스러웠지만 이걸 코딩하기로 했습니다. 코딩 결과 WA를 받았는데, 이게 무슨 에러인지 당장 알 수 없었기 때문에, 1틀 한 후 저는 잠시 알고리즘 자체에 대해 생각해보겠다고 하고 컴퓨터를 넘겨줬습니다. 다행히 제가 K번을 코딩하고 내는 사이에 계속 생각하던 DHdroid와 B번을 풀고 온 Coffeetea가 C번에 대한 뭔가 유의미한 관찰들을 빌드업했고, 잠시 구현을 시도해서 C번에서 WA를 받았습니다. C번도 다시 생각해보기로 하고 제가 다시 컴퓨터를 잡은 후, 간단한 실수임을 발견해서 148분에 AC를 받았습니다.&lt;/p&gt;

&lt;h3 id=&quot;problem-c--colorful-tower-of-hanoi&quot;&gt;Problem C : Colorful Tower of Hanoi&lt;/h3&gt;
&lt;p&gt;Solve : DHDroid, Coffeetea&lt;br /&gt;
Code : DHDroid&lt;/p&gt;

&lt;p&gt;남은 32분동안, Coffeetea와 DHDroid는 C번에 대한 기존의 풀이가 해결하지 못하는 케이스들을 찾아내서 이를 잡고자 했습니다. 결과적으로 풀이의 큰 틀은 DhDroid가 제시했고, 여러 edge case들을 Coffeetea가 발견해서 계속 풀이의 사소한 오류를 수정했습니다. 저는 30분 남은 시간동안 이 풀이를 설명해달라고 할지, 다른 뭘 할지 고민해봤지만 풀이 설명을 듣는 시간이 두명에게 굉장히 아까울 것 같아서 제가 스스로 종이들을 보면서 이해해 보려고 했고, 결국 뭔가 재귀적으로 잘 한다는 아이디어임은 주워들어서 납득했지만 그 후로는 잘 모르겠습니다.&lt;/p&gt;

&lt;p&gt;아주 간략한 아이디어는, 일반 하노이탑처럼 움직이는데 크기가 같은 판 두개가 있으면 일반 탑처럼 움직이면 그 판 두개의 위치는 서로 바뀐다는 사실을 관찰하는 것입니다. 이후 이를 바로잡아야 하는지 / 그렇지 않은지에 따라서 추가로 얼만큼 더 움직여야 하는지를 계산합니다. 시간이 될 때 DHDroid가 설명해 주기로 했습니다. [ 풀이 들어갈 자리 ]&lt;/p&gt;

&lt;p&gt;마지막에는 $n = 1, 2$ 같은 작은 케이스들이 계속 문제가 되었지만, 영혼을 바친 5틀 끝에 173분에 AC를 받을 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;retrospect&quot;&gt;Retrospect&lt;/h2&gt;
&lt;p&gt;저희는 7솔브로 18등의 성적을 거두었습니다. 10솔 2팀, 9솔 2팀, 8솔 2팀, 7솔 12팀이고 페널티싸움에서 맨 끝으로 밀렸네요.&lt;/p&gt;

&lt;p&gt;여기부터는 대회 자체와는 큰 상관 없는 얘기고, &lt;strong&gt;정확한 사실이 아닌 개인의 의견&lt;/strong&gt; (Factual하지 않다는 말이 아닙니다. Controversial / Personal이 가장 정확한 말일 것 같습니다) 에 해당하는 말들이 많습니다. 건전하고 건설적인 비판은 언제든 환영합니다. 대회와 상관있는 말부터 상관없는 말들 순서대로 적었습니다.&lt;/p&gt;

&lt;h3 id=&quot;about-problemset--our-result&quot;&gt;About Problemset / Our result&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;먼저, ICPC의 문제들은 OI와는 다르게 Syllabus가 없습니다. 정말 논문에 나오는 문제들부터, 복잡한 알고리즘 없이 construction으로 승부보는 문제까지 widely ranged 입니다. OI가 아이디어 싸움인 것과는 좀 다릅니다&lt;/li&gt;
  &lt;li&gt;그래서, 진입 장벽이 좀 있습니다. 특히 MO나 다른 수학적 사고력을 요구하는 백그라운드를 가진 사람들이 construction은 잘 할수 있지만, 매년 인예에는 FFT, LiChao Tree 등 &lt;strong&gt;학부 알고리즘 수업에서 다루지 않는 알고리즘&lt;/strong&gt; 한두개를 그냥 &lt;strong&gt;알고 있는지&lt;/strong&gt; 묻는 문제가 나옵니다. 올해는 A번이 저는 Mo’s algorithm에 대한 비슷한 스타일의 문제라고 판단했고, 결과적으로 Mo를 쓰는 것은 맞지만 그렇게까지 단순한 문제는 아니라고 (단순한 방법은 $n \sqrt{n} \log{n}$ 이고 통과하기 힘들다고 합니다) 하니 반만 맞은 말입니다.&lt;/li&gt;
  &lt;li&gt;L번이 USACO 문제와 비슷한, 나름 아는 팀들은 아는 문제라고 합니다. 그래서인지 저는 프리즈후 A번을 제출한 팀들이 대부분 맞았을 것이라고 주장했는데 그러지 않았고, 대신 L번이 생각보다 많이 풀렸습니다.&lt;/li&gt;
  &lt;li&gt;그리고 솔직히 H와 K가 같은 아이디어인 것은 충격이었습니다만, K는 LIS를 이용한 더 쉬운 풀이가 있다고 하므로 이것도 반만 맞는 말인것 같습니다.&lt;/li&gt;
  &lt;li&gt;웰노운을 출제하는게 어떤 의미가 있는지는 사람마다 생각이 다를 것입니다. 저는 딱히 지지하지도, 반대하지도 않습니다. 물론 제가 모르는 웰노운이 나오면 욕하는건 당연하지만, 그건 솔직히 말하면 어쩔 수 없는 거죠.&lt;/li&gt;
  &lt;li&gt;저희의 이번 대회는 현재 실력에 비추어 볼 때 잘 치른게 맞습니다. 다만, Coffeetea가 실력을 발휘할만한 직관싸움 문제가 딱히 없었고, 결정적으로 저희팀의 오래된 전략이지만 개선점이 있는 ‘복잡한 구현이 있으면, Coffeetea를 밀어 넣고, 나머지 2명이 기도하면서 다른 문제를 푼다’ 는 전략을 또 써야 했습니다. B번 하나에 Coffeetea의 시간을 거의 절반이나 갈아 버린 것은 좋은 전략은 아닙니다.&lt;/li&gt;
  &lt;li&gt;그럼에도 불구하고, 그러지 않았으면 저는 B번 AC를 못 받았을 것입니다. DHDroid도 딱히 이런 문제를 저보다 잘 하진 않습니다. ㅋㅋ…&lt;/li&gt;
  &lt;li&gt;특별히 아쉬움이 남는건 없습니다. 사소한 실수로 페널티 싸움을 많이 밀렸다는건 좀 아쉽지만, 솔브수에서 상위권 팀들을 따라붙었다는 의의는 확실히 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;about-my-icpc&quot;&gt;About my ICPC&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;저는 ICPC에 네 번 나가 봤고, 모두 본선에는 못 갔습니다. 사실 올해는 저를 제외한 두명이 휴학생이기 때문에, 저희가 몇 등을 했든 저는 본선 진출권이 없었습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;솔직히 말하자면 예선 성적으로는 본선에 진출하고도 남을 만한 성적을 2019년부터 받아 왔지만, ICPC는 많은 대학의 출전을 위해 상위권 대학에 더 엄격한 기준을 적용하여 본선 팀을 선발합니다. 구체적으로는, 먼저 $x$ 문제를 푼 팀들을 모두 선발하고, 이후에는 $x-1$ 문제를 푼 팀들 중 각 대학의 $y_i$ 위 이상인 팀… 을 선발하는 식입니다. 이 방식을 적용하는 데 있어, 어떤 학교도 총 출전팀의 50% 이상을 본선에 보내지 못한다는 (과거엔 explicit하게 적혀 있었다고 하지만, 지금은 찾을 수 없고, 그럼에도 아직 적용되는 것으로 보이는) 룰 이 있습니다. 맨 위의 선발 기준은 사실상 서울대를 위해 만들어졌으며 (서울대 15팀 중 7팀 이하를 자르는 컷을 찾습니다), 본선 진출 경계선인 60위에 (작년에는 90위였을 거고 그럼 얘기가 다릅니다) 50% 이상의 팀을 보낼 수 있는 학교는 몇 없기 때문에 (서울대, KAIST, 고려대 정도. 아마 해에 따라 다른 학교들도 가능한 해가 있을 것입니다) 사실상 저격밴이 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;제가 이번에 휴학생 팀으로 나간 이유도 여기에 있습니다. 저랑 비슷한 수준의 팀원 두명을 모으면 본선 진출이 어차피 어려울 것이고, 저보다 월등히 잘하는 팀원을 찾으면 어떻게 나가볼 수 있을지는 모르겠지만 첫째로는 그런 사람이 저랑 팀을 해줄지도 의문이고 두번째로는 해준다고 해도 제가 대회를 재밌게 즐기지 못할 것 같았습니다. 그래서 휴학생 팀이지만, 대회 자체를 진심으로 즐길 수 있는 - 일종의 즐겜팀이라고 할까요 - Little Piplup에 다시 함께했습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이 monotonic하지 않은 선발 기준에 대해 어떻게 생각하는지는 사람마다 다른 영역인 것 같습니다. 저는 당연히 이 기준으로 본선 무대를 못 밟았으므로 굉장히 화가 나지만, 대학 대항전인 ICPC에서 서울대 15팀이 나타나는 것이 그럼 맞느냐? 고 말하면 뭐 그렇게 볼 수도 있습니다. 다만, 이 부분은 조금 나아질 기미가 보이는데, PS판에서 서울대가 보여줬던 갭이 점점 줄어드는게 눈에 보이기 때문입니다. 올해의 인예 순위에서 솔브수로 격차를 낸 최상위권은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;서울-서울-고려-카이-카이-유니&lt;/code&gt; 입니다. (7솔에 저희를 포함 무려 12팀이 물려 있습니다) 참고로, 작년 인예는 9솔 이상이 7팀이었는데, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;서울-서울-서울-서울-카이-서울-숭실&lt;/code&gt; 이었습니다. PS판의 저변이 넓어져서 그런 것인지, 서울대의 수많은 레드들이 PS판을 떠나고 ML 같은 보다 쓸모있는 뭔가를 공부하러 갔기 때문인지, 최근 여러 학교에서 레드 이상의 CP-er를 배출한 데 어떤 요소들이 작용했는지는 잘 모르겠지만 아무튼 그렇습니다. 레드 한명이 졸업할때까지 뛸수있는 ICPC판을 보니 내년에도 이럴 것 같고, 작년처럼 서울대 리저널 6팀인가? 보내 줬더니 모든 상을 서울대가 쓸어버리는 참사가 벌어지지는 않을 것입니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;저는 내년이 마지막 ICPC고, 알고리즘을 공부하면서 / PS를 즐기면서 ICPC 본선 리저널 무대를 한번도 가보지 못했다는 것이 개인적으로 굉장히 아쉽습니다. 어떻게 보면 아카데믹하게 알고리즘을 공부하겠다는 목표를 갖게 된 지금은 PS 자체에 큰 의미는 없겠지만, 개인적으로 느낀 바가 그렇습니다. 그래서, 겨울방학에 좀 빡세게 돌면서 레드 정도 수준까지 폼을 맞춰놓고, 내년에는 레드 3명 또는 그에 근접한, 진출을 노리는 팀을 만들어 마지막 ICPC에 도전할 계획입니다. 좋은 팀원을 모은다면 80% 이상 가능하다고 확신하고 있습니다. 혹시 이 블로그를 보신 &lt;strong&gt;서울대 재학생 중&lt;/strong&gt;, 내년 10월까지 &lt;strong&gt;CF 2300 또는 Equivalent한&lt;/strong&gt; 실력을 갖출 수 있으며, &lt;strong&gt;휴학 계획이 없고&lt;/strong&gt;, &lt;strong&gt;같이 공부하고 싶은&lt;/strong&gt; 분은 연락주시면 좋을것 같네요. ㅋㅋ!!! (당연한 말이지만 이런 허공에 돌던지는 식으로 모을 생각으로 쓴 말은 아닙니다…)&lt;/p&gt;

&lt;h3 id=&quot;대회를-마치며&quot;&gt;대회를 마치며&lt;/h3&gt;
&lt;p&gt;항상 PS 대회를 뛰고 나면, PS를 즐기는 마인드와 대회 성적에 따른 competitive 한 마인드가 서로 충돌하게 됩니다. 이번 대회는 정말 간만에 그런 것 없이 순수하게 즐길 수 있었는데, 대회가 끝나고 나니 competitive mind가 잠깐 지배하고 있어서 위 500단어 정도를 ranting했습니다. 학기중에는 어차피 매우 바쁘기 때문에, 겨울방학에나 다시 손댈 수 있지 않을까 싶습니다.&lt;/p&gt;

&lt;p&gt;끝나고 팀원들과 치킨을 먹으면서 대회에 대한 얘기도 하고, 재밌게 놀고 왔습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;네. 이 문장은 &lt;del&gt;기만질&lt;/del&gt; 자랑하려고 적었습니다. ㅋㅋ!!! &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="cp-rounds" /><summary type="html">Contents Preperation / Our Team 본 대회 Problem I : Sport Climbing Combined Problem E : Histogram Problem J : Ten Problem H : Similarity Problem B : Carrot Field Problem K : Treasure Hunter Problem C : Colorful Tower of Hanoi Retrospect About Problemset / Our result About my ICPC 대회를 마치며 Little Piplup 팀으로 복귀해서 ICPC 2021을 재밌게 치고 왔습니다. 늘 대회가 끝나고 나면 Whining을 해왔지만, 이번 대회는 솔직히 말하면 Whining할게 별로 없습니다. 18등의 성적을 거두었는데, 풀었어야 할 문제 는 다 풀지 않았나 싶습니다. Prep - 대회과정 타임라인에 따른 의식의 흐름 - Retrospect의 순서로 작성합니다. 평소보다 앞뒤 글이 많이 길고 장황하기 때문에, 왼쪽 아래 Table of Content를 보면 문제에 대한 이야기만 볼 수 있습니다. Preperation / Our Team 팀연습 두번을 했습니다. GCPC 2020 : 팀연습 기록 링크 BAPC 2020 (기록 미작성) 이 팀의 객관적인 전력을 저는 개인적으로 적어도 2100 3명 정도 수준, 내지는 문제셋을 조금 잘 타면 1레드가 섞인 팀과도 비벼볼 수 있다고 생각합니다. 가장 최근의 팀 대회는 Hashcode 2021이었는데, 그때와 지금 팀을 비교하면 (dlwocks31의 부재를 제외하고 세명만) 크게 달라진 것은 없으므로 그때 썼던 기록에 더하여 팀원들에 대한 얘기를 조금 해보겠습니다. Gratus907 : 수학적인 문제에 비교적 강하고, 말리지 않을때까지는 구현이 빠르지만 말리면 한없이 말리는 경향이 있습니다. 그래도 제 코딩 경험이 쌓이면서 예전만큼 코딩이 말리지 않습니다. 반면에, 한번 어떤 방면으로 빠지면 무한한 뇌절을 이어가는 경향이 있습니다. 이는 FFT에 패배한 SCPC 2021 같은 상황에서 정말 끔찍했습니다. 수학 복수전공을 통해 얻은 지식은 딱히 PS에 도움이 되지 않지만, 씹덕같은 정수론 문제 한두개를 가끔 쳐낼 수 있는것 같습니다. 아카데믹한 알고리즘 공부를 그래도 이중에 가장 많이 했었습니다. DHDroid : Constructive한 문제에 매우 강하고, 관찰을 정당화 (증명) 하는 능력이 뛰어납니다. 이 능력을 실제로 보여준 대회가 역시 SCPC 2021입니다. Round 2 하노이탑에서 일부 레드들도 달성을 어려워했던 250점을 달성하고, 저보다 훨씬 높은 성적으로 2라운드를 마친후 본선에서 5등상을 받는 쾌거를 보여줬습니다. 본인의 표현을 빌리자면 정말 어려운 문제에 도전해서 몇 시간 고민을 이어가는 본인의 연습방식이 도움이 된다고 합니다. 학과 동기이고 친구지만 이렇게 어려운 문제를 대하는 자세를 보면서 항상 많은 것을 배웁니다. 반대로 제한시간이 짧은 대회에 살짝 약합니다. 2시간짜리 코드포스가 가장 대표적이죠. Coffeetea : 그리디하거나 휴리스틱한 관찰, 대략적인 경향성의 파악에 강합니다. 뭔가 문제에 빙의하는 특성이 있어서 글쓸때 Coffeetea의 표현을 많이 빌리게 됩니다 :) 저는 그때 이 팀에 없었지만, 작년 ICPC F번 같은 문제에서 가장 잘 느낄 수 있습니다. (이 문제는 그렇게 어렵지 않지만요) Hashcode 스타일의 대회에서 초기 아이디어를 정말 잘 던져주고, 데이터를 슥 보고 특성을 빠르게 캐치합니다. 많이 복잡한 구현은 저보다 잘 합니다. 저보다 좀더 구현에 대해 체계적으로 고민하고, 놓치는 케이스가 비교적 적으며, 디버깅할때의 끈기와 자세가 뛰어납니다. 역시 항상 많은 것을 배우게 되는 친구입니다. 개발 공부에 많은 시간과 노력을 투자했기 때문에 이런 구현 실력을 갖춘 것 같은데, 반대로 소위 ‘고인물 알고리즘’ 에 대한 공부를 많이 하지는 않았습니다. 대회 시작 전날까지 팀노트를 작년 제 팀노트에 얹어서 나름대로 열심히 준비했습니다. 후술하지만, 약간의 부족함은 있었습니다. 팀노트를 준비할 때 생각해야 하는 기준은, (보편 타당한 생각을 제가 나름대로 표현해 보자면) “어 이거 그건데” 와 AC를 받는 시점 사이의 시간의 expectation을 minimize하는 것입니다. 이 말의 의미는, 구현 실수가 날만한 부분들이나 구현이 복잡한 자료구조, 알지만 구글링 없이는 코딩이 불가능한 알고리즘 등을 적어 가야 한다는 것입니다. 저희 팀을 예로 들자면 수많은 기하 구현을 준비했습니다. 대회 시간 중에 선분 - 선분 교차를 구현해 보셨나요? ㅋㅋ! segment tree에서 lazy propagation의 개념은 잘 알고 있으나 구현시 실수할 것을 대비하여 적어 갔습니다. Dinic과 HeavyLight Decomposition 등을 적어 갔습니다. 25페이지는 효율적으로 잘 꾹꾹 눌러 쓰면 생각보다 꽤 많습니다. 저희 팀노트는 [링크] 에서 볼 수 있는데, ICPC 전날 급하게 많은 것을 추가하느라 외관의 아름다움을 많이 잃어버렸습니다만 앞으로 계속 업데이트될 것입니다 (제 개인적으로는 archive의 의미가 있어서요.) 팀노트 맨 끝장에는 Checkpoint를 붙여 갔습니다. 이 체크포인트는 제가 계속 관리하고 있는 노트인데, 제가 나가는 팀대회에서는 팀노트 맨 끝장에 붙여 나갑니다. (이미지를 우클릭-새 탭으로 열기해서 큰 화면으로 볼 수 있습니다) 모든 포인트들은 제가 문제를 풀면서 경험해본 것들입니다. PS 오답노트라고나 할까요. 본 대회 저희는 스터디카페에서 대회를 치렀기 때문에, 문제지가 뜨는걸 확인하는 즉시 제가 인쇄를 하러 나가면서 팀원들이 화면을 반으로 나눠서 A, B를 읽었습니다. 문제지 인쇄까지는 프린터가 느린데다 문제지 합본 pdf 파일이 바로 넘어오지 않아서, 거의 7분 가까운 시간이 소요되었습니다. 그러나 문제지를 인쇄하는 프린터 앞에 서서 저도 문제를 볼 수 있었기 때문에 실질적인 시간상의 로스는 거의 없습니다. 대회 규정상 팀원 1인 이상이 오랜 시간 자리를 비워서는 안되고 (아마도 이 규정이 strictly enforce되는 것은 어차피 기술적으로 불가능했을 것입니다만), 팀원들의 효율을 위해 문제지가 1/3정도 인쇄될 때마다 제가 계속 팀원들에게 배달했습니다. 그 사이에, I번의 첫 Solve들이 등장하기 시작했습니다. 처음에 어떻게 다른 팀들이 12문제 중 9번째에 있는 문제를 찾아내서 풀었는지 의아했지만, 생각해보니 4/4/4로 분배하면 팀원중 한명에게는 가장 먼저 읽는 문제니까 그런것 같습니다. (그럼에도 약간의 의문이 있습니다. 찾아보니 작년에도 I번이 가장 쉬운 문제였고, 그 전까지는 등록이 있는 자리였는데 혹시 그 사실을 인지하고 있는 팀들이 있을까요?) 인쇄 중에 저는 팀원들이 A, B 부터 읽고 있음을 감안하여 적당히 몇개 떼고 E를 읽었습니다. 한국어길래 슬쩍 B, C도 한번씩 읽었는데 B는 딱봐도 구현이 노답이고 C는 엄청나게 어려워 보였기 때문에… 제가 인쇄를 마치면서 2시 8분쯤 방에 복귀했는데, 이미 팀원들이 I번을 읽고 솔루션을 제시했으며 B가 구현 노답이라는 사실도 인지하고 있었습니다. Problem I : Sport Climbing Combined Solve : DHdroid Code : DHDroid 무슨 문제인지 방금 처음 읽었는데, 딱히 할말이 없습니다. $p_i \times q_i \times r_i$를 기준으로 정렬해서 그 $b_i$를 출력하면 됩니다. 13분에 AC를 받았습니다. 이때 저는 E번의 풀이가 간단한 $O(B N^2)$ DP로 가능하다는 것을 이미 인지했기 때문에 ($30 * 4000^2$ 이면 4.8억이지만 실제로는 그 절반만 써서 괜찮습니다), 바로 제가 E를 잡겠다고 주장했습니다. 아무도 E를 풀지 않았다는 사실이 좀 마음에 걸리지만… Problem E : Histogram Solve : Gratus907 Code : Gratus907 배열을 최대 B개의 구간으로 나누어, 각 구간에서의 분산의 합을 최소화하는 문제입니다. $n$이 더 커지면 DP 최적화 기법 등을 생각해 볼 수 있겠지만, 이정도는 $B \times N$ 테이블을 칸당 $O(N)$ 에 구해도 충분합니다. 먼저, 어떤 구간 $[j, i]$ 의 분산 $V(j, i)$ 을 $O(1)$에 구할 수 있다면, 이 문제는 간단히 다음과 같이 환원됩니다. \(D(b, i) = \min_{j &amp;lt; i} V(j, i) + D(b-1, j-1)\) 그런데, 분산은 원소의 합과 제곱의 합을 안다면 $O(1)$에 구할 수 있고 (제평-평제 공식), 이는 prefix sum으로 최적화 가능한 문제입니다. 이 문제의 구현은 금방 했지만, 실수로 n을 써야 할 자리에 MAXN 인 4000을 써넣어서 한번 틀렸습니다. 이후 이를 바로 캐치하고, 고쳤으나 맥북에 연결한 외장 키보드의 단축키가 익숙하지 않아서(변명같겠지만 진짜입니다….) 제출과 동시에 어 저장 안된거 아닌가? 라는 비명을 지르며 1번 더 틀리고 2틀 후 23분에 AC를 받았습니다. 저희 팀이 이 문제 First Solve를 받았습니다. 개인적으로 ICPC같은 큰 대회에서 퍼솔은 처음이라 굉장히 기분이 좋았습니다. ㅋㅋ!! 이제, Coffeetea가 ‘B번은 미친듯이 케이스를 나눠야 한다. 일단 구현을 시작하겠지만 누군가 짤게있으면 바로 인터셉트해서 다른거 구현 하는게 좋겠다’ 는 말을 했고, 곧 DHDroid가 J를 바로 짤수있다고 선언해서 컴퓨터를 내줬습니다. 추가로, 저는 A번을 읽고 바로 ‘수쿼 어딘가에 있을 법한 문제다’, ‘Mo’s Algorithm으로 풀 수 있을 것 같은데, 내가 그거 구현을 못한다. 정확히 이해한게 아니라서 팀노트에도 못적어왔다’ 고 말했습니다. 이때 또 웰노운 당했다는 생각에 굉장히 화가 났습니다. ㅋㅋ… Problem J : Ten Solve : DHDroid Code : DHDroid 숫자가 가득 주어지고 합이 10이 되는 직사각형의 개수를 세는 문제입니다. 일반적으로는 모든 직사각형을 볼 수 없으나, 이 문제에서는 각 숫자가 1 이상이다보니 크기가 10을 넘는 직사각형들을 볼 필요가 없어서 bruteforce할 수 있습니다. DHDroid가 2차원 부분합 잘 짜냐고 물어봐서 못한다고 대답하니까 아니;;; 이러면서 알아서 잘 짜더군요…ㅋㅋㅋ 40분 AC. 이시점 저희의 순위는 최상위권이었기 때문에 (정확히 40분 시점에 저희는 E, I, J를 풀었고, 3솔 팀 다섯 팀이 각각 E, E, B, H, K를 풀었으며 4솔 이상 팀이 없어서 저희는 5등이었습니다) 스코어보드를 보고 다음 풀 문제를 바로 알 수 없었고, B번의 케이스를 열심히 나누던 coffeetea와 제가 좀 얘기를 해보니까 H번을 금방 풀 수 있을 것 같았습니다. 제가 풀이의 확실함을 잠깐 고민하는 동안 Coffeetea가 한 7~8분? 정도 코딩을 좀 하다가, 제가 H번 풀 수 있다고 말해서 바로 바꿨습니다. Problem H : Similarity Solve : Gratus907, Coffeetea (B번에 대해 생각하느라 많은 참여는 못했습니다) Code : Gratus907 두 배열 $P, Q$가 주어졌을 때, $p_i &amp;lt; p_j &amp;lt; p_k$ 이면서 $q_i &amp;lt; q_j &amp;lt; q_k$ 인 인덱스 $(i, j, k)$ 의 개수를 세는 문제입니다. $i$번째 인덱스를 점 $(p_i, q_i)$로 표현해 보겠습니다. 그렇다면, 2차원 배열 위에서, 우리가 원하는 인덱스들은 나의 ‘왼쪽 아래’ 직사각형에 있는 점들과, ‘오른쪽 위’ 직사각형에 있는 점들입니다. 즉 2차원 평면에서 어떤 직사각형 안에 점이 몇 개 있는지를 빠르게 셀 수 있다면 - 구체적으로, 내 ‘왼쪽 아래’ 와 ‘오른쪽 위’ 직사각형 - 이 문제를 풀 수 있습니다. 언뜻 생각하면 2D segment tree 같은게 필요할 것 같지만, 잘 알려진 테크닉으로 이를 1D 세그만으로 할 수 있습니다. 세그먼트 트리는 업데이트 순서에 영향을 받기 때문에, 축 하나의 정보를 ‘업데이트 순서’ 를 이용해서 표현하는 것입니다. $x$좌표를 이용한 세그먼트 트리를 구현하되, $y$좌표가 큰 원소부터 업데이트한다고 하겠습니다. 이때, 어떤 점을 업데이트하기 직전에 $[x+1, \infty]$ 의 쿼리를 날려서 점의 개수를 세면, 아직 나보다 아래 있는 점은 업데이트를 안 했기 때문에 실제로 보이는 공간은 내 오른쪽 반평면이 아니라 내 오른쪽 위 사분면입니다. 이를 두개 이용해서 우상단과 좌하단을 각각 세면 됩니다. 같은 $y$좌표인 경우 누가 누구를 볼 수 있어야 하는지를 고려하면 되는데 여기서는 $x$좌표가 작은쪽부터 업데이트해주면 됩니다. 왼쪽에 있는 원소가 오른쪽 원소를 보게되면 ‘오른쪽 위’ 가 아니라 ‘오른쪽’ 인데도 포함하는 경우가 있어서, 왼쪽 원소는 자기랑 $y$좌표가 같고 $x$좌표가 큰 원소를 볼 수 없어야 합니다. 여름에 다른학교 컴공과에 다니는 여자친구랑 세그먼트 트리, DP, 그래프 같은 주제 몇개로 플레 문제 일주일에 5-10개씩 밀었는데 1, 그때 비슷한 문제를 풀어 봤습니다. 링크 에 있는 ‘북서풍’, ‘여우가 정보섬에 올라온 이유’ 등 문제들에서 똑같이 쓰입니다. 72분에 AC를 받았습니다. 대회시간의 대략 40%가 지난 지금, 잠시 전체 상황을 조망해보자면 4 Solve. 1등은 6솔브, 2/3등은 5솔브로 최상위팀인 서울대 팀은 저희 + B, C를 풀었고, KAIST 팀과 다른 서울대 팀 하나가 각각 저희보다 K를 추가 / (B, C) 를 풀고 H 미해결인 상태였습니다. 많이 틀려서 페널티를 쌓기는 했지만, 대회 시간 40% 시점까지 상위권 솔브수를 따라붙을 수 있었습니다. B번은 Coffeetea가 ‘충분한 시간이 주어지면 풀 수 있다’ 는 식으로 말했는데, 이게 참 어려운 말입니다. 반대로 ‘충분한 시간이 주어지지 않는’ 경우도 고려해야 합니다. K번은 DHDroid가 고민을 좀 해보고 있었는데, ‘그리디일텐데… 복잡도가…’ 정도 상황이었습니다. 다른 문제에 대해서는 솔직하게 No clue. 저는 C번을 읽어봤기에, 최상위권 팀들이 C를 풀었다는 점 + 일부 4솔팀들이 H, 심지어 E보다도 C를 먼저 풀었다는 점이 좀 신기했습니다. 객관적으로 이때의 4솔팀들중에는 2400급 강팀들도 있지만, 2019-2020 시즌 Cafe mountain처럼 말도안되는 팀은 없는 것으로 알기 때문에 이들의 액션은 유의미합니다. 이것들을 고려해서, 다시 Coffeetea가 키보드를 잡은채로 저희는 K를 풀고자 했습니다. 대회가 끝날 때까지 아마도 B, K는 풀 수 있을것 같았고, 하나 더 풀면 괜찮은 등수가 나오지 않겠느냐는 말을 했습니다. Problem B : Carrot Field Solve : Coffeetea Code : Coffeetea 중학교 1학년 수학 교재를 보면, 말 같은걸 직사각형 한 점에 길이가 $L$인 줄로 묶어놓고 그 말이 움직일 수 있는 부분의 넓이를 구하는 문제가 많이 나옵니다. 그거랑 똑같은데, 대신에 격자점의 개수를 구하는 문제입니다. 언뜻 보면 충격적으로 쉬워 보이지만, 이 문제가 끔찍한 점은 경우를 나눠야 한다는 것입니다. 편의상 $w \geq h$ 를 가정한다고 할 때, 크게 $L &amp;lt; h$ 인 경우 (원의 3/4 만큼), $h &amp;lt; L &amp;lt; w$ 인 경우 (이때는 가로쪽으로는 딱 사분원만큼을 먹을 수 있지만, 그려보면 위쪽으로는 작은 부채꼴을 더 생각해야 합니다), $w &amp;lt; L$ 인 경우가 있으며, $w &amp;lt; L$ 인 경우에는 두 점에서의 부채꼴이 겹치는 부분을 따로 세서 빼야 합니다. Coffeetea는 이 문제를 꽤 오랜 시간 붙잡았고 (구현이 체계적이려면 어쩔 수 없습니다), 구현해보았으나 틀렸습니다. 아마도 sqrt의 수치에러일 것으로 보고 다른 두 사람이 epsilon을 더하거나 이분탐색으로 직접 integer sqrt를 짤 것을 제안했고, 결국 이것 외에도 여러 자잘한 버그들을 고친 끝에 4번째만에 맞을 수 있었습니다. 119분 AC. Problem K : Treasure Hunter Solve : Gratus907, DHDroid (Coffeetea도 잠깐 얘기를 듣는것 같던데, 여전히 B에 빠져 있던 것으로 기억합니다) Code : Gratus907 2차원 그리드에서 오른쪽 또는 아래로 내려가면서 보물을 먹을 수 있습니다. 그런데 왼쪽 또는 위로 돌아갈 수 없으므로 첫 경로에는 먹지 못하는 보물이 있을 수 있습니다. 모든 보물을 먹기 위해 필요한 경로의 개수 구하기. 제가 이 문제를 잡았을때는 이미 DHDroid가 ‘그리디하게’ 라는 대략적인 각은 재 놨습니다. 즉, 한쪽의 convex hull을 따라 가면서 하나 먹고, 다 지운 다음 다시 먹고.. 하는 아이디어입니다. 이 방식이 답이 된다는 것은 약간의 논증을 통해 증명할 수 있었지만, 이 ‘외곽선 따는 경로’ 의 개수를 빠르게 구하는 방법에 대해서는 좀 어려움이 있었습니다. 한참 동안을 생각하다가, 제가 ‘이 보물을 먹으면, 이 보물보다 오른쪽 위에 있는 보물은 같은 경로에서는 먹을 수 없다’ 는 사실을 관찰했습니다. 이제 이를 이용하면, ‘매번 upper convex hull을 따면서 먹는다고 할 때, 이 보물을 먹기 위해 필요한 최소 횟수’ 를 구할 수 있습니다. 구체적으로는, ‘나보다 오른쪽 위에 있는 보물들을 먹는 데 필요한 개수 + 1’ 만큼이 필요합니다. 이는 다시 뭔가 오른쪽 위에 대한 max-2D query를 하는 연산인데, 좀아까 푼 H번에서처럼 1D 세그에다가 업데이트 순서를 잘 줘서 해결할 수 있습니다! 한 대회에 같은 아이디어를 두개 낸다는 점이 좀 의심스러웠지만 이걸 코딩하기로 했습니다. 코딩 결과 WA를 받았는데, 이게 무슨 에러인지 당장 알 수 없었기 때문에, 1틀 한 후 저는 잠시 알고리즘 자체에 대해 생각해보겠다고 하고 컴퓨터를 넘겨줬습니다. 다행히 제가 K번을 코딩하고 내는 사이에 계속 생각하던 DHdroid와 B번을 풀고 온 Coffeetea가 C번에 대한 뭔가 유의미한 관찰들을 빌드업했고, 잠시 구현을 시도해서 C번에서 WA를 받았습니다. C번도 다시 생각해보기로 하고 제가 다시 컴퓨터를 잡은 후, 간단한 실수임을 발견해서 148분에 AC를 받았습니다. Problem C : Colorful Tower of Hanoi Solve : DHDroid, Coffeetea Code : DHDroid 남은 32분동안, Coffeetea와 DHDroid는 C번에 대한 기존의 풀이가 해결하지 못하는 케이스들을 찾아내서 이를 잡고자 했습니다. 결과적으로 풀이의 큰 틀은 DhDroid가 제시했고, 여러 edge case들을 Coffeetea가 발견해서 계속 풀이의 사소한 오류를 수정했습니다. 저는 30분 남은 시간동안 이 풀이를 설명해달라고 할지, 다른 뭘 할지 고민해봤지만 풀이 설명을 듣는 시간이 두명에게 굉장히 아까울 것 같아서 제가 스스로 종이들을 보면서 이해해 보려고 했고, 결국 뭔가 재귀적으로 잘 한다는 아이디어임은 주워들어서 납득했지만 그 후로는 잘 모르겠습니다. 아주 간략한 아이디어는, 일반 하노이탑처럼 움직이는데 크기가 같은 판 두개가 있으면 일반 탑처럼 움직이면 그 판 두개의 위치는 서로 바뀐다는 사실을 관찰하는 것입니다. 이후 이를 바로잡아야 하는지 / 그렇지 않은지에 따라서 추가로 얼만큼 더 움직여야 하는지를 계산합니다. 시간이 될 때 DHDroid가 설명해 주기로 했습니다. [ 풀이 들어갈 자리 ] 마지막에는 $n = 1, 2$ 같은 작은 케이스들이 계속 문제가 되었지만, 영혼을 바친 5틀 끝에 173분에 AC를 받을 수 있었습니다. Retrospect 저희는 7솔브로 18등의 성적을 거두었습니다. 10솔 2팀, 9솔 2팀, 8솔 2팀, 7솔 12팀이고 페널티싸움에서 맨 끝으로 밀렸네요. 여기부터는 대회 자체와는 큰 상관 없는 얘기고, 정확한 사실이 아닌 개인의 의견 (Factual하지 않다는 말이 아닙니다. Controversial / Personal이 가장 정확한 말일 것 같습니다) 에 해당하는 말들이 많습니다. 건전하고 건설적인 비판은 언제든 환영합니다. 대회와 상관있는 말부터 상관없는 말들 순서대로 적었습니다. About Problemset / Our result 먼저, ICPC의 문제들은 OI와는 다르게 Syllabus가 없습니다. 정말 논문에 나오는 문제들부터, 복잡한 알고리즘 없이 construction으로 승부보는 문제까지 widely ranged 입니다. OI가 아이디어 싸움인 것과는 좀 다릅니다 그래서, 진입 장벽이 좀 있습니다. 특히 MO나 다른 수학적 사고력을 요구하는 백그라운드를 가진 사람들이 construction은 잘 할수 있지만, 매년 인예에는 FFT, LiChao Tree 등 학부 알고리즘 수업에서 다루지 않는 알고리즘 한두개를 그냥 알고 있는지 묻는 문제가 나옵니다. 올해는 A번이 저는 Mo’s algorithm에 대한 비슷한 스타일의 문제라고 판단했고, 결과적으로 Mo를 쓰는 것은 맞지만 그렇게까지 단순한 문제는 아니라고 (단순한 방법은 $n \sqrt{n} \log{n}$ 이고 통과하기 힘들다고 합니다) 하니 반만 맞은 말입니다. L번이 USACO 문제와 비슷한, 나름 아는 팀들은 아는 문제라고 합니다. 그래서인지 저는 프리즈후 A번을 제출한 팀들이 대부분 맞았을 것이라고 주장했는데 그러지 않았고, 대신 L번이 생각보다 많이 풀렸습니다. 그리고 솔직히 H와 K가 같은 아이디어인 것은 충격이었습니다만, K는 LIS를 이용한 더 쉬운 풀이가 있다고 하므로 이것도 반만 맞는 말인것 같습니다. 웰노운을 출제하는게 어떤 의미가 있는지는 사람마다 생각이 다를 것입니다. 저는 딱히 지지하지도, 반대하지도 않습니다. 물론 제가 모르는 웰노운이 나오면 욕하는건 당연하지만, 그건 솔직히 말하면 어쩔 수 없는 거죠. 저희의 이번 대회는 현재 실력에 비추어 볼 때 잘 치른게 맞습니다. 다만, Coffeetea가 실력을 발휘할만한 직관싸움 문제가 딱히 없었고, 결정적으로 저희팀의 오래된 전략이지만 개선점이 있는 ‘복잡한 구현이 있으면, Coffeetea를 밀어 넣고, 나머지 2명이 기도하면서 다른 문제를 푼다’ 는 전략을 또 써야 했습니다. B번 하나에 Coffeetea의 시간을 거의 절반이나 갈아 버린 것은 좋은 전략은 아닙니다. 그럼에도 불구하고, 그러지 않았으면 저는 B번 AC를 못 받았을 것입니다. DHDroid도 딱히 이런 문제를 저보다 잘 하진 않습니다. ㅋㅋ… 특별히 아쉬움이 남는건 없습니다. 사소한 실수로 페널티 싸움을 많이 밀렸다는건 좀 아쉽지만, 솔브수에서 상위권 팀들을 따라붙었다는 의의는 확실히 있습니다. About my ICPC 저는 ICPC에 네 번 나가 봤고, 모두 본선에는 못 갔습니다. 사실 올해는 저를 제외한 두명이 휴학생이기 때문에, 저희가 몇 등을 했든 저는 본선 진출권이 없었습니다. 솔직히 말하자면 예선 성적으로는 본선에 진출하고도 남을 만한 성적을 2019년부터 받아 왔지만, ICPC는 많은 대학의 출전을 위해 상위권 대학에 더 엄격한 기준을 적용하여 본선 팀을 선발합니다. 구체적으로는, 먼저 $x$ 문제를 푼 팀들을 모두 선발하고, 이후에는 $x-1$ 문제를 푼 팀들 중 각 대학의 $y_i$ 위 이상인 팀… 을 선발하는 식입니다. 이 방식을 적용하는 데 있어, 어떤 학교도 총 출전팀의 50% 이상을 본선에 보내지 못한다는 (과거엔 explicit하게 적혀 있었다고 하지만, 지금은 찾을 수 없고, 그럼에도 아직 적용되는 것으로 보이는) 룰 이 있습니다. 맨 위의 선발 기준은 사실상 서울대를 위해 만들어졌으며 (서울대 15팀 중 7팀 이하를 자르는 컷을 찾습니다), 본선 진출 경계선인 60위에 (작년에는 90위였을 거고 그럼 얘기가 다릅니다) 50% 이상의 팀을 보낼 수 있는 학교는 몇 없기 때문에 (서울대, KAIST, 고려대 정도. 아마 해에 따라 다른 학교들도 가능한 해가 있을 것입니다) 사실상 저격밴이 됩니다. 제가 이번에 휴학생 팀으로 나간 이유도 여기에 있습니다. 저랑 비슷한 수준의 팀원 두명을 모으면 본선 진출이 어차피 어려울 것이고, 저보다 월등히 잘하는 팀원을 찾으면 어떻게 나가볼 수 있을지는 모르겠지만 첫째로는 그런 사람이 저랑 팀을 해줄지도 의문이고 두번째로는 해준다고 해도 제가 대회를 재밌게 즐기지 못할 것 같았습니다. 그래서 휴학생 팀이지만, 대회 자체를 진심으로 즐길 수 있는 - 일종의 즐겜팀이라고 할까요 - Little Piplup에 다시 함께했습니다. 이 monotonic하지 않은 선발 기준에 대해 어떻게 생각하는지는 사람마다 다른 영역인 것 같습니다. 저는 당연히 이 기준으로 본선 무대를 못 밟았으므로 굉장히 화가 나지만, 대학 대항전인 ICPC에서 서울대 15팀이 나타나는 것이 그럼 맞느냐? 고 말하면 뭐 그렇게 볼 수도 있습니다. 다만, 이 부분은 조금 나아질 기미가 보이는데, PS판에서 서울대가 보여줬던 갭이 점점 줄어드는게 눈에 보이기 때문입니다. 올해의 인예 순위에서 솔브수로 격차를 낸 최상위권은 서울-서울-고려-카이-카이-유니 입니다. (7솔에 저희를 포함 무려 12팀이 물려 있습니다) 참고로, 작년 인예는 9솔 이상이 7팀이었는데, 서울-서울-서울-서울-카이-서울-숭실 이었습니다. PS판의 저변이 넓어져서 그런 것인지, 서울대의 수많은 레드들이 PS판을 떠나고 ML 같은 보다 쓸모있는 뭔가를 공부하러 갔기 때문인지, 최근 여러 학교에서 레드 이상의 CP-er를 배출한 데 어떤 요소들이 작용했는지는 잘 모르겠지만 아무튼 그렇습니다. 레드 한명이 졸업할때까지 뛸수있는 ICPC판을 보니 내년에도 이럴 것 같고, 작년처럼 서울대 리저널 6팀인가? 보내 줬더니 모든 상을 서울대가 쓸어버리는 참사가 벌어지지는 않을 것입니다. 저는 내년이 마지막 ICPC고, 알고리즘을 공부하면서 / PS를 즐기면서 ICPC 본선 리저널 무대를 한번도 가보지 못했다는 것이 개인적으로 굉장히 아쉽습니다. 어떻게 보면 아카데믹하게 알고리즘을 공부하겠다는 목표를 갖게 된 지금은 PS 자체에 큰 의미는 없겠지만, 개인적으로 느낀 바가 그렇습니다. 그래서, 겨울방학에 좀 빡세게 돌면서 레드 정도 수준까지 폼을 맞춰놓고, 내년에는 레드 3명 또는 그에 근접한, 진출을 노리는 팀을 만들어 마지막 ICPC에 도전할 계획입니다. 좋은 팀원을 모은다면 80% 이상 가능하다고 확신하고 있습니다. 혹시 이 블로그를 보신 서울대 재학생 중, 내년 10월까지 CF 2300 또는 Equivalent한 실력을 갖출 수 있으며, 휴학 계획이 없고, 같이 공부하고 싶은 분은 연락주시면 좋을것 같네요. ㅋㅋ!!! (당연한 말이지만 이런 허공에 돌던지는 식으로 모을 생각으로 쓴 말은 아닙니다…) 대회를 마치며 항상 PS 대회를 뛰고 나면, PS를 즐기는 마인드와 대회 성적에 따른 competitive 한 마인드가 서로 충돌하게 됩니다. 이번 대회는 정말 간만에 그런 것 없이 순수하게 즐길 수 있었는데, 대회가 끝나고 나니 competitive mind가 잠깐 지배하고 있어서 위 500단어 정도를 ranting했습니다. 학기중에는 어차피 매우 바쁘기 때문에, 겨울방학에나 다시 손댈 수 있지 않을까 싶습니다. 끝나고 팀원들과 치킨을 먹으면서 대회에 대한 얘기도 하고, 재밌게 놀고 왔습니다. 네. 이 문장은 기만질 자랑하려고 적었습니다. ㅋㅋ!!! &amp;#8617;</summary></entry></feed>