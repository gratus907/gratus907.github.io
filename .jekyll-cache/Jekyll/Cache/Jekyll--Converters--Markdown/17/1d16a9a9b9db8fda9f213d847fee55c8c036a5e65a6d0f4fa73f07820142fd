I"¦R<div id="toc">
Contents
</div>
<ul id="markdown-toc">
  <li><a href="#lenet-ëª¨ë¸" id="markdown-toc-lenet-ëª¨ë¸">LeNet ëª¨ë¸</a></li>
  <li><a href="#êµ¬í˜„" id="markdown-toc-êµ¬í˜„">êµ¬í˜„</a></li>
</ul>
<hr />

<p><strong>ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ìˆ˜í•™ì  ê¸°ì´ˆ</strong> 8ê°• (10ì›” 5ì¼) ì— ê¸°ë°˜í•©ë‹ˆë‹¤.</p>

<p><a href="/deep-learning-study/mnist-mlp/">MLPë¡œ MNIST í’€ì–´ë³´ê¸°</a>ì˜ ì½”ë“œì™€ <a href="/deep-learning-study/convolutionary-neural-networks/">CNN ê¸°ì´ˆ</a> ë‚´ìš©ì— ì´ì–´ì§€ëŠ” í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.</p>

<h2 id="lenet-ëª¨ë¸">LeNet ëª¨ë¸</h2>
<p>ì—¬ê¸°ì„œëŠ” LeNet-5 ëª¨ë¸ì— ëŒ€í•´ ê°„ë‹¨íˆ ì‚´í´ë´…ë‹ˆë‹¤.</p>

<p>LeNetì€ ê±°ì˜ ìµœì´ˆì˜ CNNì„ ì´ìš©í•œ image classification ëª¨ë¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Turing award ìˆ˜ìƒìì´ë©°, ì‚¬ì‹¤ìƒ CNNì˜ ì•„ë²„ì§€ ê²©ì¸ Yann Lecunì˜ ì—°êµ¬íŒ€ì´ 1998ë…„ì— ê°œë°œí•˜ì˜€ê³  ê·¸ ì´ë¦„ì„ ë”°ì„œ LeNetì´ë¼ëŠ” ì´ë¦„ì„ ê°–ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. â€œGradient Based Learning Applied to Document Recognitionâ€ ë¼ëŠ” ì œëª©ì˜ ë…¼ë¬¸ìœ¼ë¡œ ë°œí‘œë˜ì—ˆëŠ”ë°, ì œëª©ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ ë³¸ë˜ ì†ê¸€ì”¨ë¡œ ì“°ì¸ ê¸€ìë¥¼ êµ¬ë¶„í•˜ëŠ” taskë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.</p>

<p><img src="../../images/cd97eccdcd206c69165bedbe52ab311cecf6e35e340166c1780794892fed550e.png" alt="picture 1" /></p>

<p>ì´ êµ¬ì¡°ëŠ” LeNetì˜ ì „ì²´ì ì¸ ëª¨ë¸ì…ë‹ˆë‹¤. <a href="/deep-learning-study/convolutionary-neural-networks/">CNN ê¸°ì´ˆ</a> ì— ìˆëŠ” ê° ë ˆì´ì–´ë³„ ì„¤ëª…ì„ ëª¨ë‘ ì´í•´í–ˆë‹¤ëŠ” ê°€ì •í•˜ì—, LeNetì˜ â€˜ì„ íƒâ€™ ë§Œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.</p>
<ul>
  <li>ì²« ë ˆì´ì–´ëŠ” $5 \times 5$ Convolution filter 6ê°œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</li>
  <li>Subsamplingì€ average poolingì„ ì‚¬ìš©í•˜ê³ </li>
  <li>Activation functionìœ¼ë¡œëŠ” tanhì˜ ì•½ê°„ ë³€í˜•ëœ í˜•íƒœë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</li>
  <li>ì¬ë°ŒëŠ” ì ì€ C3 Layerê°€ ì¼ë°˜ì ì¸ convolutionì´ ì•„ë‹ˆë¼ëŠ” ì ì…ë‹ˆë‹¤. ì›ë³¸ ë…¼ë¬¸ì— ì˜í•˜ë©´, symmetryë¥¼ ê¹¨ê¸° ìœ„í•´ì„œ S2-&gt;C3 convolutionì„ í•  ë•Œ, 6ê°œ ì±„ë„ ì „ë¶€ê°€ ì•„ë‹Œ ì±„ë„ ì¼ë¶€ë§Œ ì‚¬ìš©í•´ì„œ convolutionì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 
<img src="../../images/591aba20e38405a3f2c2fef76a765f3ac12b5b8abc6c3c9c8410ab22f8abc678.png" alt="picture 2" />  ì´ì™€ ê°™ì´, 0ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ì€ 0, 1, 2 ì±„ë„ë§Œ ì“°ê³ â€¦ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.</li>
  <li>Fully connected layerë¥¼ 2ë²ˆ íƒ„ ë‹¤ìŒ, ë§ˆì§€ë§‰ì—ëŠ” Gaussian connectionì´ë¼ëŠ” ì¡°ê¸ˆ ë³µì¡í•œ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í›„ìˆ í•  ì´ìœ ë¡œ ì¸í•´ ìì„¸íˆ ì„¤ëª…í•˜ì§€ëŠ” ì•Šê² ìŠµë‹ˆë‹¤.</li>
</ul>

<p>ê·¸ëŸ¬ë‚˜ ì´ì–´ì§„ í›„ì†ì—°êµ¬ì— ì˜í•´, ê¼­ ì´ëŸ° design choiceë¥¼ ì§€í‚¬ í•„ìš”ê°€ ì—†ìŒì´ ì•Œë ¤ì¡ŒìŠµë‹ˆë‹¤. êµ¬í˜„ì˜ ë‹¨ìˆœí•¨ê³¼ ì„±ëŠ¥ì„ ìœ„í•´ ëª¨ë¸ì„ ì¡°ê¸ˆ ìˆ˜ì •í•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.</p>
<ul>
  <li>Subsamplingì—ëŠ” avg poolingì´ ì•„ë‹Œ max poolingì„ ì‚¬ìš©í•©ë‹ˆë‹¤.</li>
  <li>Activationìœ¼ë¡œ ReLUë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.</li>
  <li>êµ³ì´ Symmetryë¥¼ ì´ëŸ° ë°©ë²•ìœ¼ë¡œ ê¹¨ì§€ ì•Šì•„ë„, initializationì„ ì˜ í•˜ë©´ ìƒê´€ ì—†ë‹¤ê³  í•©ë‹ˆë‹¤. Symmetry-breaking connectionì€ ë²„ë¦¬ê² ìŠµë‹ˆë‹¤.</li>
  <li>Gaussian connectionë„ í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ê·¸ëƒ¥ Fully connected layerë¡œ ì¶©ë¶„í•˜ë‹¤ê³  í•©ë‹ˆë‹¤.</li>
</ul>

<h2 id="êµ¬í˜„">êµ¬í˜„</h2>
<p>êµ¬í˜„ì€ <a href="/deep-learning-study/mnist-mlp/">MLPë¡œ MNIST í’€ì–´ë³´ê¸°</a> ì™€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>

<p>MNIST ë°ì´í„° ë¡œë”©í•˜ëŠ” ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./mnist_data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./mnist_data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
</code></pre></div></div>

<p>ì´ì œ, LeNet ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤. Convolution ì—°ì‚°ì„ ì“´ë‹¤ëŠ”ê²ƒ ì™¸ì—ëŠ” ì—¬ì „íˆ ë‹¤ë¥¸ì ì´ ì—†ìŠµë‹ˆë‹¤.</p>

<p>ëª¨ë¸ì˜ ì •ì˜ê°€ ìœ„ ê·¸ë¦¼ê³¼ ë‹¤ë¥¸ì ì´ í•˜ë‚˜ ë” ìˆëŠ”ë°, ê·¸ë¦¼ì—ì„œëŠ” ì²« layerì— íŒ¨ë”©ì„ ì“°ì§€ ì•ŠëŠ” ëŒ€ì‹  ì´ë¯¸ì§€ í¬ê¸°ê°€ 32 by 32ì˜€ì§€ë§Œ, ìš°ë¦¬ê°€ ê°€ì§„ MNIST ë°ì´í„°ëŠ” 28 by 28ì´ê¸° ë•Œë¬¸ì— ì²« ë ˆì´ì–´ì—ì„œ íŒ¨ë”© 2ë¥¼ ë„£ì–´ ì¤ë‹ˆë‹¤. ì´í›„ì—ëŠ” ìœ„ ì„¤ëª…ê³¼ ë˜‘ê°™ìŠµë‹ˆë‹¤. Optimizerë¡œëŠ” ì—¬ê¸°ì„œë„ SGDë¥¼ ì“°ê² ìŠµë‹ˆë‹¤.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LeNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">C5_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">16</span><span class="p">,</span> <span class="mi">120</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv_layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_layer1</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv_layer2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_layer2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">16</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">C5_layer</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc_layer1</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc_layer2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LeNetModern</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span> 
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)))</span>
</code></pre></div></div>
<p>ì´ë ‡ê²Œ ì–»ì€ modelì˜ summaryëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 28, 28]             156
              ReLU-2            [-1, 6, 28, 28]               0
         MaxPool2d-3            [-1, 6, 14, 14]               0
            Conv2d-4           [-1, 16, 10, 10]           2,416
              ReLU-5           [-1, 16, 10, 10]               0
         MaxPool2d-6             [-1, 16, 5, 5]               0
            Linear-7                  [-1, 120]          48,120
              ReLU-8                  [-1, 120]               0
            Linear-9                   [-1, 84]          10,164
             ReLU-10                   [-1, 84]               0
           Linear-11                   [-1, 10]             850
================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 0.24
Estimated Total Size (MB): 0.35
----------------------------------------------------------------
</code></pre></div></div>
<p>6ë§Œ ê°œì˜ parameterë¥¼ ê°–ëŠ” ë§¤ìš° ì‘ì€ ëª¨ë¸ì…ë‹ˆë‹¤.</p>

<p>ì´ì œ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ì´ ëª¨ë¸ì„ ì‹¤ì œë¡œ í›ˆë ¨í•©ë‹ˆë‹¤. Train ë°©ë²•ë„ MLPì—ì„œì™€ ë˜‘ê°™ìŠµë‹ˆë‹¤.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">time</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCH</span><span class="p">)</span> <span class="p">:</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span> <span class="p">:</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">EPOCH</span><span class="si">}</span><span class="s"> : loss </span><span class="si">{</span><span class="n">train_loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Time taken : </span><span class="si">{</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">:.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>
</code></pre></div></div>
<ul>
  <li><code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code> ë¡œ ê¸°ì¡´ MLP ëª¨ë¸ì— ë‚¨ì•„ìˆë˜ gradient ê°’ë“¤ì„ ë‹¤ ë‚ ë¦¬ê³ </li>
  <li><code class="language-plaintext highlighter-rouge">train_loss</code> ëŠ” í˜„ì¬ ì‹œì ì— ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ ì¶”ì¸¡ì„ í•´ë³´ê³  ê·¸ loss function ê°’ì„ í™•ì¸í•˜ê³ ,</li>
  <li><code class="language-plaintext highlighter-rouge">.backward()</code> ë¡œ í˜„ì¬ ì‹œì ì˜ gradientë¥¼ ê³„ì‚°í•˜ê³ </li>
  <li><code class="language-plaintext highlighter-rouge">optimizer.step()</code> ìœ¼ë¡œ ì‹¤ì œ optimization (ì—¬ê¸°ì„  SGD)ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.</li>
</ul>
:ET