I"„<div id="toc">
Contents
</div>
<ul id="markdown-toc">
  <li><a href="#overfitting-issue" id="markdown-toc-overfitting-issue">Overfitting Issue</a></li>
  <li><a href="#how-to-deal-with" id="markdown-toc-how-to-deal-with">How to deal with?</a></li>
  <li><a href="#regularization" id="markdown-toc-regularization">Regularization</a></li>
  <li><a href="#regularized-linear-regression" id="markdown-toc-regularized-linear-regression">Regularized Linear Regression</a></li>
  <li><a href="#regularized-logistic-regression" id="markdown-toc-regularized-logistic-regression">Regularized Logistic Regression</a></li>
</ul>
<hr />

<h3 id="overfitting-issue">Overfitting Issue</h3>
<ul>
  <li>Underfitting : ë°ì´í„°ê°€ Linearí•˜ì§€ ì•ŠìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , Linear function fittingì„ í•˜ëŠ” ë“±ì˜ ì´ìœ ë¡œ fittingë˜ì§€ ì•ŠëŠ” í˜„ìƒ</li>
  <li>Overfitting : 5ê°œì˜ ë°ì´í„°ë¥¼ 4ì°¨í•¨ìˆ˜ë¡œ fittingí•œë‹¤ë©´? ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” 100%ì˜ ì •í™•ë„ë¥¼ ê°–ì§€ë§Œ, ì‹¤ì œë¡œ ì¢‹ì€ ëª¨ë¸ë§ì€ ì•„ë‹˜.</li>
  <li>ì´ë¥¼ High-varianceë¼ê³  í•œë‹¤. High-order ë‹¤í•­ì‹ì„ ì“¸ ë•Œì˜ ë¬¸ì œì . ì§€ë‚˜ì¹˜ê²Œ ë§ì€ ììœ ë„ì˜ ê°€ì„¤ì„ í—ˆìš©í•˜ì—¬, ë³„ë¡œ ì¢‹ì€ ê²°ê³¼ê°€ ì•„ë‹ˆê²Œ ë¨.</li>
  <li>Too many features -&gt; Cost functionì´ ë§¤ìš° ì‘ì§€ë§Œ ì‹¤ìš©ì ìœ¼ë¡œ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” ê²½ìš° ìˆìŒ.</li>
  <li>ì§€ë‚˜ì¹˜ê²Œ ì •í™•í•œ Fitting ê³¼ì • ë•Œë¬¸ì—, íŒŒì•…í•´ì•¼ í•  ê²½í–¥ì„±ì„ ë†“ì¹˜ëŠ” í˜„ìƒ!!</li>
</ul>

<h3 id="how-to-deal-with">How to deal with?</h3>
<ul>
  <li>Featureê°œìˆ˜ ì¤„ì´ê¸°. ì´ë¶€ë¶„ì€ Manualí•˜ê²Œ í•  ìˆ˜ë„ ìˆê³ , Model selection algorithmì„ ì“¸ ìˆ˜ë„ ìˆìŒ.
    <ul>
      <li>ì´ ê³¼ì •ì—ì„œ ì§„ì§œ í•„ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ë„ ìˆìŒ. ì‹¤ì œ Featureê°€ ì •ë§ ë¶ˆí•„ìš”í•œì§€ íŒì •í•˜ê¸°ê°€ ì–´ë µë‹¤.</li>
    </ul>
  </li>
  <li>Regularization. FeatureëŠ” ê·¸ëŒ€ë¡œ ë“¤ê³  ê°€ë˜, magnitude / value of parameterë¥¼ ì¤„ì´ëŠ” ë°©ë²•.</li>
</ul>

<h3 id="regularization">Regularization</h3>
<ul>
  <li>ex) í˜ë„í‹°ë¥¼ í†µí•´ $\theta_3, \theta_4$ ë¥¼ ì‘ì€ ê°’ìœ¼ë¡œ ìœ ì§€í•˜ë„ë¡ ê°•ì œí•˜ê¸°. \(J_{\text{new}}(\theta) = J(\theta) + 1000\theta_3^2 + 1000\theta_4^2\)</li>
  <li>ê²°êµ­ì€ Hypothesisë¥¼ ë” ê°„ë‹¨í•˜ê²Œ í•˜ëŠ” ê²ƒ. Overfitting ë¬¸ì œê°€ ì¤„ì–´ë“ ë‹¤.</li>
  <li>ex) Regularization parameterë¥¼ ì‚¬ìš©í•˜ì—¬, tradeoffë¥¼ ê°•ì œí•˜ê¸°.
\(J(\theta) = \frac{1}{2m}\left(\sum_{i = 1}^{m} (h_{\theta}(x_i) - y_i)^2 + \lambda \sum_{i = 1}^{n} \theta_j^2\right)\)</li>
  <li>$\lambda$ê°€ ë„ˆë¬´ í¬ë©´ -&gt; ì§€ë‚˜ì¹˜ê²Œ í° Penalty term ë•Œë¬¸ì— Underfitting ë°œìƒ.</li>
</ul>

<h3 id="regularized-linear-regression">Regularized Linear Regression</h3>
<p>\(\begin{aligned} \pdv{}{\theta_j}J(\theta) = \frac{1}{m} \sum_{i = 1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_j + \frac{\lambda}{m}\theta_j \end{aligned}\)</p>
<ul>
  <li>í¸ë¯¸ë¶„ì‹ì„ ì˜ ë³´ë©´, ë‹¤ìŒê³¼ ê°™ì€ ì—…ë°ì´íŠ¸ê°€ ì´ë£¨ì–´ì§ˆ ê²ƒì„ì„ ì•ˆë‹¤.
\(\theta_j := \theta_j \left( 1- \alpha \frac{\lambda}{m}\right) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_j\)</li>
  <li>
    <p>$\left( 1- \alpha \frac{\lambda}{m}\right)$ ì„ ë§¤ë²ˆ ê³±í•˜ëŠ” ëŠë‚Œì˜ Gradient Descent.</p>
  </li>
  <li>Normal equationì„ ì´ìš©í•´ì„œë„ ë¹„ìŠ·í•˜ê²Œ í•  ìˆ˜ ìˆë‹¤.
\(\theta = \left(X^T X + \lambda L\right)^{-1} X^T y\)
ì´ë•Œ $L$ ì€, Identityì—ì„œ ë§¨ ì™¼ìª½ ìœ„ í•­ì´ 0ì¸ matrixì´ë‹¤. <code class="language-plaintext highlighter-rouge">[[0, 0, 0], [0, 1, 0], [0, 0, 1]]</code> ì •ë„ ëŠë‚Œ.</li>
  <li>ì›ë˜ì˜ Linear regressionì€ Exampleë³´ë‹¤ Featureê°€ ë§ìœ¼ë©´ Non-invertibleí•˜ë‹¤. ì´ë•Œ, Regularizationì„ ì“°ë©´, $\lambda &gt; 0$ì¼ ë•Œ, $X^T X + \lambda L$ê°€ ë°˜ë“œì‹œ invertibleí•¨ì„ ë³´ì¼ ìˆ˜ ìˆë‹¤.</li>
</ul>

<h3 id="regularized-logistic-regression">Regularized Logistic Regression</h3>
<ul>
  <li>ë‹¤ìŒê³¼ ê°™ì€ updateë¥¼ ìˆ˜í–‰í•œë‹¤.
\(\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_0\)
\(\theta_j := \theta_j \left( 1- \alpha \frac{\lambda}{m}\right) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_j\)</li>
  <li>ë§ˆì°¬ê°€ì§€ë¡œ, ì‹ì€ Linear ë²„ì „ê³¼ ë˜‘ê°™ì´ ìƒê²¼ë‹¤. ì°¨ì´ëŠ” $h_\theta$ë¿.</li>
</ul>
:ET